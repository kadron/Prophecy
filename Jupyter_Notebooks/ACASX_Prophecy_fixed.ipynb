{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "t-JL_MKop5Qh",
    "outputId": "e81f2c9c-5754-45f5-a990-2430a8e5b4d6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import io\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GmYT2ebeSRD1",
    "outputId": "9c8a3cd1-542f-49f6-f811-16e0003f299a"
   },
   "outputs": [],
   "source": [
    "#!pip3 install -U pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ns8_eYDFReWq"
   },
   "outputs": [],
   "source": [
    "LAYER = 5\n",
    "LABEL = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J61k8v3VS0Rv"
   },
   "source": [
    "# READ 384221 ACASX INPUTS WITH KNOWN LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/home/burak/nasa-neural-properties/prophecy-acasx'\n",
      "/home/burak/nasa-neural-properties/prophecy-acasx\r\n"
     ]
    }
   ],
   "source": [
    "exp_folder = '/home/burak/nasa-neural-properties/prophecy-acasx'\n",
    "\n",
    "try: \n",
    "    os.mkdir(exp_folder)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "os.chdir(exp_folder)\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "y3Zs1CzKSqjM",
    "outputId": "545e9917-dc8d-4f78-8a23-d1237ad944cd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-28 19:18:46--  https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/clusterinACAS_0_short.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.24.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.24.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15903651 (15M) [text/plain]\n",
      "Saving to: ‘./clusterinACAS_0_shrt.csv’\n",
      "\n",
      "./clusterinACAS_0_s 100%[===================>]  15.17M  8.98MB/s    in 1.7s    \n",
      "\n",
      "2020-07-28 19:18:49 (8.98 MB/s) - ‘./clusterinACAS_0_shrt.csv’ saved [15903651/15903651]\n",
      "\n",
      "384221 examples\n",
      "(384221, 5)\n"
     ]
    }
   ],
   "source": [
    "acas_train = np.empty([384221,5],dtype=float)\n",
    "acas_train_labels = np.zeros(384221,dtype=int)\n",
    "\n",
    "def read_inputs_from_file(inputFile):\n",
    "    global acas_train, acas_train_labels, num\n",
    "    with open(inputFile) as f:\n",
    "        lines = f.readlines()\n",
    "        print(len(lines), \"examples\")\n",
    "        acas_train = np.empty([len(lines),5],dtype=float)\n",
    "        acas_train_labels = np.zeros(len(lines),dtype=int)\n",
    "        \n",
    "        for l in range(len(lines)):\n",
    "            k = [float(stringIn) for stringIn in lines[l].split(',')] #This is to remove the useless 1 at the start of each string. Not sure why that's there.\n",
    "            #acas_train[l+num] = np.zeros(5,dtype=float) #we're asuming that everything is 2D for now. The 1 is just to keep numpy happy.\n",
    "            if len(k) > 5:\n",
    "              lab = int(k[5])\n",
    "              #if ((lab == 0) or (lab == 2)):\n",
    "              #  lab = 0\n",
    "              #else:\n",
    "              #  lab = 1\n",
    "              acas_train_labels[l+num] = lab\n",
    "            \n",
    "            count = 0\n",
    "            for i in range(0,5):\n",
    "                #print(count)\n",
    "                acas_train[l+num][i] = k[i]\n",
    "                \n",
    "                #print(k[i])\n",
    "            \n",
    "                \n",
    "        \n",
    "              \n",
    "#url1 = 'https://github.com/hayesconverse/sym_convnn/blob/master/MNIST_ITR_REL/mnist_10_layer.txt' \n",
    "!wget https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/clusterinACAS_0_short.csv -O ./clusterinACAS_0_shrt.csv\n",
    "#!wget https://raw.githubusercontent.com/hayesconverse/sym_convnn/master/COV_prop6.csv -O ./COV_prop6.csv\n",
    "#!wget https://raw.githubusercontent.com/hayesconverse/sym_convnn/master/COV_prop6_1.csv -O ./COV_prop6_1.csv\n",
    "#!wget https://raw.githubusercontent.com/hayesconverse/sym_convnn/master/prop1_cov.csv -O ./prop1_cov.csv\n",
    "#!wget https://raw.githubusercontent.com/hayesconverse/sym_convnn/master/clusterinACAS_0_c2.csv -O ./clusterinACAS_0_c2.csv\n",
    "#!wget https://raw.githubusercontent.com/hayesconverse/sym_convnn/master/clusterinACAS_0_c3.csv -O ./clusterinACAS_0_c3.csv\n",
    "#!wget https://raw.githubusercontent.com/hayesconverse/sym_convnn/master/clusterinACAS_0_c4.csv -O ./clusterinACAS_0_c4.csv\n",
    "#!wget https://raw.githubusercontent.com/hayesconverse/sym_convnn/master/clusterinACAS_0_c5.csv -O ./clusterinACAS_0_c5.csv\n",
    "#!wget https://raw.githubusercontent.com/hayesconverse/sym_convnn/master/clusterinACAS_0_c6.csv -O ./clusterinACAS_0_c6.csv\n",
    "num = 0\n",
    "#read_inputs_from_file('./COV_prop6_1.csv')\n",
    "#prop6_inputs_part1 = acas_train\n",
    "#read_inputs_from_file('./COV_prop6.csv')\n",
    "#prop6_inputs_part2 = acas_train\n",
    "#read_inputs_from_file('./prop1_cov.csv')\n",
    "#prop1_inputs = acas_train\n",
    "\n",
    "read_inputs_from_file('./clusterinACAS_0_shrt.csv')\n",
    "\n",
    "#num = num + 458066\n",
    "#read_inputs_from_file('./clusterinACAS_0_c2.csv')\n",
    "#num = num + 460342\n",
    "#read_inputs_from_file('./clusterinACAS_0_c3.csv')\n",
    "#num = num + 462166\n",
    "#read_inputs_from_file('./clusterinACAS_0_c4.csv')\n",
    "#num = num + 467893\n",
    "#read_inputs_from_file('./clusterinACAS_0_c5.csv')\n",
    "#num = num + 467646\n",
    "#read_inputs_from_file('./clusterinACAS_0_c6.csv')\n",
    "\n",
    "print((acas_train).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHI2V3zxUhac"
   },
   "source": [
    "## **DEFINE THE ACASX MODEL IN TENSORFLOW 6 LAYERS WITH 50 HIDDEN NODES, 5 INPUTS AND 5 OUTPUTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39JpLmTitqdj"
   },
   "outputs": [],
   "source": [
    "\n",
    "def weight_variable(shape, name):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial, name=name)\n",
    "\n",
    "def fc2d(x, W):\n",
    "  return tf.nn.fc2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def create_model():\n",
    "    x = tf.identity(tf.placeholder(tf.float32, shape=[None, 5]), name=\"input\")\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 5])\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    #LAYER 0\n",
    "    W_fc1 = weight_variable([5, 50],name='w_fc1')\n",
    "    b_fc1 = bias_variable([50],name='b_fc1')\n",
    "    x_image = tf.reshape(x, [-1, 5])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(x_image, W_fc1) + b_fc1)\n",
    "    h_fc1_iden = tf.identity(h_fc1,name='h_fc1')\n",
    "    \n",
    "    #LAYER 1\n",
    "    W_fc2 = weight_variable([50, 50],name='w_fc2')\n",
    "    b_fc2 = bias_variable([50],name='b_fc2')\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "    h_fc2_iden = tf.identity(h_fc2,name='h_fc2')\n",
    "    \n",
    "    #LAYER 2\n",
    "    W_fc3 = weight_variable([50, 50],name='w_fc3')\n",
    "    b_fc3 = bias_variable([50],name='b_fc3')\n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2, W_fc3) + b_fc3)\n",
    "    h_fc3_iden = tf.identity(h_fc3,name='h_fc3')\n",
    "    \n",
    "    #LAYER 3\n",
    "    W_fc4 = weight_variable([50, 50],name='w_fc4')\n",
    "    b_fc4 = bias_variable([50],name='b_fc4')\n",
    "    h_fc4 = tf.nn.relu(tf.matmul(h_fc3, W_fc4) + b_fc4)\n",
    "    h_fc4_iden = tf.identity(h_fc4,name='h_fc4')\n",
    "    \n",
    "    #LAYER 4\n",
    "    W_fc5 = weight_variable([50, 50],name='w_fc5')\n",
    "    b_fc5 = bias_variable([50],name='b_fc5')\n",
    "    h_fc5 = tf.nn.relu(tf.matmul(h_fc4, W_fc5) + b_fc5)\n",
    "    h_fc5_iden = tf.identity(h_fc5,name='h_fc5')\n",
    "    \n",
    "    #LAYER 5\n",
    "    W_fc6 = weight_variable([50, 50],name='w_fc6')\n",
    "    b_fc6 = bias_variable([50],name='b_fc6')\n",
    "    h_fc6 = tf.nn.relu(tf.matmul(h_fc5, W_fc6) + b_fc6)\n",
    "    h_fc6_iden = tf.identity(h_fc6,name='h_fc6')\n",
    "\n",
    "    #LAYER 6\n",
    "    W_fc7 = weight_variable([50, 5],name='w_fc7')\n",
    "    b_fc7 = bias_variable([5],name='b_fc7')\n",
    "   \n",
    "  \n",
    "    y_fc = tf.matmul(h_fc6, W_fc7) + b_fc7\n",
    "    h_y_fc_iden = tf.identity(y_fc,name='y_fc')\n",
    "    \n",
    "    \n",
    "    prediction = tf.identity(tf.nn.softmax(y_fc), name=\"import/prediction\")\n",
    "    \n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_fc))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmin(y_fc, 1), tf.argmax(y_, 1))\n",
    "    \n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    return cross_entropy, accuracy, x, keep_prob, y_fc, y_, W_fc1, W_fc2, W_fc3, W_fc4, W_fc5, W_fc6, W_fc7, b_fc1, b_fc2, b_fc3, b_fc4, b_fc5, b_fc6, b_fc7, h_fc1, h_fc2, h_fc3, h_fc4, h_fc5, h_fc6\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0i4RUUCvT4qR"
   },
   "source": [
    "### **Restore a pretrained ACASX model FROM A .NN OR TXT FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "M-NyZVbLT4qO",
    "outputId": "b5ea980d-b3a1-41ee-b032-7a09e06340cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-28 19:19:08--  https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/ACASX_layer.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.24.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.24.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 264199 (258K) [text/plain]\n",
      "Saving to: ‘./ACASX_layer.txt’\n",
      "\n",
      "./ACASX_layer.txt   100%[===================>] 258.01K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-07-28 19:19:09 (1.95 MB/s) - ‘./ACASX_layer.txt’ saved [264199/264199]\n",
      "\n",
      "0 [[ 5.40060e-02 -1.12374e+00  1.96019e-01 -1.63015e+00 -3.55133e-01\n",
      "  -3.41920e-02  4.02002e-01 -1.41575e+00 -1.44498e+00 -1.12740e+00\n",
      "   6.13717e-01  9.33699e-01 -4.08030e-02 -2.12265e-01  3.20180e-02\n",
      "  -1.24050e-02 -1.22430e-01  6.01740e-02  8.33030e-02 -1.18804e+00\n",
      "  -1.03537e-01 -8.53900e-02 -1.93840e-02  1.66870e-02  1.67600e-03\n",
      "  -8.97525e-01 -9.33220e-01  1.60333e-01  8.34020e-02  2.84019e-01\n",
      "   1.37295e+00 -1.44445e-01 -1.36290e+00 -1.55178e+00  1.29659e+00\n",
      "   1.58680e-02 -4.15860e-02 -8.26990e-02 -1.59025e+00  2.83390e-02\n",
      "   1.39212e-01  2.57852e-01  6.86480e-02 -7.44590e-01 -4.16569e-01\n",
      "  -6.32539e-01  3.92010e-02 -3.85880e-02 -1.57631e+00  6.20367e-01]\n",
      " [-2.61092e+00  2.63620e-02  2.42159e-01 -3.44450e-02  5.65969e-01\n",
      "   1.49570e+00  2.24022e-01 -7.47430e-02  4.48400e-02  2.39890e-02\n",
      "  -5.57820e-01  2.03647e-01  5.48666e-01 -3.28003e-01  4.22455e-01\n",
      "   2.28453e+00 -7.12042e-01 -6.39070e-02 -4.07490e-02  1.44630e-01\n",
      "   6.99910e-02  1.75215e-01  3.99390e+00 -6.54405e-01  5.38400e-03\n",
      "  -1.27606e-01 -2.43280e-02  3.69300e-03  2.01281e+00 -4.65740e-02\n",
      "   5.88100e-03  6.08000e-04 -2.07200e-02  8.38020e-02  9.38270e-02\n",
      "   3.29773e-01 -1.47674e+00  2.55100e-03  4.75710e-02 -2.30820e-02\n",
      "  -5.72182e-01 -6.26800e-02  2.45900e-03  3.11900e-03  1.20670e-02\n",
      "  -3.58630e-02  5.64469e-01 -1.23878e-01  4.40000e-04  7.50370e-02]\n",
      " [-1.80027e-01 -9.17900e-03  6.38452e-01 -6.05500e-03  2.28267e-01\n",
      "  -1.53371e+00 -4.67160e-02  6.04390e-02  8.88900e-03 -9.56700e-03\n",
      "  -5.19510e-02  1.66178e-01  5.74870e-02  3.57536e-01 -5.68833e-01\n",
      "   5.34620e-02  9.15900e-03 -2.50281e+00 -7.52101e-01 -1.49280e-01\n",
      "   2.42373e+00 -8.74010e-02  1.17807e-01  5.60096e-01 -7.26600e-03\n",
      "   1.62803e-01  2.30273e-01  2.62149e-01  3.55310e-01  7.47900e-03\n",
      "   1.30910e-02 -2.11640e-02  4.45640e-02 -3.52090e-02  1.75474e-01\n",
      "  -2.65353e-01 -5.79320e-02  9.87200e-03  7.63100e-03 -7.63310e-02\n",
      "   4.26805e-01 -3.31132e-01 -1.42610e-02 -1.87879e-01 -4.81610e-02\n",
      "   2.83510e-02  2.62818e-01 -7.62627e-01 -8.32200e-03 -1.46140e-02]\n",
      " [ 2.42194e-01  5.56230e-02 -4.78265e-01  1.12080e-02  1.77342e-01\n",
      "   4.05050e-02  1.63890e-01  4.82660e-02 -2.50230e-01  8.92800e-03\n",
      "   1.60852e-01 -1.52200e-03  1.42985e-01 -3.89715e-01 -2.10782e-01\n",
      "   5.80560e-02 -3.91123e-01  4.99700e-02 -1.18798e-01 -3.60770e-02\n",
      "   2.26500e-02 -7.31836e-01  7.84150e-02  1.96579e-01  4.18100e-03\n",
      "  -4.81180e-02 -2.09033e-01  2.81943e-01  3.60060e-02 -8.40513e-01\n",
      "  -7.41000e-02 -6.47714e-01  3.94110e-02  6.06000e-03  1.33440e-01\n",
      "  -1.03541e-01 -2.06667e-01  6.89710e-02 -1.42600e-02 -7.71610e-01\n",
      "  -3.30029e-01  3.29905e-01  2.79900e-02  1.36180e-02 -3.64603e-01\n",
      "   7.37680e-02 -1.39610e-02  4.23040e-02 -9.26610e-02  2.62575e-01]\n",
      " [ 1.41407e-01 -3.27635e-01  1.42577e-01 -1.05000e-02 -2.08078e-01\n",
      "   1.64350e-01 -1.60826e-01 -5.60100e-02  6.53310e-02 -4.58000e-03\n",
      "  -9.71770e-02 -2.09448e-01  9.48680e-02 -4.59337e-01  7.57510e-02\n",
      "   1.18652e-01  3.39850e-02 -3.77900e-02 -2.18044e-01 -1.18933e-01\n",
      "   3.19610e-02 -2.20850e-01 -1.45180e-02 -4.49805e-01  1.78100e-03\n",
      "   7.85460e-02 -9.43660e-02 -5.51476e-01 -9.96480e-02 -4.81789e-01\n",
      "  -1.55849e-01 -1.82690e-02  9.35690e-02  8.28400e-03  2.98777e-01\n",
      "   7.65930e-02  2.01547e-01 -8.78938e-01  2.85000e-03  4.99034e-01\n",
      "   2.80864e-01 -8.56315e-01 -1.85103e+00 -1.59550e-02  2.88194e-01\n",
      "   6.50000e-02 -3.57883e-01  4.98900e-02 -4.93700e-03 -2.57948e-01]]\n",
      "0 [ 0.22763  -0.188762  0.053409 -0.377861 -0.081253 -0.588651  0.074607\n",
      " -0.392887 -0.356303 -0.167712  0.058711  0.183917  0.131957 -0.308681\n",
      "  0.196929  0.206664 -0.311696  0.030658 -0.138822 -0.347434 -0.004518\n",
      " -0.390616  0.096963  0.009833 -0.018859 -0.231919 -0.238165  0.071015\n",
      " -0.141913 -0.442307  0.559084  0.135483 -0.373217 -0.41539   0.759638\n",
      "  0.132825  0.235566  0.214858 -0.440841 -0.077297  0.221606 -0.006509\n",
      " -0.634843 -0.153833 -0.057303 -0.109229  0.037034  0.053809 -0.44755\n",
      "  0.175917]\n",
      "1 [[-0.184202  0.017164  0.069828 ...  0.396691 -1.24508  -0.348713]\n",
      " [ 0.034383 -0.034474 -0.004089 ... -0.096631  0.562699  0.098937]\n",
      " [-0.115142 -0.008693 -0.277997 ...  0.524738  0.260105  0.176364]\n",
      " ...\n",
      " [ 0.337388 -0.037116 -1.87652  ... -0.742039  0.646698 -0.60238 ]\n",
      " [ 0.395671  0.019644 -0.592208 ... -0.16962  -0.159838 -0.142155]\n",
      " [-0.223473 -0.035174  0.440622 ... -0.581466 -0.231139  0.160951]]\n",
      "1 [ 0.08355  -0.021326  0.756291 -1.25082   0.178469 -0.339158  0.109226\n",
      " -1.26214  -0.356488 -0.008294 -0.020118 -0.192039 -0.089258 -0.206319\n",
      "  0.105053 -0.093223 -0.245924  0.159416  0.465794 -0.760039  0.127213\n",
      "  0.393189 -0.071787  0.319831 -0.014118 -0.006604 -0.703714  0.440894\n",
      " -0.403874 -0.550258 -1.33355  -1.11956  -0.731673  0.237415 -0.827488\n",
      "  0.317529 -0.741801 -0.017441 -0.302206 -0.099699  0.655079  1.25241\n",
      "  0.039099 -0.024238 -0.385696 -0.359071 -0.155856  0.028597 -0.426623\n",
      "  0.780925]\n",
      "2 [[ 0.146062 -1.159     1.01583  ...  0.047013 -1.14982  -0.684643]\n",
      " [-0.005491 -0.008278  0.02824  ...  0.026038  0.008     0.026621]\n",
      " [ 0.793907 -0.478648  0.111866 ... -0.002391 -0.02437  -0.027043]\n",
      " ...\n",
      " [-1.15657  -2.33211   0.076939 ...  0.024557 -1.17371  -0.064733]\n",
      " [ 0.515279 -0.517898 -0.490059 ... -0.002761  0.414968 -0.186417]\n",
      " [-0.132622 -0.317556 -0.305079 ... -0.006872  0.732138  1.32784 ]]\n",
      "2 [-0.408486  1.06875  -0.101351  0.291739  0.361906 -1.17598  -1.08494\n",
      " -0.525396 -0.485121 -0.563451 -0.430958 -0.375102 -0.299369 -0.300263\n",
      " -0.528058 -0.062003 -0.65379   0.730181 -0.849961 -0.01573  -0.289808\n",
      "  0.27894   1.47078   2.10793  -0.31017  -0.538444 -0.145919  1.01049\n",
      " -0.374156 -0.052722 -0.14879   0.255464 -0.772198 -1.76047   0.062297\n",
      "  0.254439 -0.150744 -0.757264 -2.46425  -0.913194 -0.563058 -0.217101\n",
      "  0.570546 -0.523408 -1.49997  -0.261921 -0.526109 -0.00599  -0.464336\n",
      "  0.114195]\n",
      "3 [[-0.775044 -0.289933 -0.099163 ... -0.027932  0.124486  0.086276]\n",
      " [-0.415395 -0.039059 -0.03666  ... -0.061061 -0.114356  0.214661]\n",
      " [-0.324942 -0.235392  0.075501 ... -0.010141 -0.213392 -0.205132]\n",
      " ...\n",
      " [ 0.002888  0.028977 -0.017441 ...  0.030699 -0.014055  0.021973]\n",
      " [-0.058761  0.094352  0.135628 ...  0.010927  0.07039  -0.040301]\n",
      " [ 0.393332  0.244394  0.03856  ...  0.022571  0.087027  0.198957]]\n",
      "3 [ 1.48416  -0.039273 -0.090784 -2.47397  -2.26864   0.289911  0.084978\n",
      " -0.021694 -0.688173 -0.245358 -0.408883  0.345316 -1.17538  -0.129693\n",
      " -0.015381  2.30298   0.472199 -0.466609 -1.12351   0.495937 -0.570643\n",
      " -0.788515  1.01652   0.462602 -1.62913  -0.584215  0.124253 -0.077461\n",
      "  0.288896 -1.92722  -1.86128   0.507499  2.08643  -0.100975  0.302989\n",
      " -0.800885 -0.166501  0.224915 -0.31377  -0.088514 -0.041323 -0.688478\n",
      "  0.099973  0.235693  0.200208  0.185322  0.213242 -0.036336  0.076284\n",
      " -0.216393]\n",
      "4 [[-1.69473e-01  1.43577e-01  1.20000e-03 ...  4.18294e-01  2.33909e-01\n",
      "   1.92390e-01]\n",
      " [-1.03007e+00  1.57256e-01 -2.54742e-01 ... -1.40829e+00 -2.42613e-01\n",
      "  -8.79008e-01]\n",
      " [ 5.93824e-01  2.10021e+00  2.02776e-01 ... -2.72308e+00 -3.61940e-02\n",
      "   1.01191e+00]\n",
      " ...\n",
      " [-1.58800e-02 -8.13100e-03  2.05800e-03 ... -4.13330e-02 -4.08960e-02\n",
      "   4.02970e-02]\n",
      " [ 2.71254e-01 -1.93434e-01 -1.94817e-01 ...  1.14776e-01 -1.33666e+00\n",
      "  -2.91227e-01]\n",
      " [ 6.60591e-01 -9.96148e-01 -7.19632e-01 ...  1.42896e-01 -3.31785e-01\n",
      "   8.76066e-01]]\n",
      "4 [ 0.343884 -0.148704 -0.182344  2.09282   0.057392  1.07278  -3.5375\n",
      "  0.290246  1.78528   0.570392  0.102578 -0.867694 -1.88844  -1.11489\n",
      " -0.445675  0.694016  1.27762  -1.29112  -1.34225  -0.159671  0.645223\n",
      "  0.988629  0.516151 -2.38274   0.676756  0.761867  0.056761 -0.222461\n",
      "  1.86957   1.05205  -0.107629  0.090662  2.55632   0.875174  0.082792\n",
      " -1.16245   1.19683   0.119459  0.052383 -0.25144   0.971201  0.414523\n",
      "  0.559316  0.711265 -3.24478   0.58      0.165873 -1.29327  -0.331041\n",
      " -0.654165]\n",
      "5 [[ 1.98900e-02 -1.24780e-01 -1.47445e+00 ... -7.10425e-01 -2.83984e-01\n",
      "   1.14590e-02]\n",
      " [-4.04530e-02  4.16070e-02 -1.20772e+00 ...  5.89590e-02  2.41602e-01\n",
      "   7.35028e-01]\n",
      " [-2.77591e-01  6.87740e-02 -5.33325e-01 ...  2.00475e-01  2.44170e-02\n",
      "  -5.64580e-02]\n",
      " ...\n",
      " [-5.56117e-01  8.24240e-02 -7.74552e+00 ... -4.11356e-01  2.93450e-02\n",
      "  -1.56880e-02]\n",
      " [-3.21128e-01  2.93020e-02 -1.05717e-01 ...  1.26710e-02 -3.25370e-02\n",
      "  -5.48700e-03]\n",
      " [-4.48875e+00  3.86900e-02  3.23942e+00 ...  5.60790e-01 -4.14609e-01\n",
      "   1.93330e-02]]\n",
      "5 [-0.430061 -0.024574 -1.85737  -0.013815  0.419247 -0.213587  0.16007\n",
      "  0.741838  0.008469 -0.726034 -4.74206   0.06949  -0.33274   0.458429\n",
      " -1.03401  -0.436594  0.087068 -1.17479   0.295038  0.64818   0.596977\n",
      " -2.17556  -1.11059  -0.429719  0.24184   0.161132  0.103251  0.190621\n",
      " -2.56281   0.428494  0.165919 -0.041315 -3.21202   0.016572 -1.44951\n",
      " -0.212717  0.096362 -0.183611 -0.554534  0.339886  0.36664   1.18725\n",
      " -7.0066    0.864816 -4.08665   0.190657  0.438984 -0.664789 -0.114347\n",
      "  0.121706]\n",
      "6 [[-1.00500e-03 -1.60900e-03  3.17030e-02  3.86000e-03  3.29740e-02]\n",
      " [ 1.77590e-02  2.38130e-02  2.12330e-02  1.59410e-02 -3.21000e-03]\n",
      " [ 6.44700e-03  7.46900e-03 -4.98200e-03  1.25380e-02 -7.30700e-03]\n",
      " [ 1.00600e-02 -3.13100e-03  2.76190e-02  4.46200e-03  1.42820e-02]\n",
      " [ 2.15800e-03 -2.81000e-03  2.03130e-02 -2.79640e-02  3.09290e-02]\n",
      " [ 2.41700e-02  2.28730e-02  2.17320e-02  2.42820e-02  2.67670e-02]\n",
      " [ 2.07160e-02  2.36430e-02  1.20340e-02  8.00900e-03  2.29180e-02]\n",
      " [ 3.25300e-03  8.20800e-03 -6.28800e-03  2.42510e-02 -2.24140e-02]\n",
      " [ 3.76960e-02  4.33520e-02  4.11110e-02 -4.30000e-03  4.61000e-03]\n",
      " [ 5.37380e-02  5.18450e-02  5.82640e-02  5.97860e-02  5.24490e-02]\n",
      " [ 3.96700e-03 -9.75000e-04  9.41800e-03 -1.14640e-02  1.78040e-02]\n",
      " [ 2.95000e-04 -2.46000e-04  1.53710e-02 -1.91130e-02  2.93890e-02]\n",
      " [ 8.44100e-03  3.99500e-03  2.89060e-02  4.06600e-03  2.78020e-02]\n",
      " [ 4.30000e-03 -8.09400e-03  1.30500e-02 -1.23400e-02  2.45190e-02]\n",
      " [ 5.50000e-05 -7.29100e-03  2.92400e-03 -1.65000e-02  1.20460e-02]\n",
      " [ 2.70630e-02  1.95300e-02  2.52010e-02  2.48730e-02  3.47380e-02]\n",
      " [ 4.23000e-03 -8.46000e-03 -1.02100e-02  2.29470e-02  2.26420e-02]\n",
      " [-1.69610e-02 -2.80780e-02 -1.21320e-02 -2.87020e-02  1.86000e-03]\n",
      " [ 4.34000e-03  2.22400e-03  1.39770e-02 -1.10200e-02  2.31080e-02]\n",
      " [ 5.67520e-02  6.69690e-02  6.93010e-02  4.60940e-02  5.06330e-02]\n",
      " [ 6.00250e-02  5.56080e-02  5.26070e-02  5.86000e-02  5.19770e-02]\n",
      " [ 3.47100e-02  3.75400e-02  3.74210e-02  3.64220e-02  3.55480e-02]\n",
      " [ 1.04600e-03  8.12100e-03 -2.58300e-03  2.28340e-02 -2.09630e-02]\n",
      " [ 9.26000e-03 -1.06020e-02 -6.97100e-03  1.47450e-02  5.19500e-03]\n",
      " [ 1.04900e-02  1.40600e-02  3.10800e-03  1.50310e-02 -1.29480e-02]\n",
      " [-6.27140e-02 -1.13680e-02 -1.35620e-02 -1.41500e-02 -1.84530e-02]\n",
      " [ 1.29800e-02  2.48420e-02  2.04090e-02  2.87790e-02 -5.44900e-03]\n",
      " [ 1.43107e-01  1.74828e-01  1.59073e-01  1.34752e-01  9.65000e-02]\n",
      " [ 1.56000e-04  1.45280e-02  1.64500e-03  2.10020e-02 -1.13050e-02]\n",
      " [ 9.09700e-03  1.00500e-02  1.90930e-02 -1.44820e-02  2.43230e-02]\n",
      " [ 1.86967e-01  2.01379e-01  1.99540e-01  1.46935e-01  1.34838e-01]\n",
      " [ 1.09490e-02  2.06930e-02  1.33320e-02  4.79500e-03  8.60200e-03]\n",
      " [-1.54140e-02 -1.40340e-02 -1.11090e-02 -1.90160e-02 -1.68500e-02]\n",
      " [ 3.66418e-01  4.13943e-01  4.00429e-01  1.98699e-01  2.04973e-01]\n",
      " [-4.64900e-03 -1.12930e-02 -3.65800e-03 -9.20700e-03  1.31380e-02]\n",
      " [-1.05610e-02 -4.36400e-03 -1.75430e-02  1.75600e-02 -2.45340e-02]\n",
      " [ 3.46630e-02  3.29310e-02  3.16600e-02  4.21520e-02  3.75600e-02]\n",
      " [ 3.54150e-02  2.33760e-02  3.06690e-02  3.91120e-02  3.36530e-02]\n",
      " [-7.78000e-04  2.94510e-02 -1.19000e-03  3.13060e-02  1.47600e-03]\n",
      " [ 3.85700e-03  1.55090e-02 -1.00580e-02  1.98000e-02 -1.03690e-02]\n",
      " [ 4.19100e-03 -2.07800e-03  2.21800e-03 -2.45560e-02  1.88850e-02]\n",
      " [-1.72910e-02 -2.57480e-02 -1.67650e-02 -3.48250e-02 -4.69500e-03]\n",
      " [ 6.28000e-03  1.32770e-02 -7.80000e-04  1.42150e-02 -3.16600e-03]\n",
      " [-1.46310e-02 -1.34530e-02 -2.45080e-02  1.62110e-02 -3.83990e-02]\n",
      " [ 5.26800e-03  1.97700e-03  2.07160e-02 -1.02770e-02  1.55330e-02]\n",
      " [ 2.35740e-02  2.45500e-02  1.52770e-02  2.69720e-02  2.36700e-02]\n",
      " [ 1.81070e-02  2.00010e-02  2.14740e-02  1.88190e-02  1.62630e-02]\n",
      " [-1.14800e-03 -5.15160e-02  2.84900e-03 -5.82470e-02 -3.40800e-03]\n",
      " [ 1.16410e-02  1.12730e-02  1.94170e-02 -1.00230e-02  2.12920e-02]\n",
      " [-4.97500e-03 -8.87700e-03 -9.55300e-03 -9.96500e-03 -8.07600e-03]]\n",
      "6 [-0.010282 -0.015867 -0.015482 -0.015336 -0.014828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/burak/nasa-neural-properties/nasa-neural-properties-env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Test accuracy 0.766304\n"
     ]
    }
   ],
   "source": [
    "def read_weights_from_file(inputFile):\n",
    "    global weightMatrix, biasMatrix\n",
    "    weightMatrix = np.empty(7, dtype=list)\n",
    "    biasMatrix = np.empty(7, dtype=list)\n",
    "    \n",
    "    weightMatrix_layer0 = np.zeros([5,50], dtype=float)\n",
    "    biasMatrix_layer0 = np.zeros([50], dtype=float)\n",
    "    weightMatrix_layer1 = np.zeros([50,50], dtype=float)\n",
    "    biasMatrix_layer1 = np.zeros([50], dtype=float)\n",
    "    weightMatrix_layer2 = np.zeros([50,50], dtype=float)\n",
    "    biasMatrix_layer2 = np.zeros([50], dtype=float)\n",
    "    weightMatrix_layer3 = np.zeros([50,50], dtype=float)\n",
    "    biasMatrix_layer3 = np.zeros([50], dtype=float)\n",
    "    weightMatrix_layer4 = np.zeros([50,50], dtype=float)\n",
    "    biasMatrix_layer4 = np.zeros([50], dtype=float)\n",
    "    weightMatrix_layer5 = np.zeros([50,50], dtype=float)\n",
    "    biasMatrix_layer5 = np.zeros([50], dtype=float)\n",
    "    weightMatrix_layer6 = np.zeros([50,5], dtype=float)\n",
    "    biasMatrix_layer6 = np.zeros([5], dtype=float)\n",
    "    \n",
    "    with open(inputFile) as f:\n",
    "        lines = f.readlines()\n",
    "        currentLine = 0\n",
    "        prevlayer = -1\n",
    "        for indx in range(0,len(lines)):\n",
    "            vals = lines[currentLine].split(',')\n",
    "            #print vals\n",
    "            layer = int(vals[0])\n",
    "            isBias = int(vals[1])\n",
    "            OutNum = int(vals[2])\n",
    "            InNum = int(vals[3]) - 1\n",
    "            \n",
    "         \n",
    "            if ((prevlayer == -1) or (prevlayer != layer)):\n",
    "              if (prevlayer == 0):\n",
    "                  weightMatrix[prevlayer] = weightMatrix_layer0\n",
    "                  biasMatrix[prevlayer] = biasMatrix_layer0\n",
    "              if (prevlayer == 1):\n",
    "                  weightMatrix[prevlayer] = weightMatrix_layer1\n",
    "                  biasMatrix[prevlayer] = biasMatrix_layer1\n",
    "              if (prevlayer == 2):\n",
    "                  weightMatrix[prevlayer] = weightMatrix_layer2\n",
    "                  biasMatrix[prevlayer] = biasMatrix_layer2\n",
    "              if (prevlayer == 3):\n",
    "                  weightMatrix[prevlayer] = weightMatrix_layer3\n",
    "                  biasMatrix[prevlayer] = biasMatrix_layer3\n",
    "              if (prevlayer == 4):\n",
    "                  weightMatrix[prevlayer] = weightMatrix_layer4\n",
    "                  biasMatrix[prevlayer] = biasMatrix_layer4\n",
    "              if (prevlayer == 5):\n",
    "                  weightMatrix[prevlayer] = weightMatrix_layer5\n",
    "                  biasMatrix[prevlayer] = biasMatrix_layer5\n",
    "              prevlayer = layer\n",
    "              \n",
    "             \n",
    "              \n",
    "            if (isBias == 0):\n",
    "                if (layer == 0):\n",
    "                  weightMatrix_layer0[InNum][OutNum] = float(vals[4])\n",
    "                if (layer == 1):\n",
    "                  weightMatrix_layer1[InNum][OutNum] = float(vals[4])\n",
    "                if (layer == 2):\n",
    "                  weightMatrix_layer2[InNum][OutNum] = float(vals[4])\n",
    "                if (layer == 3):\n",
    "                  weightMatrix_layer3[InNum][OutNum] = float(vals[4])   \n",
    "                if (layer == 4):\n",
    "                  weightMatrix_layer4[InNum][OutNum] = float(vals[4])\n",
    "                if (layer == 5):\n",
    "                  weightMatrix_layer5[InNum][OutNum] = float(vals[4])\n",
    "                if (layer == 6):\n",
    "                  weightMatrix_layer6[InNum][OutNum] = float(vals[4])   \n",
    "               \n",
    "            else:\n",
    "                if (layer == 0):\n",
    "                  biasMatrix_layer0[OutNum] = float(vals[4])\n",
    "                if (layer == 1):\n",
    "                  biasMatrix_layer1[OutNum] = float(vals[4])\n",
    "                if (layer == 2):\n",
    "                  biasMatrix_layer2[OutNum] = float(vals[4])\n",
    "                if (layer == 3):\n",
    "                  biasMatrix_layer3[OutNum] = float(vals[4])   \n",
    "                if (layer == 4):\n",
    "                  biasMatrix_layer4[OutNum] = float(vals[4])\n",
    "                if (layer == 5):\n",
    "                  biasMatrix_layer5[OutNum] = float(vals[4])\n",
    "                if (layer == 6):\n",
    "                  biasMatrix_layer6[OutNum] = float(vals[4])   \n",
    "               \n",
    "                \n",
    "            currentLine += 1\n",
    "            \n",
    "    \n",
    "    weightMatrix[6] = weightMatrix_layer6\n",
    "    biasMatrix[6] = biasMatrix_layer6\n",
    "    \n",
    "    for indx in range(0,7):\n",
    "          print(indx,weightMatrix[indx])\n",
    "          print(indx,biasMatrix[indx])\n",
    "              \n",
    "!wget 'https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/ACASX_layer.txt' -O ./ACASX_layer.txt\n",
    "\n",
    "read_weights_from_file('./ACASX_layer.txt')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#tf.compat.v1.get_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "cross_entropy, accuracy, x, keep_prob, y_fc, y_, W_fc1, W_fc2, W_fc3, W_fc4, W_fc5, W_fc6, W_fc7, b_fc1, b_fc2, b_fc3, b_fc4, b_fc5, b_fc6, b_fc7, h_fc1, h_fc2, h_fc3, h_fc4, h_fc5, h_fc6 = create_model()\n",
    "feed_dict = {x:acas_train, y_: np.eye(5)[acas_train_labels], keep_prob: 1.0, W_fc1: weightMatrix[0], b_fc1: biasMatrix[0], W_fc2: weightMatrix[1], b_fc2: biasMatrix[1], W_fc3: weightMatrix[2], b_fc3: biasMatrix[2], W_fc4: weightMatrix[3], b_fc4: biasMatrix[3], W_fc5: weightMatrix[4], b_fc5: biasMatrix[4], W_fc6: weightMatrix[5], b_fc6: biasMatrix[5], W_fc7: weightMatrix[6],  b_fc7:biasMatrix[6]}\n",
    "\n",
    "test_accuracy = accuracy.eval(feed_dict)\n",
    "print(\"Test accuracy %g\"%(test_accuracy))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVIhOqo_kf2k"
   },
   "outputs": [],
   "source": [
    "if (LAYER == 1):\n",
    "  curr_lay = h_fc1\n",
    "  prev_lay = h_fc1\n",
    " \n",
    "if (LAYER == 2):\n",
    "  curr_lay = h_fc2\n",
    "  prev_lay = h_fc1\n",
    "  \n",
    "if (LAYER == 3):\n",
    "  curr_lay = h_fc3\n",
    "  prev_lay = h_fc2\n",
    " \n",
    "if (LAYER == 4):\n",
    "  curr_lay = h_fc4\n",
    "  prev_lay = h_fc3\n",
    "\n",
    "if (LAYER == 5):\n",
    "  curr_lay = h_fc5\n",
    "  prev_lay = h_fc4\n",
    "\n",
    "if (LAYER == 6):\n",
    "  curr_lay = h_fc6\n",
    "  prev_lay = h_fc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRi_eAoeoFGE"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def get_prediction(inps, tensor=y_fc, batch_size=100):\n",
    "  def get_prediction_batch(batch):\n",
    "    #feed = {x: np.array(batch), keep_prob:1.0}\n",
    "    feed = {x: np.array(batch), keep_prob:1.0, W_fc1: weightMatrix[0], b_fc1: biasMatrix[0], W_fc2: weightMatrix[1], b_fc2: biasMatrix[1], W_fc3: weightMatrix[2], b_fc3: biasMatrix[2], W_fc4: weightMatrix[3], b_fc4: biasMatrix[3], W_fc5: weightMatrix[4], b_fc5: biasMatrix[4], W_fc6: weightMatrix[5], b_fc6: biasMatrix[5],W_fc7: weightMatrix[6], b_fc7: biasMatrix[6]}\n",
    "    return sess.run(tensor, feed_dict=feed)\n",
    "  n = len(inps)\n",
    "  if n%batch_size == 0:\n",
    "    batches = [inps[i*batch_size:(i+1)*batch_size] for i in range(int(n/batch_size))]\n",
    "  else:\n",
    "    batches = [inps[i*batch_size:(i+1)*batch_size] for i in range(int(n/batch_size) +1)]    \n",
    "  batch_predictions = [get_prediction_batch(b) for b in tqdm(batches)]\n",
    "  return np.concatenate(tuple(batch_predictions), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_uhUyYiBlL7"
   },
   "source": [
    "## Extracting Invariant Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPvUSoGyFkdt"
   },
   "outputs": [],
   "source": [
    "def fingerprint_suffix(inps,ten):\n",
    "  # Below t_fc1 is the final fully connected layer of size 1024.\n",
    "  return (get_prediction(inps, tensor=ten)>0.0).astype('int')\n",
    "\n",
    "def fingerprint_signature(inps,ten = h_fc5):\n",
    "  # Below t_fc1 is the final fully connected layer of size 1024.\n",
    "  return (get_prediction(inps, tensor=ten)>0.0).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "3QarR8VNHZNk",
    "outputId": "d12a0f62-3982-4b87-e833-8533d784f8aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3843/3843 [00:03<00:00, 1084.80it/s]\n",
      "  2%|▏         | 83/3843 [00:00<00:04, 827.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffixes computed for all training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3843/3843 [00:04<00:00, 938.17it/s] \n"
     ]
    }
   ],
   "source": [
    "# train_suffixes, train_predictions are in the same order\n",
    "# as mnist.train.images. Henceforth when we use the index i we will\n",
    "# be referring to mnist.train.images[i].\n",
    "train_suffixes = fingerprint_suffix(acas_train,curr_lay)\n",
    "print(\"Suffixes computed for all training data\")\n",
    "train_predictions = np.argmin(get_prediction(acas_train), axis=1)\n",
    "\n",
    "#ACASX accuracy is about 76.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxgnKvn04Q92"
   },
   "outputs": [],
   "source": [
    "def describe_input(i, training=True):\n",
    "  print(\"Input\", i)\n",
    "  print(\"SHOW INPUT\", acas_train[i])\n",
    "  print(\"Groundtruth\", acas_train_labels[i])\n",
    "  print(\"Prediction\", train_predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fcVM2dek4Qo"
   },
   "source": [
    "### Build the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "c_0fvX3aAWHN",
    "outputId": "a3e53831-be1a-47b3-f4f0-ed4ed7d1b8f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic decision tree\n",
    "basic_estimator = tree.DecisionTreeClassifier()\n",
    "basic_estimator.fit(train_suffixes, train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yK1Pr1agnsoi"
   },
   "source": [
    "### Examine clusters/invariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrv4jT4GXrp9"
   },
   "outputs": [],
   "source": [
    "def get_decision_path(estimator, inp):\n",
    "  # Extract the decision path taken by an input as an ordered list of indices\n",
    "  # of the neurons that were evaluated.\n",
    "  # See: http://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html\n",
    "  n_nodes = estimator.tree_.node_count\n",
    "  feature = estimator.tree_.feature\n",
    "\n",
    "  # First let's retrieve the decision path of each sample. The decision_path\n",
    "  # method allows to retrieve the node indicator functions. A non zero element of\n",
    "  # indicator matrix at the position (i, j) indicates that the sample i goes\n",
    "  # through the node j.\n",
    "  X_test = [inp]\n",
    "  node_indicator = estimator.decision_path(X_test)\n",
    "  # Similarly, we can also have the leaves ids reached by each sample.\n",
    "  leaf_id = estimator.apply(X_test)\n",
    "  # Now, it's possible to get the tests that were used to predict a sample or\n",
    "  # a group of samples. First, let's make it for the sample.\n",
    "  node_index = node_indicator.indices[node_indicator.indptr[0]:\n",
    "                                      node_indicator.indptr[1]]\n",
    "  neuron_ids = []\n",
    "  for node_id in node_index:\n",
    "    if leaf_id[0] == node_id:\n",
    "        continue\n",
    "    neuron_ids.append(feature[node_id])\n",
    "  return neuron_ids\n",
    "\n",
    "def get_suffix_cluster(neuron_ids, neuron_sig,suffixes=train_suffixes):\n",
    "  # Get the cluster of inputs that such that all inputs in the cluster\n",
    "  # have provided on/off signature for the provided neurons.\n",
    "  #\n",
    "  # The returned cluster is an array of indices (into mnist.train.images).\n",
    "  return np.where((suffixes[:, neuron_ids] == neuron_sig).all(axis=1))[0]\n",
    "\n",
    "def is_consistent_cluster(cluster, predictions):\n",
    "  # Check if all inputs within the cluster have the same prediction.\n",
    "  # 'cluster' is an array of input ids.\n",
    "  pred = predictions[cluster[0]]\n",
    "  for i in cluster:\n",
    "    if predictions[i] != pred:\n",
    "      return False\n",
    "  return True\n",
    "\n",
    "def is_misclassified(i):\n",
    "  return train_predictions[i] != acas_train_labels[i]\n",
    "\n",
    "def visualize_conductances(img, label, neuron_ids, only_on=False):\n",
    "  # Visualize the conductances for the provided image.\n",
    "  # Args:\n",
    "  # - img: the provided mnist image\n",
    "  # - label: prediction label w.r.t. conductance must be computed\n",
    "  # - neuron_ids: list of neurons indices from the suffix tensor for which\n",
    "  #    conductances must be computed.\n",
    "  # - only_on: If True then conductance is computed only for those neurons\n",
    "  #    that are on for the given image. \n",
    "  vis = [mnist_to_pil_img(img)]\n",
    "  suffix = fingerprint_suffix([img])\n",
    "  sumigc = 0.0\n",
    "  for i, id in enumerate(neuron_ids):\n",
    "    if only_on and suffix[i] != 1:\n",
    "      continue  \n",
    "    igc = conductance(img, label, neuron_id=id)\n",
    "    # igc = conductances[id]\n",
    "    sumigc = sumigc + igc\n",
    "  \n",
    "  \n",
    "  avgigc = sumigc / len(neuron_ids)\n",
    "  maxval = abs(max(avgigc, key=abs))\n",
    "  minval = abs(min(avgigc, key=abs))\n",
    "  threshold = (maxval - minval)/2.0\n",
    "  print(\"MAX ATR:\", maxval, \"MIN ATR:\", minval, \"THRESH:\", threshold)\n",
    "  avgigc = 1.0 * avgigc * (abs(avgigc) >= threshold)\n",
    "  \n",
    "  \n",
    "  vis.append(visualize_attrs2(255*mnist_to_rgb(img), mnist_to_rgb(avgigc)))\n",
    "  return combine(vis)\n",
    "\n",
    "def get_invariant_inp(estimator, ref_id, suffixes):\n",
    "  # Returns an invariant found w.r.t. the provided reference input\n",
    "  # Args\n",
    "  #  - inp: reference input, shape <784,>\n",
    "  # Returns:\n",
    "  #  - cluster: Indices of training inputs that satisfy the invariant\n",
    "  #  - neuron_id: A list of neurons such that all inputs that agree with\n",
    "  #    the reference input on the on/off status of these neurons have the\n",
    "  #    same prediction as the reference input.\n",
    "  ref_img = mnist_inp_images[ref_id]\n",
    "  ref_suffix = suffixes[ref_id]\n",
    "  print('PREFIX',ref_suffix)\n",
    "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
    "  print('NEURON IDS',neuron_ids)\n",
    "  neuron_sig = ref_suffix[neuron_ids]\n",
    "  print('NEURON SIGNATURE',neuron_sig)\n",
    "  cluster = get_suffix_cluster(neuron_ids, neuron_sig,suffixes)\n",
    "  imgs = []\n",
    "  cnt = 0\n",
    "  for indx1 in range(0,len(cluster)):\n",
    "    img = mnist.train.images(cluster[indx1])\n",
    "    fnd = 1\n",
    "    for i in range(0,len(img)):\n",
    "      if (ref_img[i] != img[i]):\n",
    "        fnd = 0\n",
    "        break\n",
    "    if (fnd == 1):\n",
    "        ref_id = cnt\n",
    "    cnt = cnt + 1\n",
    "    imgs.append(img)\n",
    "    \n",
    "  imgs_suffixes = fingerprint_signature(imgs,t_fc2)\n",
    "  ref_suffix = imgs_suffixes[ref_id]\n",
    "  print('PREFIX',ref_suffix)\n",
    "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
    "  print('NEURON IDS',neuron_ids)\n",
    "  neuron_sig = ref_suffix[neuron_ids]\n",
    "  print('NEURON SIGNATURE',neuron_sig)\n",
    "  cluster = get_suffix_cluster(neuron_ids, neuron_sig,imgs_suffixes)\n",
    "    \n",
    "  return cluster, neuron_ids, neuron_sig\n",
    "\n",
    "def get_invariant(estimator, ref_id):\n",
    "  # Returns an invariant found w.r.t. the provided reference input\n",
    "  # Args\n",
    "  #  - ref_id: Index (into mnist.train.images) of the reference input\n",
    "  # Returns:\n",
    "  #  - cluster: Indices of training inputs that satisfy the invariant\n",
    "  #  - neuron_id: A list of neurons such that all inputs that agree with\n",
    "  #    the reference input on the on/off status of these neurons have the\n",
    "  #    same prediction as the reference input.\n",
    "  ref_img = mnist.train.images[ref_id]\n",
    "  ref_suffix = train_suffixes[ref_id]\n",
    "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
    "  neuron_sig = ref_suffix[neuron_ids]\n",
    "  cluster = get_suffix_cluster(neuron_ids, neuron_sig)\n",
    "  return cluster, neuron_ids, neuron_sig\n",
    "\n",
    "\n",
    "def get_all_invariants(estimator):\n",
    "  # Returns a dictionary mapping each decision tree prediction class\n",
    "  # to a list of invariants. Each invariant is specified as a triple:\n",
    "  # - neuron ids\n",
    "  # - neuron signature (for the neuron ids)\n",
    "  # - number of training samples that hit it\n",
    "  # The neuron ids and neuron signature can be supplied to get_suffix_cluster\n",
    "  # to obtain the cluster of training instances that hit the invariant.\n",
    "  def is_leaf(node):\n",
    "    return estimator.tree_.children_left[node] == estimator.tree_.children_right[node]\n",
    "\n",
    "  def left_child(node):\n",
    "    return estimator.tree_.children_left[node]\n",
    "\n",
    "  def right_child(node):\n",
    "    return estimator.tree_.children_right[node]\n",
    "  \n",
    "  def get_all_paths_rec(node):\n",
    "    # Returns a list of triples corresponding to paths\n",
    "    # in the decision tree. Each triple consists of\n",
    "    # - neurons encountered along the path\n",
    "    # - signature along the path\n",
    "    # - prediction class at the leaf\n",
    "    # - number of training samples that hit the path\n",
    "    # The prediction class and number of training samples\n",
    "    # are set to -1 when the leaf is \"impure\".\n",
    "    feature = estimator.tree_.feature\n",
    "    if is_leaf(node):\n",
    "      values = estimator.tree_.value[node][0]\n",
    "      if len(np.where(values != 0)[0]) == 1:\n",
    "        cl = estimator.classes_[np.where(values != 0)[0][0]]\n",
    "        nsamples = estimator.tree_.n_node_samples[node]\n",
    "      else:\n",
    "        # impure node\n",
    "        cl = -1\n",
    "        nsamples = -1\n",
    "      return [[[], [], cl, nsamples]]\n",
    "    # If it is not a leaf both left and right childs must exist\n",
    "    paths = [[[feature[node]] + p[0], [0] + p[1], p[2], p[3]] for p in get_all_paths_rec(left_child(node))]\n",
    "    paths += [[[feature[node]] + p[0], [1] + p[1], p[2], p[3]] for p in get_all_paths_rec(right_child(node))]\n",
    "    return paths\n",
    "  paths =  get_all_paths_rec(0)\n",
    "  print(\"Obtained all paths\")\n",
    "  invariants = {}\n",
    "  for p in tqdm(paths):\n",
    "    neuron_ids, neuron_sig, cl, nsamples = p\n",
    "    if cl not in invariants:\n",
    "      invariants[cl] = []\n",
    "    # cluster = get_suffix_cluster(neuron_ids, neuron_sig)\n",
    "    invariants[cl].append([neuron_ids, neuron_sig, nsamples])\n",
    "  for cl in invariants.keys():\n",
    "    invariants[cl] = sorted(invariants[cl], key=operator.itemgetter(2), reverse=True)\n",
    "  return invariants\n",
    "\n",
    "\n",
    "def describe_cluster(cluster, neuron_ids, show_samples=False):\n",
    "  neuron_sig = train_suffixes[cluster[0]][neuron_ids]\n",
    "  print(\"Num neurons in invariant\", len(neuron_ids))\n",
    "  print(\"Neuron id and signature\")\n",
    "  \n",
    "  for i in range(0,len(neuron_ids)):\n",
    "    print(\"id:\", neuron_ids[i], \"sig:\", neuron_sig[i])\n",
    "  \n",
    "  print(\"Cluster size: \", len(cluster))\n",
    "  print(\"Num misclassified\", len([i for i in cluster if is_misclassified(i)]))\n",
    "  if show_samples:\n",
    "    for i in range(10):\n",
    "      images = []\n",
    "      for j in range(10):\n",
    "        if 10*i + j >= len(cluster):\n",
    "          break\n",
    "        images.append(mnist_to_pil_img(mnist.train.images[cluster[10*i+j]]))\n",
    "      if len(images) > 0:\n",
    "        show_img(combine(images))\n",
    "  \n",
    "\n",
    "def describe_invariants_all_labels(all_invariants,prevlayer = h_fc1,layer = h_fc2,suffixes=train_suffixes,COMMON=False, DEC_PREFX= False):\n",
    "  \n",
    "  print(\"PRINTING PURE RULES WITH SUPPORT MORE THAN 1000 FOR EVERY LABEL:\");\n",
    "  for cl, invs in all_invariants.items():\n",
    "    if (cl == -1):\n",
    "      continue\n",
    "    \n",
    "    for indx in range (0, 5):\n",
    "    #len(invs)):\n",
    "      inv = invs[indx]\n",
    "      cls = get_suffix_cluster(inv[0],inv[1],suffixes)\n",
    "      \n",
    "      neurons = inv[0]\n",
    "      signature = inv[1]\n",
    "\n",
    "      if (len(cls) <= 1000):\n",
    "        continue\n",
    "      print(\"Class:\", cl, \", Rule:(neurons:\",inv[0],\",signature:\",inv[1],\"), Support:\",inv[2],\", Num misclassified\", len([i for i in cls if is_misclassified(i)]));\n",
    "\n",
    "      ##invoke_marabou_chk(LAYER,neurons,signature,cl)\n",
    "\n",
    "      if (COMMON == True):\n",
    "          common_nodes(cls,suffixes)\n",
    "\n",
    "      if (DEC_PREFX == True):\n",
    "          decision_prefs(cls,suffixes)\n",
    "\n",
    "  return\n",
    "  \n",
    "def common_nodes(cls,suffixes):\n",
    "    cnt = 0\n",
    "    common = np.zeros(10,dtype=int)\n",
    "    prev = np.zeros(10,dtype=int)\n",
    "    \n",
    "    for indx in range(0, len(cls)):\n",
    "        i = cls[indx]\n",
    "        cnt = cnt + 1\n",
    "        for j in range(0,len(suffixes[i])):\n",
    "          if (common[j] == -1):\n",
    "             continue\n",
    "          if ((indx != 0) and (suffixes[i][j] != prev[j])):\n",
    "             common[j] = -1\n",
    "          else:\n",
    "             common[j] = suffixes[i][j]\n",
    "          prev[j] = suffixes[i][j]\n",
    "\n",
    "\n",
    "    print('COMMON NODES IN CLUSTER for CLASS:',cl,cnt)\n",
    "    com = []\n",
    "    for k in range(0,len(common)):\n",
    "        if (common[k] != -1):\n",
    "           com.append((k,common[k]))\n",
    "    print(com)\n",
    "\n",
    "    return\n",
    "    \n",
    "def decision_prefs(cls,suffixes):\n",
    "    images = mnist.train.images\n",
    "    imgsCom = []\n",
    "    imgs = []\n",
    "    for indx in range(0, len(cls)):\n",
    "        print('IMG:')\n",
    "        print(list(zip(images[cls[indx]])))\n",
    "        imgs.append(images[cls[indx]])\n",
    "        imgsCom.append(images[cls[indx]])\n",
    "            \n",
    "    dec_prefixes= fingerprint_signature(imgs,layer)\n",
    "    prefixes = []\n",
    "    for indx in range(0,len(dec_prefixes)):\n",
    "       dec_pref = dec_prefixes[indx]\n",
    "    \n",
    "       match = 0\n",
    "       for indx1 in range(0, len(prefixes)):\n",
    "          match = 1\n",
    "          for i in range(0,len(prefixes[indx1])):\n",
    "             if (dec_pref[i] != prefixes[indx1][i]):\n",
    "                match = 0\n",
    "                break\n",
    "          if (match == 1):\n",
    "             break\n",
    "    \n",
    "       if (match == 0):\n",
    "          prefixes.append(dec_pref)\n",
    "    \n",
    "    print('DECISION PREFIXES IN CLUSTER for CLASS:',cl,cnt)\n",
    "    for k in range(0,len(prefixes)):\n",
    "      print(prefixes[k])\n",
    "\n",
    "    return\n",
    "    \n",
    "  \n",
    "  #print('LAYER INPS:')\n",
    "  #min = np.zeros(10)\n",
    "  #max = np.zeros(10)\n",
    "  #for dim in range(0,10):\n",
    "  #    min[dim] = 1000\n",
    "  #    max[dim] = -1000\n",
    "          \n",
    "  #prevlayer_vals = get_prediction(imgsCom,prevlayer)      \n",
    "  #print('MIN, MAX LAYER INPS:',len(prevlayer_vals))\n",
    "  #for i in range(0,len(prevlayer_vals)):\n",
    "  #    if (i == 0):\n",
    "  #      print(zip(prevlayer_vals[i]))\n",
    "  #    for dim in range(0,10):\n",
    "  #        if ( prevlayer_vals[i][dim] < min[dim]):\n",
    "  #            min[dim] = prevlayer_vals[i][dim]\n",
    "  #        if ( prevlayer_vals[i][dim] > max[dim]):\n",
    "  #            max[dim] = prevlayer_vals[i][dim]\n",
    "    \n",
    "  #print('MIN')\n",
    "  #print(zip(min))\n",
    "  #print('MAX')\n",
    "  #print(zip(max))    \n",
    "    \n",
    "  #df = pd.DataFrame(df, columns=['Prediction Class', 'Num Instances', 'Num Invariants', 'Num Invariants with cluster size >= 10', 'Size of largest invariant cluster'])\n",
    "  #df = pd.DataFrame(df,columns=['Pred Class','Total #Neurons','# Invariants'])\n",
    "  #return df\n",
    "\n",
    "\n",
    "def describe_all_invariants(all_invariants):\n",
    "  df = []\n",
    "  for cl, invs in all_invariants.iteritems(): \n",
    "    inv = invs[0]\n",
    "    clus = get_suffix_cluster(inv[0],inv[1])\n",
    "    #print(len(clus))\n",
    "    misCl = 0\n",
    "    for i in range(0,len(clus)):\n",
    "      indx = clus[i]\n",
    "      if (is_misclassified(indx) == True):\n",
    "        misCl = misCl + 1\n",
    "    print('class:',cl,',masSup:',inv[2],',#misCl:',misCl)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUrTEpB-eExO"
   },
   "source": [
    "## Property Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOb6B40teTml"
   },
   "outputs": [],
   "source": [
    "def property_membership(pr):\n",
    "  inputsProp = []\n",
    "  for i in range(0,len(acas_train)):\n",
    "      inp = acas_train[i]\n",
    "      if ((pr == 6) and ((inp[0] < -0.12929) or (inp[0] > 0.700435))):#p6\n",
    "          continue\n",
    "      if ((pr == 10) and ((inp[0] < 0.268978) or (inp[0] > 0.679858))):#p10\n",
    "          continue\n",
    "      if ((pr == 9) and ((inp[0] < -0.29523) or (inp[0] > -0.21226))):#p9\n",
    "          continue\n",
    "      if ((pr == 5) and ((inp[0] < -0.32427) or (inp[0] > -0.32179))):#p5\n",
    "          continue\n",
    "      if ((pr == 8) and ((inp[0] < -0.32842) or (inp[0] > 0.679858))):#p8\n",
    "          continue\n",
    "      if ((pr == 7) and ((inp[0] < -0.32842) or (inp[0] > 0.679858))):#p7\n",
    "          continue\n",
    "      if (((pr == 2) or (pr == 1)) and ((inp[0] < 0.6) or (inp[0] > 0.679858))):#p2, p1\n",
    "          continue\n",
    "      #if ((inp[0] < 0.6) or (inp[0] > 0.679858) ):#p2a\n",
    "      if ((pr == 4) and ((inp[0] < -0.30353) or (inp[0] > -0.29855))):#p4\n",
    "          continue\n",
    "\n",
    "      \n",
    "      if ((pr == 6) and ((inp[1] < -0.5) or (inp[1] > -0.11141))):#p6\n",
    "          continue\n",
    "      if ((pr == 10) and ((inp[1] < 0.111408) or (inp[1] > 0.499999))):#p10\n",
    "          continue\n",
    "      if ((pr == 9) and ((inp[1] < -0.06366) or (inp[1] > -0.02228))):#p9\n",
    "          continue\n",
    "      if ((pr == 5) and ((inp[1] < 0.031831) or (inp[1] > 0.063662))):#p5\n",
    "          continue\n",
    "      if ((pr == 8) and ((inp[1] < -0.5) or (inp[1] > -0.375))):#p8\n",
    "          continue\n",
    "      if ((pr == 7) and ((inp[1] < -0.5) or (inp[1] > 0.499999))):#p7\n",
    "          continue\n",
    "      if (((pr == 2) or (pr == 1)) and ((inp[1] < -0.5) or (inp[1] > 0.5 ))):#p2, p1\n",
    "          continue\n",
    "      #if ((inp[0] < 0.6) or (inp[0] > 0.679858) ):#p2a\n",
    "      if ((pr == 4) and ((inp[1] < -0.00955) or (inp[1] > 0.009549 ))):#p4\n",
    "          continue\n",
    "\n",
    "\n",
    "      if ((pr == 6) and ((inp[2] < -0.5) or (inp[2] > -0.4992))):#p6\n",
    "          continue\n",
    "      if ((pr == 10) and ((inp[2] < -0.5) or (inp[2] > -0.49841))):#p10\n",
    "          continue\n",
    "      if ((pr == 9) and ((inp[2] < -0.5) or (inp[2] > -0.49841))):#p9\n",
    "          continue\n",
    "      if ((pr == 5) and ((inp[2] < -0.5) or (inp[2] > -0.4992) )):#p5\n",
    "          continue\n",
    "      if ((pr == 8) and ((inp[2] < -0.01592) or (inp[2] > 0.015915))):#p8\n",
    "          continue\n",
    "      if ((pr == 7) and ((inp[2] < -0.5) or (inp[2] > 0.499999) )):#p7\n",
    "          continue\n",
    "      if (((pr == 2) or (pr == 1)) and ((inp[2] < -0.5) or (inp[2] > 0.5) )):#p2, p1\n",
    "          continue\n",
    "      #if ((inp[0] < 0.6) or (inp[0] > 0.679858) ):#p2a\n",
    "      if ((pr == 4) and ((inp[2] < 0.493379))):#p4\n",
    "          continue\n",
    "\n",
    "\n",
    "      if ((pr == 6) and ((inp[3] < -0.5) or (inp[3] > 0.5))):#p6\n",
    "          continue\n",
    "      if ((pr == 10) and ((inp[3] < 0.227273) or (inp[3] > 0.5))):#p10\n",
    "          continue\n",
    "      if ((pr == 9) and ((inp[3] < -0.5) or (inp[3] > -0.45455))):#p9\n",
    "          continue\n",
    "      if ((pr == 5) and ((inp[3] < -0.5) or (inp[3] > -0.22727) )):#p5\n",
    "          continue\n",
    "      if ((pr == 8) and ((inp[3] < -0.045) or (inp[3] > 0.5))):#p8\n",
    "          continue\n",
    "      if ((pr == 7) and ((inp[3] < -0.5) or (inp[3] > 0.5))):#p7\n",
    "          continue\n",
    "      if (((pr == 2) or (pr == 1)) and ((inp[3] < 0.45) or (inp[3] > 0.5))):#p2, p1\n",
    "          continue\n",
    "      #if ((inp[0] < 0.6) or (inp[0] > 0.679858) ):#p2a\n",
    "      if ((pr == 4) and (inp[3] < 0.3 )):#p4\n",
    "          continue\n",
    "\n",
    "      if ((pr == 6) and ((inp[4] < -0.5) or (inp[4] > 0.5))):#p6\n",
    "          continue\n",
    "      if ((pr == 10) and ((inp[4] < 0) or (inp[4] > 0.5) )):#p10\n",
    "          continue\n",
    "      if ((pr == 9) and ((inp[4] < -0.5) or (inp[4] > -0.375))):#p9\n",
    "          continue\n",
    "      if ((pr == 5) and ((inp[4] < -0.5) or (inp[4] > -0.16667))):#p5\n",
    "          continue\n",
    "      if ((pr == 8) and ((inp[4] < 0.0) or (inp[4] > 0.5))):#p8\n",
    "          continue\n",
    "      if ((pr == 7) and ((inp[4] < -0.5) or (inp[4] > 0.5) )):#p7\n",
    "          continue\n",
    "      if (((pr == 2) or (pr == 1)) and ((inp[4] < -0.5) or (inp[4] > -0.45))):#p2, p1\n",
    "          continue\n",
    "      #if ((inp[0] < 0.6) or (inp[0] > 0.679858) ):#p2a\n",
    "      if ((pr == 4) and (inp[4] < 0.3 )):#p4\n",
    "          continue\n",
    "\n",
    "      inputsProp.append(i)\n",
    "\n",
    "  return inputsProp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwnyRdyFeEWL"
   },
   "outputs": [],
   "source": [
    "def property_chk(full,pr,label,all_invariants,prop_minIn,prop_maxIn,lay=LAYER,suffixes=train_suffixes):\n",
    "  \n",
    "  inputsProp = property_membership(pr)\n",
    "  print(\"\\n \\n Property:\" + str(pr), \",A => \" + str(label))\n",
    "  print('INPUTS WITHIN A:', len(inputsProp))\n",
    "\n",
    "  df = []\n",
    "  \n",
    "  images = acas_train\n",
    "  imgsCom = []\n",
    "  tot = 0\n",
    "  notCovered = inputsProp\n",
    "  notCov = []\n",
    "  for cl, invs in all_invariants.items():\n",
    "    \n",
    "    if (cl != label):\n",
    "      continue\n",
    "    #print(cl, len(invs))\n",
    "   \n",
    "    cnt = 0\n",
    "    \n",
    "    for invariant in invs:\n",
    "        cls = get_suffix_cluster(invariant[0],invariant[1],suffixes)\n",
    "        \n",
    "        lst3 = [value for value in inputsProp if value in cls]\n",
    "        withinAcnt = len(lst3)\n",
    "        notCovered = list(set(notCovered) - set(lst3))\n",
    "       \n",
    "        if (withinAcnt > 100):\n",
    "            print('INVARIANT:' , invariant[0], invariant[1])\n",
    "            print('SUPPORT:' , invariant[2], ', A SUPPORT:', withinAcnt)\n",
    "            \n",
    "            minI = np.zeros(5)\n",
    "            maxI = np.zeros(5)\n",
    "            for ind in range(0,5):\n",
    "                minI[ind] = 1000\n",
    "                maxI[ind] = -1000\n",
    "            \n",
    "            imgs = []\n",
    "            #print('COVERED:')\n",
    "            for indx in range(0,len(lst3)):\n",
    "                index = lst3[indx]\n",
    "                img = acas_train[index]\n",
    "                imgs.append(img)\n",
    "                #print(list(img))\n",
    "                for ind in range(0,5):\n",
    "                  if (img[ind] < minI[ind]):\n",
    "                      minI[ind] = img[ind]\n",
    "                  if (img[ind] > maxI[ind]):\n",
    "                      maxI[ind] = img[ind] \n",
    "            \n",
    "            #print('INP MIN,MAX covered:')\n",
    "            #print(list(minI))\n",
    "            #print(list(maxI))\n",
    "      \n",
    "            if (len(notCovered) > 0):\n",
    "              for ind in range(0,5):\n",
    "                minI[ind] = 1000\n",
    "                maxI[ind] = -1000\n",
    "              #print('NOT COVERED:')\n",
    "              for indx in range(0,len(notCovered)):\n",
    "                index = notCovered[indx]\n",
    "                img = acas_train[index]\n",
    "                #print(list(img))\n",
    "              for ind in range(0,5):\n",
    "                if (img[ind] < minI[ind]):\n",
    "                  minI[ind] = img[ind]\n",
    "                if (img[ind] > maxI[ind]):\n",
    "                  maxI[ind] = img[ind] \n",
    "              #print('INP MIN,MAX not covered:')\n",
    "              #print(list(minI))\n",
    "              #print(list(maxI))\n",
    "\n",
    "\n",
    "            # Get the min,max before the layer\n",
    "            minIn =[]\n",
    "            maxIn = []\n",
    "            for ind in range(0,50):\n",
    "               minIn.append(1000)\n",
    "               maxIn.append(-1000)\n",
    "\n",
    "            layer_vals = get_prediction(imgs,h_fc5)      \n",
    "            #print('MIN, MAX LAYER INPS:',len(layer_vals))\n",
    "            for i in range(0,len(layer_vals)):\n",
    "                  for dim in range(0,50):\n",
    "                           if ( layer_vals[i][dim] < minIn[dim]):\n",
    "                                         minIn[dim] = layer_vals[i][dim]\n",
    "                           if ( layer_vals[i][dim] > maxIn[dim]):\n",
    "                                         maxIn[dim] = layer_vals[i][dim]\n",
    "    \n",
    "            #print('INP MIN,MAX PREV LAYER:')\n",
    "            #print(list(minIn))\n",
    "            #print(list(maxIn))\n",
    "  \n",
    "            \n",
    "            sig = []\n",
    "            for dim in range(0,50):\n",
    "                if (layer_vals[0][dim] == 0):\n",
    "                  sig.append(0)\n",
    "                else:\n",
    "                  sig.append(1)\n",
    "                \n",
    "\n",
    "            for i in range(1,len(layer_vals)):\n",
    "                #print(layer_vals[i][0],layer_vals[i][47],layer_vals[i][48] )\n",
    "                for dim in range(0,50):\n",
    "                  if (sig[dim] == -1):\n",
    "                    continue\n",
    "                  if ((layer_vals[i][dim] > 0) and (sig[dim] == 0)):\n",
    "                      sig[dim] = -1\n",
    "                      continue\n",
    "                  if ((layer_vals[i][dim] == 0) and (sig[dim] == 1)):\n",
    "                      sig[dim] = -1\n",
    "                      continue\n",
    "\n",
    "            #print(\"COMMON SIGNATURE:\")\n",
    "            #for dim in range(0,50):\n",
    "            #  if (sig[dim] != -1):\n",
    "            #      print(\"index:\" + str(dim) + \"=\" + str(sig[dim]))\n",
    "            \n",
    "            if(full == True):\n",
    "              print(\"\\n CHECK A => B on full network\")\n",
    "              invoke_marabou_chk(label,prop_minIn,prop_maxIn) \n",
    "              break\n",
    "\n",
    "            neurons = invariant[0]\n",
    "            signature = invariant[1]\n",
    "            \n",
    "            prov = False\n",
    "            print(\"\\n CHECK I /\\ covered_consts on short network => B\") ## UPDATE notCov\n",
    "            prov = invoke_marabou_chk_1(lay,neurons,signature,label,minIn,maxIn,sig) ## I => LABEL\n",
    " \n",
    "            if (prov == True):\n",
    "                print(\"\\n CHECK I /\\ covered_consts on short network => B, PROVED \")\n",
    "                notCovStrs = []\n",
    "                notCovStrs.append(notCov)\n",
    "                for i in range(0,len(neurons)):\n",
    "                  strChk = \"ws_\"+ str(lay) + \"_\" + str(neurons[i])\n",
    "                  if (strChk in notCovStrs):\n",
    "                    notCov.remove(notCovstr)\n",
    "                \n",
    "                print(\"\\n CHECK A  => I \") ## COLLECT NOT COVERED CONSTRAINTS\n",
    "                notCov.append(invoke_marabou_chk_2(lay,neurons,signature,prop_minIn,prop_maxIn)) \n",
    "\n",
    "            if (len(notCov) == 0):\n",
    "              print(\"\\n A => I proved.\")   \n",
    "              print(\"\\n PROPERTY A => B proved!\")    \n",
    "              break\n",
    "\n",
    "    print(\"\\n A => I proved.\")   \n",
    "    print(\"\\n PROPERTY A => B proved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 832
    },
    "colab_type": "code",
    "id": "aBK9KWLc6TSe",
    "outputId": "d76516d6-f8fb-4f77-cfbb-be7535b2c0ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-28 19:19:40--  https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/marabou_DnC_InternalNodes.elf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.24.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.24.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14808728 (14M) [application/octet-stream]\n",
      "Saving to: ‘./marabou_DnC_InternalNodes.elf’\n",
      "\n",
      "./marabou_DnC_Inter 100%[===================>]  14.12M  7.37MB/s    in 1.9s    \n",
      "\n",
      "2020-07-28 19:19:42 (7.37 MB/s) - ‘./marabou_DnC_InternalNodes.elf’ saved [14808728/14808728]\n",
      "\n",
      "--2020-07-28 19:19:42--  https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.24.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.24.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 167553 (164K) [text/plain]\n",
      "Saving to: ‘./ACASXU_run2a_1_1_batch_2000.nnet’\n",
      "\n",
      "./ACASXU_run2a_1_1_ 100%[===================>] 163.63K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-07-28 19:19:43 (1.57 MB/s) - ‘./ACASXU_run2a_1_1_batch_2000.nnet’ saved [167553/167553]\n",
      "\n",
      "--2020-07-28 19:19:43--  https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/ACASXU_run2a_1_2_batch_fc5.nnet\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.24.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.24.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68527 (67K) [text/plain]\n",
      "Saving to: ‘./ACASXU_run2a_1_2_batch_fc5.nnet’\n",
      "\n",
      "./ACASXU_run2a_1_2_ 100%[===================>]  66.92K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2020-07-28 19:19:44 (1.06 MB/s) - ‘./ACASXU_run2a_1_2_batch_fc5.nnet’ saved [68527/68527]\n",
      "\n",
      "--2020-07-28 19:19:44--  https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/ACASXU_run2a_1_2_batch_fc5OP.nnet\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.24.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.24.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 36367 (36K) [text/plain]\n",
      "Saving to: ‘./ACASXU_run2a_1_2_batch_fc5OP.nnet’\n",
      "\n",
      "./ACASXU_run2a_1_2_ 100%[===================>]  35.51K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2020-07-28 19:19:44 (918 KB/s) - ‘./ACASXU_run2a_1_2_batch_fc5OP.nnet’ saved [36367/36367]\n",
      "\n",
      "/home/burak/nasa-neural-properties/prophecy-acasx\n",
      "-rw-rw-r-- 1 burak burak 14808728 Jul 28 19:19 ./marabou_DnC_InternalNodes.elf\n",
      "-rwxrwxrwx 1 burak burak 14808728 Jul 28 19:19 ./marabou_DnC_InternalNodes.elf\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/marabou_DnC_InternalNodes.elf -O ./marabou_DnC_InternalNodes.elf\n",
    "!wget https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/ACASXU_run2a_1_1_batch_2000.nnet -O ./ACASXU_run2a_1_1_batch_2000.nnet\n",
    "!wget https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/ACASXU_run2a_1_2_batch_fc5.nnet -O ./ACASXU_run2a_1_2_batch_fc5.nnet\n",
    "!wget https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/ACASXU_run2a_1_2_batch_fc5OP.nnet -O ./ACASXU_run2a_1_2_batch_fc5OP.nnet\n",
    "!pwd\n",
    "!ls -lt ./marabou_DnC_InternalNodes.elf\n",
    "!chmod 777 ./marabou_DnC_InternalNodes.elf\n",
    "!ls -lt ./marabou_DnC_InternalNodes.elf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfQqEF2M96T4"
   },
   "outputs": [],
   "source": [
    "## A => B WITH FULL NETWORK\n",
    "def invoke_marabou_chk(label,inp_min,inp_max):\n",
    "\n",
    "  for lab_indx in range(0,5):\n",
    "    if (lab_indx == label):\n",
    "      continue\n",
    "\n",
    "    not_done = False\n",
    "    strInp = \"\"\n",
    "   \n",
    "    for i in range(0,5):\n",
    "          strInp = strInp + \"x\"+ str(i) + \" >= \" + str(inp_min[i]) + \"\\n\"\n",
    "          strInp = strInp + \"x\"+ str(i) + \" <= \" + str(inp_max[i]) + \"\\n\"\n",
    "    #print(strInp)\n",
    "\n",
    "    strInternal = \"\"\n",
    "    #for i in range(0,len(neurons)):\n",
    "    #    strInternal = strInternal + \"ws_\"+ str(layer) + \"_\" + str(neurons[i])\n",
    "    #    if (signature[i] == 0):\n",
    "    #       strInternal = strInternal + \" <= 0.0\" + \"\\n\"\n",
    "    #    else:\n",
    "    #       strInternal = strInternal + \" >= 0.0\"  + \"\\n\"\n",
    "      \n",
    "    strOP = \"+y\"+ str(lab_indx) + \" -y\" + str(label) + \" <= -0.001\" + \"\\n\"\n",
    "\n",
    "    #Write to a property file\n",
    "    file1 = open('property.txt',\"w\")\n",
    "    file1.writelines(strInp) \n",
    "    #file1.writelines(strInternal) \n",
    "    file1.writelines(strOP) \n",
    "    file1.close() \n",
    "\n",
    "    file1 = open('property.txt',\"r\")  \n",
    "    print(\"PROPERTY FILE IS \")\n",
    "    print(file1.read())\n",
    "    file1.close()\n",
    "\n",
    "    #!./marabou_DnC_InternalNodes.elf ./ACASXU_run2a_1_1_batch_2000.nnet ./property.txt --dnc --num-workers=4 --summary-file=summary1.txt\n",
    "    !./marabou_DnC_InternalNodes.elf ./ACASXU_run2a_1_1_batch_2000.nnet ./property.txt --summary-file=summary1.txt --verbosity=0\n",
    "  \n",
    "    print(\"SUMMARY:\")\n",
    "    f = open('summary1.txt', 'r')\n",
    "    file_contents = f.read()\n",
    "    print (file_contents)\n",
    "    f.close()\n",
    "    if (file_contents.find('UNSAT') == -1):\n",
    "        not_done = True\n",
    "        break\n",
    "       \n",
    "  if (not_done == False):\n",
    "     print(\"Property proved!\")\n",
    "     return True\n",
    "  else:\n",
    "     print (\"PROPERTY COULD NOT BE PROVED:\")\n",
    "     return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qgWmhNqpyzec"
   },
   "outputs": [],
   "source": [
    "## I => B WITH STRIPPED NETWORK\n",
    "def invoke_marabou_chk_1(layer,neurons,signature,label,inp_min = [],inp_max = [], com_sig = [], notCov = []):\n",
    "  #layer = 1\n",
    "  #neurons = [4, 8, 7, 1, 0, 2, 5, 3, 9, 6] \n",
    "  #signature = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  #label = 6\n",
    " propsig = True\n",
    " not_done = True\n",
    " comsig = False\n",
    " while( (not_done == True) and (comsig == False)):\n",
    "  \n",
    "  for lab_indx in range(0,5):\n",
    "    if (lab_indx == label):\n",
    "      continue\n",
    "\n",
    "    not_done = False\n",
    "    strInp = \"\"\n",
    "    if (len(inp_min) > 0):\n",
    "      for i in range(0,50):\n",
    "          strInp = strInp + \"x\"+ str(i) + \" >= \" + str(inp_min[i]) + \"\\n\"\n",
    "          strInp = strInp + \"x\"+ str(i) + \" <= \" + str(inp_max[i]) + \"\\n\"\n",
    "    #print(strInp)\n",
    "\n",
    "    strInternal = \"\"\n",
    "    if (propsig == True):\n",
    "      for i in range(0,len(neurons)):\n",
    "        strInternal = strInternal + \"ws_\"+ str(1) + \"_\" + str(neurons[i])\n",
    "        if (signature[i] == 0):\n",
    "           strInternal = strInternal + \" <= 0.0\" + \"\\n\"\n",
    "        else:\n",
    "           strInternal = strInternal + \" >= 0.0\"  + \"\\n\"\n",
    "      propsig = False\n",
    "    else:\n",
    "      for dim in range(0,len(com_sig)):\n",
    "        if (com_sig[dim] == -1):\n",
    "          continue\n",
    "        strInternal = strInternal + \"ws_\"+ str(1) + \"_\" + str(dim)\n",
    "        if (com_sig[dim] == 0):\n",
    "           strInternal = strInternal + \" <= 0.0\" + \"\\n\"\n",
    "        else:\n",
    "           strInternal = strInternal + \" >= 0.0\"  + \"\\n\"\n",
    "      comsig = True\n",
    "\n",
    "    strOP = \"+y\"+ str(lab_indx) + \" -y\" + str(label) + \" <= -0.001\" + \"\\n\"\n",
    "\n",
    "    #Write to a property file\n",
    "    file1 = open('property.txt',\"w\")\n",
    "    file1.writelines(strInp) \n",
    "    #file1.writelines(strInternal) \n",
    "    file1.writelines(strOP) \n",
    "    file1.close() \n",
    "\n",
    "    file1 = open('property.txt',\"r\")  \n",
    "    print(\"PROPERTY FILE IS \")\n",
    "    print(file1.read())\n",
    "    file1.close()\n",
    "\n",
    "    #!./marabou_DnC_InternalNodes.elf ./ACASXU_run2a_1_1_batch_2000.nnet ./property.txt --dnc --num-workers=4 --summary-file=summary1.txt\n",
    "    print(\"\\n I /\\ label=\", str(lab_indx))\n",
    "    !./marabou_DnC_InternalNodes.elf ./ACASXU_run2a_1_2_batch_fc5OP.nnet ./property.txt --summary-file=summary1.txt --verbosity=0\n",
    "    \n",
    "    print(\"SUMMARY:\")\n",
    "    f = open('summary1.txt', 'r')\n",
    "    file_contents = f.read()\n",
    "    print (file_contents)\n",
    "    f.close()\n",
    "    if (file_contents.find('UNSAT') == -1):\n",
    "        not_done = True\n",
    "        break\n",
    "       \n",
    " if (not_done == False):\n",
    "   print(\"Property proved!\")\n",
    "   return True\n",
    " else:\n",
    "   print (\"PROPERTY COULD NOT BE PROVED:\")\n",
    "   return False\n",
    "  \n",
    "  #f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pL08iQBNXewm"
   },
   "outputs": [],
   "source": [
    "# A => I\n",
    "def invoke_marabou_chk_2(layer,neurons,signature,inp_min,inp_max):\n",
    " \n",
    "    strInp = \"\"\n",
    "    for i in range(0,5):\n",
    "          strInp = strInp + \"x\"+ str(i) + \" >= \" + str(inp_min[i]) + \"\\n\"\n",
    "          strInp = strInp + \"x\"+ str(i) + \" <= \" + str(inp_max[i]) + \"\\n\"\n",
    "    #print(strInp)\n",
    "\n",
    "    strInternals = []\n",
    "    for i in range(0,len(neurons)):\n",
    "        strInternal = \"ws_\"+ str(layer) + \"_\" + str(neurons[i])\n",
    "        if (signature[i] == 0):\n",
    "           strInternal = strInternal + \" >= 0.0\" + \"\\n\"\n",
    "        else:\n",
    "           strInternal = strInternal + \" <= 0.0\"  + \"\\n\"\n",
    "        strInternals.append(strInternal)\n",
    "\n",
    "    notCov = []\n",
    "    for strInternal in strInternals:\n",
    "      #Write to a property file\n",
    "      file1 = open('property.txt',\"w\")\n",
    "      file1.writelines(strInp) \n",
    "      file1.writelines(strInternal) \n",
    "      file1.close() \n",
    "\n",
    "      file1 = open('property.txt',\"r\")  \n",
    "      print(\"PROPERTY FILE IS \")\n",
    "      print(file1.read())\n",
    "      file1.close()\n",
    "      print(\"\\n CHECK A /\\ not(I) \")\n",
    "      !./marabou_DnC_InternalNodes.elf ./ACASXU_run2a_1_1_batch_2000.nnet ./property.txt --summary-file=summary1.txt --verbosity=0\n",
    "\n",
    "      print(\"SUMMARY:\")\n",
    "      f = open('summary1.txt', 'r')\n",
    "      file_contents = f.read()\n",
    "      print (file_contents)\n",
    "      f.close()\n",
    "      if (file_contents.find('UNSAT') == -1):\n",
    "         notCov.append(strInternal)\n",
    "\n",
    "    return notCov\n",
    "  #f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KOUniL-T5-Sa",
    "outputId": "756bb581-01df-4403-850b-ae18a3b1a693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9109/9109 [00:00<00:00, 1193300.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained all paths\n",
      "PRINTING PURE RULES WITH SUPPORT MORE THAN 1000 FOR EVERY LABEL:\n",
      "Class: 4 , Rule:(neurons: [41, 21, 36, 32, 8, 5, 10, 16, 47, 0, 7, 37, 28, 20] ,signature: [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1] ), Support: 2133 , Num misclassified 1851\n",
      "Class: 4 , Rule:(neurons: [41, 0, 20, 46, 5, 16, 3, 38, 40, 17, 28] ,signature: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1] ), Support: 2056 , Num misclassified 1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 4 , Rule:(neurons: [41, 0, 20, 46, 5, 16, 3, 38, 40, 17, 28, 27, 49, 37] ,signature: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1] ), Support: 1199 , Num misclassified 1009\n",
      "Class: 3 , Rule:(neurons: [41, 21, 36, 20, 10, 28, 32, 13, 47, 37, 15, 8, 33, 16] ,signature: [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1] ), Support: 2097 , Num misclassified 1807\n",
      "Class: 0 , Rule:(neurons: [41, 21, 2, 40, 43, 9, 33, 22, 26, 27, 34, 3, 8, 42, 4, 15, 20, 23, 37, 45] ,signature: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ), Support: 109147 , Num misclassified 0\n",
      "Class: 0 , Rule:(neurons: [41, 21, 2, 40, 43, 9, 33, 22, 26, 27, 34, 3, 8, 42, 4, 15, 20, 23] ,signature: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1] ), Support: 58070 , Num misclassified 4\n",
      "Class: 0 , Rule:(neurons: [41, 21, 2, 40, 43, 9, 33, 22, 26, 27, 34, 3, 8, 42, 4, 15, 20, 23, 37, 45, 31] ,signature: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] ), Support: 9977 , Num misclassified 17\n",
      "Class: 0 , Rule:(neurons: [41, 21, 2, 40, 43, 9, 33, 22, 26, 27, 34, 3, 8, 42, 4, 15, 31] ,signature: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] ), Support: 8950 , Num misclassified 23\n",
      "Class: 0 , Rule:(neurons: [41, 21, 2, 40, 43, 9, 33, 22, 26, 27, 34, 3, 8, 42, 20] ,signature: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0] ), Support: 7424 , Num misclassified 3\n",
      "Class: 2 , Rule:(neurons: [41, 0, 20, 46, 8, 43, 48, 3, 15, 5, 21, 28, 45, 34, 29, 32, 17, 31] ,signature: [1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1] ), Support: 1324 , Num misclassified 1167\n",
      "CHECK PROPERTY: 10\n",
      "REGION A:\n",
      "[0.268978, 0.111408, -0.5, 0.227273, 0.0]\n",
      "[0.679858, 0.499999, -0.49841, 0.5, 0.5]\n",
      "LABEL B: 0\n",
      "CHECK A => B on full network:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 133.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Property:10 ,A => 0\n",
      "INPUTS WITHIN A: 195\n",
      "INVARIANT: [41, 21, 2, 40, 43, 9, 33, 22, 26, 27, 34, 3, 8, 42, 4, 15, 20, 23, 37, 45] [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "SUPPORT: 109147 , A SUPPORT: 195\n",
      "\n",
      " CHECK A => B on full network\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "+y1 -y0 <= -0.001\n",
      "\n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 221 520 120\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "+y2 -y0 <= -0.001\n",
      "\n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 202 486 115\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "+y3 -y0 <= -0.001\n",
      "\n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 226 566 115\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "+y4 -y0 <= -0.001\n",
      "\n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 324 714 127\n",
      "\n",
      "Property proved!\n",
      "\n",
      " A => I proved.\n",
      "\n",
      " PROPERTY A => B proved!\n",
      "TIME FOR A => B on full network: 976.6421120166779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 161.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Property:10 ,A => 0\n",
      "INPUTS WITHIN A: 195\n",
      "INVARIANT: [41, 21, 2, 40, 43, 9, 33, 22, 26, 27, 34, 3, 8, 42, 4, 15, 20, 23, 37, 45] [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "SUPPORT: 109147 , A SUPPORT: 195\n",
      "\n",
      " CHECK I /\\ covered_consts on short network => B\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.0\n",
      "x0 <= 0.4879558\n",
      "x1 >= 0.0\n",
      "x1 <= 0.0\n",
      "x2 >= 0.0\n",
      "x2 <= 0.0\n",
      "x3 >= 0.0\n",
      "x3 <= 0.0\n",
      "x4 >= 0.0\n",
      "x4 <= 0.0\n",
      "x5 >= 0.0\n",
      "x5 <= 0.0\n",
      "x6 >= 0.0\n",
      "x6 <= 0.0\n",
      "x7 >= 0.0\n",
      "x7 <= 0.0\n",
      "x8 >= 0.0\n",
      "x8 <= 0.0\n",
      "x9 >= 0.0\n",
      "x9 <= 0.0\n",
      "x10 >= 1.7928456\n",
      "x10 <= 3.7465637\n",
      "x11 >= 0.0\n",
      "x11 <= 0.0\n",
      "x12 >= 0.0\n",
      "x12 <= 0.0\n",
      "x13 >= 0.0\n",
      "x13 <= 0.0\n",
      "x14 >= 0.0\n",
      "x14 <= 0.0\n",
      "x15 >= 0.0\n",
      "x15 <= 0.0\n",
      "x16 >= 0.0\n",
      "x16 <= 0.0\n",
      "x17 >= 0.0\n",
      "x17 <= 0.0\n",
      "x18 >= 0.0\n",
      "x18 <= 0.0\n",
      "x19 >= 0.0\n",
      "x19 <= 0.0\n",
      "x20 >= 0.0\n",
      "x20 <= 0.0\n",
      "x21 >= 0.0\n",
      "x21 <= 0.0\n",
      "x22 >= 0.0\n",
      "x22 <= 0.0\n",
      "x23 >= 0.0\n",
      "x23 <= 0.0\n",
      "x24 >= 0.0\n",
      "x24 <= 0.0\n",
      "x25 >= 3.0954623\n",
      "x25 <= 5.6651177\n",
      "x26 >= 0.0\n",
      "x26 <= 0.0\n",
      "x27 >= 0.0\n",
      "x27 <= 0.0\n",
      "x28 >= 0.0\n",
      "x28 <= 0.0\n",
      "x29 >= 0.0\n",
      "x29 <= 0.0\n",
      "x30 >= 0.0\n",
      "x30 <= 0.0\n",
      "x31 >= 0.0\n",
      "x31 <= 0.17363238\n",
      "x32 >= 0.0\n",
      "x32 <= 0.0\n",
      "x33 >= 4.986863\n",
      "x33 <= 9.182409\n",
      "x34 >= 0.0\n",
      "x34 <= 0.0\n",
      "x35 >= 0.0\n",
      "x35 <= 0.0\n",
      "x36 >= 0.0\n",
      "x36 <= 0.0\n",
      "x37 >= 0.0\n",
      "x37 <= 0.0\n",
      "x38 >= 0.0\n",
      "x38 <= 0.0\n",
      "x39 >= 0.0\n",
      "x39 <= 0.0\n",
      "x40 >= 0.0\n",
      "x40 <= 0.0\n",
      "x41 >= 0.0\n",
      "x41 <= 0.0\n",
      "x42 >= 0.0\n",
      "x42 <= 0.0\n",
      "x43 >= 0.0\n",
      "x43 <= 0.0\n",
      "x44 >= 0.0\n",
      "x44 <= 0.0\n",
      "x45 >= 0.0\n",
      "x45 <= 0.0\n",
      "x46 >= 2.041381\n",
      "x46 <= 4.108132\n",
      "x47 >= 0.0\n",
      "x47 <= 1.0279948\n",
      "x48 >= 0.0\n",
      "x48 <= 2.1200972\n",
      "x49 >= 0.0\n",
      "x49 <= 0.0\n",
      "+y1 -y0 <= -0.001\n",
      "\n",
      "\n",
      " I /\\ label= 1\n",
      "Network: ./ACASXU_run2a_1_2_batch_fc5OP.nnet\n",
      "Number of layers: 3. Input layer size: 50. Output layer size: 5. Number of ReLUs: 50\n",
      "Total number of variables: 155\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY:\n",
      "UNSAT 0 10 11\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.0\n",
      "x0 <= 0.4879558\n",
      "x1 >= 0.0\n",
      "x1 <= 0.0\n",
      "x2 >= 0.0\n",
      "x2 <= 0.0\n",
      "x3 >= 0.0\n",
      "x3 <= 0.0\n",
      "x4 >= 0.0\n",
      "x4 <= 0.0\n",
      "x5 >= 0.0\n",
      "x5 <= 0.0\n",
      "x6 >= 0.0\n",
      "x6 <= 0.0\n",
      "x7 >= 0.0\n",
      "x7 <= 0.0\n",
      "x8 >= 0.0\n",
      "x8 <= 0.0\n",
      "x9 >= 0.0\n",
      "x9 <= 0.0\n",
      "x10 >= 1.7928456\n",
      "x10 <= 3.7465637\n",
      "x11 >= 0.0\n",
      "x11 <= 0.0\n",
      "x12 >= 0.0\n",
      "x12 <= 0.0\n",
      "x13 >= 0.0\n",
      "x13 <= 0.0\n",
      "x14 >= 0.0\n",
      "x14 <= 0.0\n",
      "x15 >= 0.0\n",
      "x15 <= 0.0\n",
      "x16 >= 0.0\n",
      "x16 <= 0.0\n",
      "x17 >= 0.0\n",
      "x17 <= 0.0\n",
      "x18 >= 0.0\n",
      "x18 <= 0.0\n",
      "x19 >= 0.0\n",
      "x19 <= 0.0\n",
      "x20 >= 0.0\n",
      "x20 <= 0.0\n",
      "x21 >= 0.0\n",
      "x21 <= 0.0\n",
      "x22 >= 0.0\n",
      "x22 <= 0.0\n",
      "x23 >= 0.0\n",
      "x23 <= 0.0\n",
      "x24 >= 0.0\n",
      "x24 <= 0.0\n",
      "x25 >= 3.0954623\n",
      "x25 <= 5.6651177\n",
      "x26 >= 0.0\n",
      "x26 <= 0.0\n",
      "x27 >= 0.0\n",
      "x27 <= 0.0\n",
      "x28 >= 0.0\n",
      "x28 <= 0.0\n",
      "x29 >= 0.0\n",
      "x29 <= 0.0\n",
      "x30 >= 0.0\n",
      "x30 <= 0.0\n",
      "x31 >= 0.0\n",
      "x31 <= 0.17363238\n",
      "x32 >= 0.0\n",
      "x32 <= 0.0\n",
      "x33 >= 4.986863\n",
      "x33 <= 9.182409\n",
      "x34 >= 0.0\n",
      "x34 <= 0.0\n",
      "x35 >= 0.0\n",
      "x35 <= 0.0\n",
      "x36 >= 0.0\n",
      "x36 <= 0.0\n",
      "x37 >= 0.0\n",
      "x37 <= 0.0\n",
      "x38 >= 0.0\n",
      "x38 <= 0.0\n",
      "x39 >= 0.0\n",
      "x39 <= 0.0\n",
      "x40 >= 0.0\n",
      "x40 <= 0.0\n",
      "x41 >= 0.0\n",
      "x41 <= 0.0\n",
      "x42 >= 0.0\n",
      "x42 <= 0.0\n",
      "x43 >= 0.0\n",
      "x43 <= 0.0\n",
      "x44 >= 0.0\n",
      "x44 <= 0.0\n",
      "x45 >= 0.0\n",
      "x45 <= 0.0\n",
      "x46 >= 2.041381\n",
      "x46 <= 4.108132\n",
      "x47 >= 0.0\n",
      "x47 <= 1.0279948\n",
      "x48 >= 0.0\n",
      "x48 <= 2.1200972\n",
      "x49 >= 0.0\n",
      "x49 <= 0.0\n",
      "+y2 -y0 <= -0.001\n",
      "\n",
      "\n",
      " I /\\ label= 2\n",
      "Network: ./ACASXU_run2a_1_2_batch_fc5OP.nnet\n",
      "Number of layers: 3. Input layer size: 50. Output layer size: 5. Number of ReLUs: 50\n",
      "Total number of variables: 155\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 8 5\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.0\n",
      "x0 <= 0.4879558\n",
      "x1 >= 0.0\n",
      "x1 <= 0.0\n",
      "x2 >= 0.0\n",
      "x2 <= 0.0\n",
      "x3 >= 0.0\n",
      "x3 <= 0.0\n",
      "x4 >= 0.0\n",
      "x4 <= 0.0\n",
      "x5 >= 0.0\n",
      "x5 <= 0.0\n",
      "x6 >= 0.0\n",
      "x6 <= 0.0\n",
      "x7 >= 0.0\n",
      "x7 <= 0.0\n",
      "x8 >= 0.0\n",
      "x8 <= 0.0\n",
      "x9 >= 0.0\n",
      "x9 <= 0.0\n",
      "x10 >= 1.7928456\n",
      "x10 <= 3.7465637\n",
      "x11 >= 0.0\n",
      "x11 <= 0.0\n",
      "x12 >= 0.0\n",
      "x12 <= 0.0\n",
      "x13 >= 0.0\n",
      "x13 <= 0.0\n",
      "x14 >= 0.0\n",
      "x14 <= 0.0\n",
      "x15 >= 0.0\n",
      "x15 <= 0.0\n",
      "x16 >= 0.0\n",
      "x16 <= 0.0\n",
      "x17 >= 0.0\n",
      "x17 <= 0.0\n",
      "x18 >= 0.0\n",
      "x18 <= 0.0\n",
      "x19 >= 0.0\n",
      "x19 <= 0.0\n",
      "x20 >= 0.0\n",
      "x20 <= 0.0\n",
      "x21 >= 0.0\n",
      "x21 <= 0.0\n",
      "x22 >= 0.0\n",
      "x22 <= 0.0\n",
      "x23 >= 0.0\n",
      "x23 <= 0.0\n",
      "x24 >= 0.0\n",
      "x24 <= 0.0\n",
      "x25 >= 3.0954623\n",
      "x25 <= 5.6651177\n",
      "x26 >= 0.0\n",
      "x26 <= 0.0\n",
      "x27 >= 0.0\n",
      "x27 <= 0.0\n",
      "x28 >= 0.0\n",
      "x28 <= 0.0\n",
      "x29 >= 0.0\n",
      "x29 <= 0.0\n",
      "x30 >= 0.0\n",
      "x30 <= 0.0\n",
      "x31 >= 0.0\n",
      "x31 <= 0.17363238\n",
      "x32 >= 0.0\n",
      "x32 <= 0.0\n",
      "x33 >= 4.986863\n",
      "x33 <= 9.182409\n",
      "x34 >= 0.0\n",
      "x34 <= 0.0\n",
      "x35 >= 0.0\n",
      "x35 <= 0.0\n",
      "x36 >= 0.0\n",
      "x36 <= 0.0\n",
      "x37 >= 0.0\n",
      "x37 <= 0.0\n",
      "x38 >= 0.0\n",
      "x38 <= 0.0\n",
      "x39 >= 0.0\n",
      "x39 <= 0.0\n",
      "x40 >= 0.0\n",
      "x40 <= 0.0\n",
      "x41 >= 0.0\n",
      "x41 <= 0.0\n",
      "x42 >= 0.0\n",
      "x42 <= 0.0\n",
      "x43 >= 0.0\n",
      "x43 <= 0.0\n",
      "x44 >= 0.0\n",
      "x44 <= 0.0\n",
      "x45 >= 0.0\n",
      "x45 <= 0.0\n",
      "x46 >= 2.041381\n",
      "x46 <= 4.108132\n",
      "x47 >= 0.0\n",
      "x47 <= 1.0279948\n",
      "x48 >= 0.0\n",
      "x48 <= 2.1200972\n",
      "x49 >= 0.0\n",
      "x49 <= 0.0\n",
      "+y3 -y0 <= -0.001\n",
      "\n",
      "\n",
      " I /\\ label= 3\n",
      "Network: ./ACASXU_run2a_1_2_batch_fc5OP.nnet\n",
      "Number of layers: 3. Input layer size: 50. Output layer size: 5. Number of ReLUs: 50\n",
      "Total number of variables: 155\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 14 10\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.0\n",
      "x0 <= 0.4879558\n",
      "x1 >= 0.0\n",
      "x1 <= 0.0\n",
      "x2 >= 0.0\n",
      "x2 <= 0.0\n",
      "x3 >= 0.0\n",
      "x3 <= 0.0\n",
      "x4 >= 0.0\n",
      "x4 <= 0.0\n",
      "x5 >= 0.0\n",
      "x5 <= 0.0\n",
      "x6 >= 0.0\n",
      "x6 <= 0.0\n",
      "x7 >= 0.0\n",
      "x7 <= 0.0\n",
      "x8 >= 0.0\n",
      "x8 <= 0.0\n",
      "x9 >= 0.0\n",
      "x9 <= 0.0\n",
      "x10 >= 1.7928456\n",
      "x10 <= 3.7465637\n",
      "x11 >= 0.0\n",
      "x11 <= 0.0\n",
      "x12 >= 0.0\n",
      "x12 <= 0.0\n",
      "x13 >= 0.0\n",
      "x13 <= 0.0\n",
      "x14 >= 0.0\n",
      "x14 <= 0.0\n",
      "x15 >= 0.0\n",
      "x15 <= 0.0\n",
      "x16 >= 0.0\n",
      "x16 <= 0.0\n",
      "x17 >= 0.0\n",
      "x17 <= 0.0\n",
      "x18 >= 0.0\n",
      "x18 <= 0.0\n",
      "x19 >= 0.0\n",
      "x19 <= 0.0\n",
      "x20 >= 0.0\n",
      "x20 <= 0.0\n",
      "x21 >= 0.0\n",
      "x21 <= 0.0\n",
      "x22 >= 0.0\n",
      "x22 <= 0.0\n",
      "x23 >= 0.0\n",
      "x23 <= 0.0\n",
      "x24 >= 0.0\n",
      "x24 <= 0.0\n",
      "x25 >= 3.0954623\n",
      "x25 <= 5.6651177\n",
      "x26 >= 0.0\n",
      "x26 <= 0.0\n",
      "x27 >= 0.0\n",
      "x27 <= 0.0\n",
      "x28 >= 0.0\n",
      "x28 <= 0.0\n",
      "x29 >= 0.0\n",
      "x29 <= 0.0\n",
      "x30 >= 0.0\n",
      "x30 <= 0.0\n",
      "x31 >= 0.0\n",
      "x31 <= 0.17363238\n",
      "x32 >= 0.0\n",
      "x32 <= 0.0\n",
      "x33 >= 4.986863\n",
      "x33 <= 9.182409\n",
      "x34 >= 0.0\n",
      "x34 <= 0.0\n",
      "x35 >= 0.0\n",
      "x35 <= 0.0\n",
      "x36 >= 0.0\n",
      "x36 <= 0.0\n",
      "x37 >= 0.0\n",
      "x37 <= 0.0\n",
      "x38 >= 0.0\n",
      "x38 <= 0.0\n",
      "x39 >= 0.0\n",
      "x39 <= 0.0\n",
      "x40 >= 0.0\n",
      "x40 <= 0.0\n",
      "x41 >= 0.0\n",
      "x41 <= 0.0\n",
      "x42 >= 0.0\n",
      "x42 <= 0.0\n",
      "x43 >= 0.0\n",
      "x43 <= 0.0\n",
      "x44 >= 0.0\n",
      "x44 <= 0.0\n",
      "x45 >= 0.0\n",
      "x45 <= 0.0\n",
      "x46 >= 2.041381\n",
      "x46 <= 4.108132\n",
      "x47 >= 0.0\n",
      "x47 <= 1.0279948\n",
      "x48 >= 0.0\n",
      "x48 <= 2.1200972\n",
      "x49 >= 0.0\n",
      "x49 <= 0.0\n",
      "+y4 -y0 <= -0.001\n",
      "\n",
      "\n",
      " I /\\ label= 4\n",
      "Network: ./ACASXU_run2a_1_2_batch_fc5OP.nnet\n",
      "Number of layers: 3. Input layer size: 50. Output layer size: 5. Number of ReLUs: 50\n",
      "Total number of variables: 155\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 8 5\n",
      "\n",
      "Property proved!\n",
      "\n",
      " CHECK I /\\ covered_consts on short network => B, PROVED \n",
      "\n",
      " CHECK A  => I \n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_41 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 26 66 123\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_21 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 17 44 128\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_2 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 26 54 137\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_40 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 13 36 120\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_43 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 24 60 122\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_9 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 46 102 132\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_33 <= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 1 1 106\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_22 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 35 76 131\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_26 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 87 204 123\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_27 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 59 132 126\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_34 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 27 72 126\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_3 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 36 88 127\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_8 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 41 100 126\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_42 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 37 96 108\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_4 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 27 66 117\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_15 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 59 144 111\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_20 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "Before declaring SAT, recomputing...\n",
      "SAT\n",
      "\n",
      "Input assignment:\n",
      "\tx0 =   0.2690\n",
      "\tx1 =   0.1479\n",
      "\tx2 =  -0.5000\n",
      "\tx3 =   0.5000\n",
      "\tx4 =   0.0000\n",
      "\n",
      "Output:\n",
      "\ty0 =  -0.0216\n",
      "\ty1 =  -0.0189\n",
      "\ty2 =  -0.0190\n",
      "\ty3 =  -0.0190\n",
      "\ty4 =  -0.0190\n",
      "\n",
      "SUMMARY:\n",
      "SAT 26 52 110\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_23 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 41 94 122\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_37 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 57 140 133\n",
      "\n",
      "PROPERTY FILE IS \n",
      "x0 >= 0.268978\n",
      "x0 <= 0.679858\n",
      "x1 >= 0.111408\n",
      "x1 <= 0.499999\n",
      "x2 >= -0.5\n",
      "x2 <= -0.49841\n",
      "x3 >= 0.227273\n",
      "x3 <= 0.5\n",
      "x4 >= 0.0\n",
      "x4 <= 0.5\n",
      "ws_5_45 >= 0.0\n",
      "\n",
      "\n",
      " CHECK A /\\ not(I) \n",
      "Network: ./ACASXU_run2a_1_1_batch_2000.nnet\n",
      "Number of layers: 8. Input layer size: 5. Output layer size: 5. Number of ReLUs: 300\n",
      "Total number of variables: 610\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 87 176 134\n",
      "\n",
      "\n",
      " A => I proved.\n",
      "\n",
      " PROPERTY A => B proved!\n",
      "TIME FOR A => layer property, layer property => B: 862.6762335300446\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"layer:\", LAYER)\n",
    "#\",label:\", LABEL)\n",
    "invariants = get_all_invariants(basic_estimator)\n",
    "describe_invariants_all_labels(invariants,prev_lay,curr_lay)\n",
    "\n",
    "pr = 10\n",
    "label = 0\n",
    "pr_minIn = [0.268978,0.111408,-0.5, 0.227273,0.0]\n",
    "pr_maxIn = [0.679858,0.499999,-0.49841,0.5,0.5]\n",
    "\n",
    "print(\"CHECK PROPERTY:\", str(pr) )\n",
    "print(\"REGION A:\")\n",
    "print(pr_minIn)\n",
    "print(pr_maxIn)\n",
    "print(\"LABEL B:\", str(label))\n",
    "\n",
    "print(\"CHECK A => B on full network:\")\n",
    "\n",
    "start1 = time.time()\n",
    "property_chk(True,pr,label,invariants,pr_minIn,pr_maxIn)\n",
    "end1 = time.time()\n",
    "\n",
    "print(\"TIME FOR A => B on full network:\", (end1 - start1))\n",
    "\n",
    "start = time.time()\n",
    "property_chk(False,pr,label,invariants,pr_minIn,pr_maxIn)\n",
    "end = time.time()\n",
    "\n",
    "print(\"TIME FOR A => layer property, layer property => B:\", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ACASX_Prophecy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
