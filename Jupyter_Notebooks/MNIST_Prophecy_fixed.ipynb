{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-JL_MKop5Qh"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import io\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dFrZ3KPV1kA2",
    "outputId": "9647726c-cfba-42c6-e485-f1de621eb38e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tensorflow'...\n",
      "remote: Enumerating objects: 194, done.\u001b[K\n",
      "remote: Counting objects: 100% (194/194), done.\u001b[K\n",
      "remote: Compressing objects: 100% (154/154), done.\u001b[K\n",
      "remote: Total 956541 (delta 73), reused 153 (delta 35), pack-reused 956347\u001b[K\n",
      "Receiving objects: 100% (956541/956541), 558.27 MiB | 4.64 MiB/s, done.\n",
      "Resolving deltas: 100% (778343/778343), done.\n",
      "Updating files: 100% (22841/22841), done.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/tensorflow/tensorflow.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CBe-ZIE4qL0N"
   },
   "source": [
    "**LOAD MNIST DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "tXVviKka2Kou",
    "outputId": "4fbacb52-b4f7-420b-d10e-e923856678d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/burak/nasa-neural-properties/prophecy-mnist\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "exp_folder = '/home/burak/nasa-neural-properties/prophecy-mnist'\n",
    "\n",
    "try: \n",
    "    os.mkdir(exp_folder) \n",
    "except OSError as error: \n",
    "    print(error) \n",
    "\n",
    "os.chdir(exp_folder)\n",
    "    \n",
    "!pwd\n",
    "os.chdir('/home/burak/nasa-neural-properties/tensorflow/tensorflow/examples/tutorials/mnist/')\n",
    "#!ls -lt\n",
    "import input_data\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "mnist = input_data.read_data_sets('MNIST_data')\n",
    "\n",
    "os.chdir(exp_folder)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8C45xGa98mzt"
   },
   "source": [
    "**ARCHITECTURE OF THE MNIST MODEL (10 LAYER) IN TENSORFLOW** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39JpLmTitqdj"
   },
   "outputs": [],
   "source": [
    "\n",
    "def weight_variable(shape, name):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial, name=name)\n",
    "\n",
    "def fc2d(x, W):\n",
    "  return tf.nn.fc2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def create_model():\n",
    "    x = tf.identity(tf.placeholder(tf.float32, shape=[None, 784]), name=\"input\")\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "    W_fc1 = weight_variable([784, 10],name='w_fc1')\n",
    "    b_fc1 = bias_variable([10],name='b_fc1')\n",
    "    x_image = tf.reshape(x, [-1, 784])\n",
    "    h_fc1_relu_inp = tf.identity(tf.matmul(x_image, W_fc1) + b_fc1, name='h_fc1_relu_inp')\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(x_image, W_fc1) + b_fc1)\n",
    "#    h_fc1_iden = tf.identity(h_fc1,name='h_fc1')\n",
    "    \n",
    "    \n",
    "    W_fc2 = weight_variable([10, 10],name='w_fc2')\n",
    "    b_fc2 = bias_variable([10],name='b_fc2')\n",
    "    h_fc2_relu_inp = tf.identity(tf.matmul(h_fc1, W_fc2) + b_fc2, name='h_fc2_relu_inp')\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    " #   h_fc2_iden = tf.identity(h_fc2,name='h_fc2')\n",
    "    \n",
    "    \n",
    "    W_fc3 = weight_variable([10, 10],name='w_fc3')\n",
    "    b_fc3 = bias_variable([10],name='b_fc3')\n",
    "    h_fc3_relu_inp = tf.identity(tf.matmul(h_fc2, W_fc3) + b_fc3, name='h_fc3_relu_inp')\n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2, W_fc3) + b_fc3)\n",
    "  #  h_fc3_iden = tf.identity(h_fc3,name='h_fc3')\n",
    "\n",
    "    W_fc4 = weight_variable([10, 10],name='w_fc4')\n",
    "    b_fc4 = bias_variable([10],name='b_fc4')\n",
    "    h_fc4_relu_inp = tf.identity(tf.matmul(h_fc3, W_fc4) + b_fc4, name='h_fc4_relu_inp')\n",
    "    h_fc4 = tf.nn.relu(tf.matmul(h_fc3, W_fc4) + b_fc4)\n",
    "   # h_fc4_iden = tf.identity(h_fc4,name='h_fc4')\n",
    "    \n",
    "    \n",
    "    W_fc5 = weight_variable([10, 10],name='w_fc5')\n",
    "    b_fc5 = bias_variable([10],name='b_fc5')\n",
    "    h_fc5_relu_inp = tf.identity(tf.matmul(h_fc4, W_fc5) + b_fc5, name='h_fc5_relu_inp')\n",
    "    h_fc5 = tf.nn.relu(tf.matmul(h_fc4, W_fc5) + b_fc5)\n",
    "    #h_fc5_iden = tf.identity(h_fc5,name='h_fc5')\n",
    "\n",
    "   \n",
    "    W_fc6 = weight_variable([10, 10],name='w_fc6')\n",
    "    b_fc6 = bias_variable([10],name='b_fc6')\n",
    "    h_fc6_relu_inp = tf.identity(tf.matmul(h_fc5, W_fc6) + b_fc6, name='h_fc6_relu_inp')\n",
    "    h_fc6 = tf.nn.relu(tf.matmul(h_fc5, W_fc6) + b_fc6)\n",
    "   # h_fc6_iden = tf.identity(h_fc6,name='h_fc6')\n",
    "    \n",
    "    \n",
    "    W_fc7 = weight_variable([10, 10],name='w_fc7')\n",
    "    b_fc7 = bias_variable([10],name='b_fc7')\n",
    "    h_fc7_relu_inp = tf.identity(tf.matmul(h_fc6, W_fc7) + b_fc7, name='h_fc7_relu_inp')\n",
    "    h_fc7 = tf.nn.relu(tf.matmul(h_fc6, W_fc7) + b_fc7)\n",
    "   # h_fc7_iden = tf.identity(h_fc7,name='h_fc7')\n",
    "\n",
    "    W_fc8 = weight_variable([10, 10],name='w_fc8')\n",
    "    b_fc8 = bias_variable([10],name='b_fc8')\n",
    "    h_fc8_relu_inp = tf.identity(tf.matmul(h_fc7, W_fc8) + b_fc8, name='h_fc8_relu_inp')\n",
    "    h_fc8 = tf.nn.relu(tf.matmul(h_fc7, W_fc8) + b_fc8)\n",
    "   # h_fc8_iden = tf.identity(h_fc8,name='h_fc8')\n",
    "    \n",
    "    \n",
    "    W_fc9 = weight_variable([10, 10],name='w_fc9')\n",
    "    b_fc9 = bias_variable([10],name='b_fc9')\n",
    "    h_fc9_relu_inp = tf.identity(tf.matmul(h_fc8, W_fc9) + b_fc9, name='h_fc9_relu_inp')\n",
    "    h_fc9 = tf.nn.relu(tf.matmul(h_fc8, W_fc9) + b_fc9)\n",
    "   # h_fc9_iden = tf.identity(h_fc9,name='h_fc9')\n",
    "\n",
    "    W_fc10 = weight_variable([10, 10],name='w_fc10')\n",
    "    b_fc10 = bias_variable([10],name='b_fc10')\n",
    "    h_fc10_relu_inp = tf.identity(tf.matmul(h_fc9, W_fc10) + b_fc10, name='h_fc10_relu_inp')\n",
    "    h_fc10 = tf.nn.relu(tf.matmul(h_fc9, W_fc10) + b_fc10)\n",
    "    #h_fc10_iden = tf.identity(h_fc10,name='h_fc10')\n",
    "\n",
    "    W_fc11 = weight_variable([10, 10],name='w_fc11')\n",
    "    b_fc11 = bias_variable([10],name='b_fc11')\n",
    "    \n",
    "    y_fc = tf.matmul(h_fc10, W_fc11) + b_fc11\n",
    "    h_y_fc_iden = tf.identity(y_fc,name='y_fc')\n",
    "    \n",
    "    \n",
    "    prediction = tf.identity(tf.nn.softmax(y_fc), name=\"import/prediction\")\n",
    "    \n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_fc))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_fc, 1), tf.argmax(y_, 1))\n",
    "    \n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    \n",
    "\n",
    "    return cross_entropy, accuracy, x, keep_prob, y_fc, y_, W_fc1, W_fc2, W_fc3, W_fc4, W_fc5, W_fc6, W_fc7, W_fc8, W_fc9, W_fc10, W_fc11, b_fc1, b_fc2, b_fc3, b_fc4, b_fc5, b_fc6, b_fc7, b_fc8, b_fc9, b_fc10, b_fc11, h_fc1, h_fc1_relu_inp, h_fc2, h_fc2_relu_inp, h_fc3, h_fc3_relu_inp, h_fc4, h_fc4_relu_inp, h_fc5, h_fc5_relu_inp, h_fc6, h_fc6_relu_inp, h_fc7, h_fc7_relu_inp, h_fc8, h_fc8_relu_inp, h_fc9, h_fc9_relu_inp, h_fc10, h_fc10_relu_inp, y_fc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jv3U6Xs_T2el"
   },
   "source": [
    "Train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-2x6UTcuJUK"
   },
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "#sess = tf.InteractiveSession()\n",
    "#cross_entropy, accuracy, x, keep_prob, y_conv, y_ = create_model()\n",
    "#train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "#saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "#for i in range(0, 1200):\n",
    "#  batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "#  train_step.run(feed_dict={x: batch[0], y_: np.eye(10)[batch[1]], keep_prob: 0.5})\n",
    "#  if i%100 == 0:\n",
    "#    test_accuracy = accuracy.eval(feed_dict={\n",
    "#        x:mnist.test.images, y_: np.eye(10)[mnist.test.labels], keep_prob: 1.0})\n",
    "#    print(\"step %d, test accuracy %g\"%(i, test_accuracy))    \n",
    "#ckpt_path_name = saver.save(sess, './checkpoints/mnist_invariant.ckpt', global_step=i)\n",
    "#print \"Checkpoint saved at: %s\" % ckpt_path_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylVCQ9lfTfWF"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#files.download(ckpt_path_name + '.data-00000-of-00001')\n",
    "#files.download(ckpt_path_name + '.index')\n",
    "#files.download(ckpt_path_name + '.meta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uy6_gvmpT4Wv"
   },
   "source": [
    "### Restore a pretrained model from check point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMibD_lwWdVG"
   },
   "outputs": [],
   "source": [
    "#!mkdir -p ./checkpoints\n",
    "#!wget https://github.com/safednn-nasa/prophecy_DNN/sym_convnn/raw/master/MNIST_ITR_REL/MNIST_conv_checkpoint/mnist_invariants.ckpt.index -O ./checkpoints/mnist_invariants.ckpt.index\n",
    "#!wget https://github.com/safednn-nasa/prophecy_DNN/sym_convnn/raw/master/MNIST_ITR_REL/MNIST_conv_checkpoint/mnist_invariants.ckpt.meta -O ./checkpoints/mnist_invariants.ckpt.meta\n",
    "#!wget https://github.com/safednn-nasa/prophecy_DNN/sym_convnn/raw/master/MNIST_ITR_REL/MNIST_conv_checkpoint/mnist_invariants.ckpt.data-00000-of-00001 -O ./checkpoints/mnist_invariants.ckpt.data-00000-of-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwDRpu0_1QDv"
   },
   "source": [
    "**Restore pre-trained model from a .nn file with weights and biases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "7JmFzaPPT6ql",
    "outputId": "ff8375cc-7fbf-4399-9aff-a234426518aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-28 19:12:46--  https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/MNIST_ITR_REL/mnist_10_layer.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.24.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.24.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 146765 (143K) [text/plain]\n",
      "Saving to: ‘./mnist_10_layer.txt’\n",
      "\n",
      "./mnist_10_layer.tx 100%[===================>] 143.33K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-07-28 19:12:46 (1.32 MB/s) - ‘./mnist_10_layer.txt’ saved [146765/146765]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/burak/nasa-neural-properties/nasa-neural-properties-env/lib/python3.8/site-packages/tensorflow/python/client/session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.933\n"
     ]
    }
   ],
   "source": [
    "def read_weights_from_file(inputFile):\n",
    "    global weightMatrix, biasMatrix\n",
    "    \n",
    "    with open(inputFile) as f:\n",
    "        lines = f.readlines()\n",
    "        for indx in range(0,len(lines)):\n",
    "            #print(indx, lines[indx])\n",
    "            numberOfLayers = int(lines[0])\n",
    "            numberOfLayers = 11\n",
    "            weightMatrix = np.empty(numberOfLayers, dtype=list)\n",
    "            biasMatrix = np.empty(numberOfLayers, dtype=list)\n",
    "            currentLine = 2\n",
    "            for i in range(numberOfLayers):\n",
    "              dimensions = lines[currentLine].split(',')\n",
    "              dimensions = [int(stringDimension) for stringDimension in dimensions]\n",
    "              #print dimensions\n",
    "              currentLine += 1\n",
    "              weights = [float(stringWeight) for stringWeight in lines[currentLine].split(',')]\n",
    "              #print len(weights)\n",
    "              count = 0\n",
    "              weightMatrix[i] = np.zeros((dimensions[0], dimensions[1]), dtype=float)\n",
    "              for j in range(dimensions[1]):\n",
    "                 for k in range(dimensions[0]):\n",
    "                      weightMatrix[i][k][j] = weights[count]\n",
    "                      count += 1\n",
    "              currentLine += 1\n",
    "              biases = [float(stringBias) for stringBias in lines[currentLine].split(',')]\n",
    "              biasMatrix[i] = np.zeros(len(biases))\n",
    "              biasMatrix[i] = biases\n",
    "              currentLine += 2\n",
    "\n",
    "!wget https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/MNIST_ITR_REL/mnist_10_layer.txt -O ./mnist_10_layer.txt\n",
    "\n",
    "\n",
    "read_weights_from_file('./mnist_10_layer.txt')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "cross_entropy, accuracy, x, keep_prob, y_fc, y_, W_fc1, W_fc2, W_fc3, W_fc4, W_fc5, W_fc6, W_fc7, W_fc8, W_fc9, W_fc10, W_fc11,b_fc1, b_fc2, b_fc3, b_fc4, b_fc5, b_fc6, b_fc7, b_fc8, b_fc9, b_fc10, b_fc11, h_fc1, h_fc1_relu_inp, h_fc2, h_fc2_relu_inp, h_fc3, h_fc3_relu_inp,h_fc4, h_fc4_relu_inp, h_fc5, h_fc5_relu_inp, h_fc6, h_fc6_relu_inp, h_fc7, h_fc7_relu_inp, h_fc8, h_fc8_relu_inp, h_fc9, h_fc9_relu_inp, h_fc10, h_fc10_relu_inp, y_fc = create_model()\n",
    "feed_dict = {x:mnist.test.images, y_: np.eye(10)[mnist.test.labels], keep_prob: 1.0, W_fc1: weightMatrix[0], b_fc1: biasMatrix[0], W_fc2: weightMatrix[1], b_fc2: biasMatrix[1], W_fc3: weightMatrix[2], b_fc3: biasMatrix[2], W_fc4: weightMatrix[3], b_fc4: biasMatrix[3], W_fc5: weightMatrix[4], b_fc5: biasMatrix[4], W_fc6: weightMatrix[5], b_fc6: biasMatrix[5],W_fc7: weightMatrix[6], b_fc7: biasMatrix[6],W_fc8: weightMatrix[7], b_fc8: biasMatrix[7],W_fc9: weightMatrix[8], b_fc9: biasMatrix[8], W_fc10: weightMatrix[9], b_fc10: biasMatrix[9], W_fc11: weightMatrix[10], b_fc11: biasMatrix[10]}\n",
    "  \n",
    "test_accuracy = accuracy.eval(feed_dict)\n",
    "print(\"Test accuracy %g\"%(test_accuracy))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "no8LrMARrM2l"
   },
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TL92gsWskV0-"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def get_prediction(inps, tensor=y_fc, batch_size=100):\n",
    "  def get_prediction_batch(batch):\n",
    "    #feed = {x: np.array(batch), keep_prob:1.0}\n",
    "    feed = {x: np.array(batch), keep_prob:1.0, W_fc1: weightMatrix[0], b_fc1: biasMatrix[0], W_fc2: weightMatrix[1], b_fc2: biasMatrix[1], W_fc3: weightMatrix[2], b_fc3: biasMatrix[2], W_fc4: weightMatrix[3], b_fc4: biasMatrix[3], W_fc5: weightMatrix[4], b_fc5: biasMatrix[4], W_fc6: weightMatrix[5], b_fc6: biasMatrix[5],W_fc7: weightMatrix[6], b_fc7: biasMatrix[6],W_fc8: weightMatrix[7], b_fc8: biasMatrix[7],W_fc9: weightMatrix[8], b_fc9: biasMatrix[8], W_fc10: weightMatrix[9], b_fc10: biasMatrix[9], W_fc11: weightMatrix[10], b_fc11: biasMatrix[10]}\n",
    "    return sess.run(tensor, feed_dict=feed)\n",
    "  n = len(inps)\n",
    "  if n%batch_size == 0:\n",
    "    batches = [inps[i*batch_size:(i+1)*batch_size] for i in range(int(n/batch_size))]\n",
    "  else:\n",
    "    batches = [inps[i*batch_size:(i+1)*batch_size] for i in range(int(n/batch_size) +1)]    \n",
    "  batch_predictions = [get_prediction_batch(b) for b in tqdm(batches)]\n",
    "  return np.concatenate(tuple(batch_predictions), axis=0)\n",
    "\n",
    "def attribute(inp, label, baseline=None, steps=50, use_top_label=False):\n",
    "  def top_label(inp):\n",
    "    return np.argmax(get_prediction([inp])[0])\n",
    "  if baseline is None:\n",
    "    baseline = 0*inp\n",
    "  scaled_inputs = [baseline + (float(i)/steps)*(inp-baseline) for i in range(0, steps)]\n",
    "  #feed = {keep_prob:1.0}\n",
    "  feed = {keep_prob:1.0, W_fc1: weightMatrix[0], b_fc1: biasMatrix[0], W_fc2: weightMatrix[1], b_fc2: biasMatrix[1], W_fc3: weightMatrix[2], b_fc3: biasMatrix[2], W_fc4: weightMatrix[3], b_fc4: biasMatrix[3], W_fc5: weightMatrix[4], b_fc5: biasMatrix[4], W_fc6: weightMatrix[5], b_fc6: biasMatrix[5],W_fc7: weightMatrix[6], b_fc7: biasMatrix[6],W_fc8: weightMatrix[7], b_fc8: biasMatrix[7],W_fc9: weightMatrix[8], b_fc9: biasMatrix[8], W_fc10: weightMatrix[9], b_fc10: biasMatrix[9], W_fc11: weightMatrix[10], b_fc11: biasMatrix[10]}\n",
    "    \n",
    "  if use_top_label:\n",
    "    feed[x] = [inp]\n",
    "    logits = sess.run(y_fc, feed_dict=feed)[0]\n",
    "    label = np.argmax(logits)\n",
    "  feed[x] = scaled_inputs\n",
    "  feed[t_label] = label\n",
    "  grads, scores = sess.run([t_grad, y_fc], feed_dict=feed)  # shapes: <steps+1>, <steps+1, inp.shape>\n",
    "  integrated_gradients = (inp-baseline)*np.average(grads[0], axis=0)  # shape: <inp.shape>\n",
    "#  print \"FINAL SCORE\", scores[-1][label]\n",
    "#  print \"BASELINE SCORE\", scores[0][label]\n",
    "#  print \"SUM\", np.sum(integrated_gradients), \"DIFF\", scores[-1][label] - scores[0][label]\n",
    "  return integrated_gradients\n",
    "\n",
    "def conductance(inp, label, neuron_id=None, baseline=None, steps=50):\n",
    "  # neuron_id is the id of the neuron in layer t_fc1 through which conductance\n",
    "  # must be computed. If None, vanilla IG is computed.\n",
    "  if baseline is None:\n",
    "    baseline = 0*inp\n",
    "  scaled_inputs = [baseline + (float(i)/steps)*(inp-baseline) for i in range(0, steps)]\n",
    "  feed = {keep_prob:1.0, W_fc1: weightMatrix[0], b_fc1: biasMatrix[0], W_fc2: weightMatrix[1], b_fc2: biasMatrix[1], W_fc3: weightMatrix[2], b_fc3: biasMatrix[2], W_fc4: weightMatrix[3], b_fc4: biasMatrix[3], W_fc5: weightMatrix[4], b_fc5: biasMatrix[4], W_fc6: weightMatrix[5], b_fc6: biasMatrix[5],W_fc7: weightMatrix[6], b_fc7: biasMatrix[6],W_fc8: weightMatrix[7], b_fc8: biasMatrix[7],W_fc9: weightMatrix[8], b_fc9: biasMatrix[8], W_fc10: weightMatrix[9], b_fc10: biasMatrix[9], W_fc11: weightMatrix[10], b_fc11: biasMatrix[10]}\n",
    "  feed[x] = scaled_inputs\n",
    "  feed[t_label] = label\n",
    "  if neuron_id != None:\n",
    "    feed[t_neuron_id] = neuron_id\n",
    "    grads, scores = sess.run([t_grad_conductance, y_fc], feed_dict=feed)  # shapes: <steps+1>, <steps+1, inp.shape>\n",
    "    integrated_gradients = (inp-baseline)*np.average(grads[0], axis=0)  # shape: <inp.shape>\n",
    "    return integrated_gradients\n",
    "  grads, scores = sess.run([t_grad, y_fc], feed_dict=feed)  # shapes: <steps+1>, <steps+1, inp.shape>    \n",
    "  integrated_gradients = (inp-baseline)*np.average(grads[0], axis=0)  # shape: <inp.shape>\n",
    "  #print \"FINAL SCORE\", scores[-1][label]\n",
    "  #print \"BASELINE SCORE\", scores[0][label]\n",
    "  #print \"SUM\", np.sum(integrated_gradients), \"DIFF\", scores[-1][label] - scores[0][label]\n",
    "  return integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "AzUgsmFQyohg",
    "outputId": "1eb3b7d1-cc69-4baa-93e1-8c84e3399d38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 550/550 [00:00<00:00, 639.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions computed for all training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_predictions = np.argmax(get_prediction(mnist.train.images), axis=1)\n",
    "print(\"Predictions computed for all training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iG5Fq5GIkP6u"
   },
   "source": [
    "Library for Visualizing Images and Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "czxZISZYkLaH"
   },
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_o25suPkTL3"
   },
   "outputs": [],
   "source": [
    "FONT_PATH='/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed.ttf'\n",
    "IMAGE_SIZE = 28\n",
    "\n",
    "def mnist_to_rgb(mnist_img):\n",
    "  \"\"\"\n",
    "  Transformsn an MNIST image (shape: <784>) to a grayscale\n",
    "  RGB image (shape: <28,28,3>)\n",
    "  \"\"\"\n",
    "  pixel_array = mnist_img.reshape(IMAGE_SIZE, IMAGE_SIZE)  # shape: 28,28\n",
    "  rgb_image = np.transpose([pixel_array,pixel_array,pixel_array], axes=[1,2,0])\n",
    "  return rgb_image\n",
    "\n",
    "def pil_img(a):\n",
    "  '''Returns a PIL image created from the provided RGB array.\n",
    "  '''\n",
    "  a = np.uint8(a)\n",
    "  return PIL.Image.fromarray(a)\n",
    "\n",
    "def mnist_to_pil_img(inp):\n",
    "  rgb_inp = 255*mnist_to_rgb(inp)\n",
    "  vis_inp = pil_img(rgb_inp)\n",
    "  return vis_inp  \n",
    "\n",
    "def pil_fig(fig):\n",
    "  # Returns a PIL image obtained from the provided PLT figure.\n",
    "  buf = io.BytesIO()\n",
    "  fig.savefig(buf, format='png')\n",
    "  plt.close(fig)\n",
    "  buf.seek(0)\n",
    "  img = PIL.Image.open(buf)\n",
    "  return img\n",
    "\n",
    "def show_img(img, fmt='jpeg'):\n",
    "  '''Displays the provided PIL image\n",
    "  '''\n",
    "  #f = StringIO()\n",
    "  f = BytesIO()\n",
    "  img.save(f, fmt)\n",
    "  display(Image(data=f.getvalue()))\n",
    " \n",
    "def show_mnist_img(mnist_img):\n",
    "  show_img(pil_img(255*mnist_to_rgb(mnist_img)))\n",
    "  \n",
    "def gray_scale(img):\n",
    "  '''Converts the provided RGB image to gray scale.\n",
    "  '''\n",
    "  img = np.average(img, axis=2)\n",
    "  return np.transpose([img, img, img], axes=[1,2,0])\n",
    "\n",
    "def normalize(attrs, ptile=99):\n",
    "  '''Normalize the provided attributions so that they fall between\n",
    "     -1.0 and 1.0.\n",
    "  '''\n",
    "  h = np.percentile(attrs, ptile)\n",
    "  l = np.percentile(attrs, 100-ptile)\n",
    "  return np.clip(attrs/max(abs(h), abs(l)), -1.0, 1.0)    \n",
    "\n",
    "def pil_text(strs, shape, start_h=10, start_w=10, font_size=18, color=(0, 0, 0)):\n",
    "  # Returns a PIL image with the provided text.\n",
    "  img = pil_img(255*np.ones(shape))\n",
    "  draw = PIL.ImageDraw.Draw(img)\n",
    "  font = PIL.ImageFont.truetype(FONT_PATH, font_size)\n",
    "  h = start_h\n",
    "  for s in strs: \n",
    "    draw.text((start_w,h), s, fill=color, font=font)\n",
    "    h = h + 30\n",
    "  return img\n",
    "\n",
    "def combine(imgs, horizontal=True):\n",
    "  # Combines the provided PIL Images horizontally or veritically\n",
    "  if horizontal:\n",
    "    w = np.sum([img.size[0]+10 for img in imgs])\n",
    "    h = np.max([img.size[1] for img in imgs])\n",
    "  else:\n",
    "    w = np.max([img.size[0] for img in imgs])\n",
    "    h = np.sum([img.size[1]+10 for img in imgs])\n",
    "  final_img = PIL.Image.new('RGB', (w, h), color='white')\n",
    "  pos = 0\n",
    "  for img in imgs:\n",
    "    if horizontal:\n",
    "      final_img.paste(im=img, box=(pos,0))\n",
    "      pos = pos+img.size[0]+10\n",
    "    else:\n",
    "      final_img.paste(im=img, box=(0,pos))\n",
    "      pos = pos+img.size[1]+10\n",
    "  return final_img\n",
    "\n",
    "def visualize_attrs(img, attrs, ptile=99):\n",
    "  '''Visaualizes the provided attributions by first aggregating them\n",
    "    along the color channel to obtain per-pixel attributions and then\n",
    "    scaling the intensities of the pixels in the original image in\n",
    "    proportion to absolute value of these attributions.\n",
    "\n",
    "    The provided image and attributions must of shape (224, 224, 3).\n",
    "  '''\n",
    "  if np.sum(attrs) == 0.0:\n",
    "    # print \"Attributions are all ZERO\"\n",
    "    return pil_img(0*img)\n",
    "  attrs = gray_scale(attrs)\n",
    "  attrs = abs(attrs)\n",
    "  attrs = np.clip(attrs/np.percentile(attrs, ptile), 0,1)\n",
    "  vis = img*attrs\n",
    "  return pil_img(vis)\n",
    "  \n",
    "  \n",
    "R=np.array([255,0,0])\n",
    "G=np.array([0,255,0])\n",
    "B=np.array([0,0,255])\n",
    "def visualize_attrs2(img, attrs, pos_ch=G, neg_ch=R, ptile=99):\n",
    "  '''Visaualizes the provided attributions by first aggregating them\n",
    "     along the color channel and then overlaying the positive attributions\n",
    "     along pos_ch, and negative attributions along neg_ch.\n",
    "\n",
    "     The provided image and attributions must of shape (224, 224, 3).\n",
    "  '''\n",
    " \n",
    "  if np.sum(attrs) == 0.0:\n",
    "    # print \"Attributions are all ZERO\"\n",
    "    return pil_img(0*img)\n",
    " \n",
    "  attrs = gray_scale(attrs)\n",
    "  attrs = normalize(attrs, ptile)   \n",
    "  \n",
    "  pos_attrs = attrs * (attrs >= 0.0)\n",
    "  #pos_attrs = pos_attrs1 * (abs(pos_attrs1) >= threshold)\n",
    "  neg_attrs = -1.0 * attrs * (attrs < 0.0)\n",
    "  #neg_attrs = -1.0 * neg_attrs1 * (abs(neg_attrs1) >= threshold)\n",
    "  attrs_mask = pos_attrs*pos_ch + neg_attrs*neg_ch\n",
    "  vis = 0.3*gray_scale(img) + 0.7*attrs_mask\n",
    "  return pil_img(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_uhUyYiBlL7"
   },
   "source": [
    "Extracting Invariant Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPvUSoGyFkdt"
   },
   "outputs": [],
   "source": [
    "def fingerprint_signature(inps,ten):\n",
    "  # Below t_fc1 is the final fully connected layer of size 1024.\n",
    "  return (get_prediction(inps, tensor=ten)>0.0).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxgnKvn04Q92"
   },
   "outputs": [],
   "source": [
    "def describe_input(i, training=True):\n",
    "  print(\"Input\", i)\n",
    "  print(\"Groundtruth\", mnist.train.labels[i])\n",
    "  print(\"Prediction\", train_predictions[i])\n",
    " # print(\"Fine-grained prediction\", 10*mnist.train.labels[i] + train_predictions[i])\n",
    "  show_mnist_img(mnist.train.images[i])\n",
    "  \n",
    "def describe_input_INP(i):\n",
    "  print(\"Input\", i)\n",
    "  print(\"Groundtruth\", mnist_inp_labels[i])\n",
    "  print(\"Prediction\", inp_predictions[i])\n",
    "  show_mnist_img(mnist_inp_images[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jajbWWpjscYZ"
   },
   "source": [
    "Download Marabou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "aBK9KWLc6TSe",
    "outputId": "a2f64628-7662-4d64-9427-523ef78eacb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-28 19:12:52--  https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/marabou1.elf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.24.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.24.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4231816 (4.0M) [application/octet-stream]\n",
      "Saving to: ‘./marabou1.elf’\n",
      "\n",
      "./marabou1.elf      100%[===================>]   4.04M  6.00MB/s    in 0.7s    \n",
      "\n",
      "2020-07-28 19:12:54 (6.00 MB/s) - ‘./marabou1.elf’ saved [4231816/4231816]\n",
      "\n",
      "--2020-07-28 19:12:54--  https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/MNIST_ITR_REL/mnist_10_layer.nnet\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.24.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.24.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 159523 (156K) [text/plain]\n",
      "Saving to: ‘./mnist_10_layer.nnet’\n",
      "\n",
      "./mnist_10_layer.nn 100%[===================>] 155.78K  --.-KB/s    in 0.09s   \n",
      "\n",
      "2020-07-28 19:12:55 (1.75 MB/s) - ‘./mnist_10_layer.nnet’ saved [159523/159523]\n",
      "\n",
      "/home/burak/nasa-neural-properties/prophecy-mnist\n",
      "-rw-rw-r-- 1 burak burak 4231816 Jul 28 19:12 ./marabou1.elf\n",
      "-rwxrwxrwx 1 burak burak 4231816 Jul 28 19:12 ./marabou1.elf\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/marabou1.elf -O ./marabou1.elf\n",
    "!wget https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/MNIST_ITR_REL/mnist_10_layer.nnet -O ./mnist_10_layer.nnet\n",
    "!pwd\n",
    "!ls -lt ./marabou1.elf\n",
    "!chmod 777 ./marabou1.elf\n",
    "!ls -lt ./marabou1.elf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yy0b_gz46_55"
   },
   "source": [
    "**INVOKE MARABOU FOR VERIFYING POTENTIAL RULES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLuPLXFC6_Rd"
   },
   "outputs": [],
   "source": [
    "def invoke_marabou_chk(layer,neurons,signature,label):\n",
    "  #layer = 1\n",
    "  #neurons = [4, 8, 7, 1, 0, 2, 5, 3, 9, 6] \n",
    "  #signature = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  #label = 6\n",
    "\n",
    "  for lab_indx in range(0,10):\n",
    "    if (lab_indx == label):\n",
    "      continue \n",
    "    not_done = False\n",
    "\n",
    "    print(\"there exists x: x /\\ Rule /\\ y_\" , lab_indx,\" > y_\", label)\n",
    "    #strInp = \"\"\n",
    "    #for i in range(0,784):\n",
    "    #  strInp = strInp + \"x\"+ str(i) + \" >= 0.0\" + \"\\n\"\n",
    "    #  strInp = strInp + \"x\"+ str(i) + \" <= 1.0\" + \"\\n\"\n",
    "    #print(strInp)\n",
    "\n",
    "    strInternal = \"\"\n",
    "    for i in range(0,len(neurons)):\n",
    "      strInternal = strInternal + \"ws_\"+ str(layer) + \"_\" + str(neurons[i])\n",
    "      if (signature[i] == 0):\n",
    "         strInternal = strInternal + \" <= 0.0\" + \"\\n\"\n",
    "      else:\n",
    "         strInternal = strInternal + \" >= 0.0\"  + \"\\n\"\n",
    "\n",
    "    strOP = \"-y\"+ str(lab_indx) + \" +y\" + str(label) + \" <= 0.00\" + \"\\n\"\n",
    "\n",
    "    #Write to a property file\n",
    "    file1 = open('property.txt',\"w\")\n",
    "    #file1.writelines(strInp) \n",
    "    file1.writelines(strInternal) \n",
    "    file1.writelines(strOP) \n",
    "    file1.close() \n",
    "\n",
    "#    file1 = open('property.txt',\"r\")  \n",
    "#    print(\"PROPERTY FILE IS \")\n",
    "#    print(file1.read())\n",
    "#    file1.close()\n",
    "\n",
    "   ## UNCOMMENT - use stripped network\n",
    "    !./marabou1.elf ./mnist_10_layer.nnet ./property.txt --summary-file=summary1.txt --verbosity=0\n",
    "    print(\"SUMMARY:\")\n",
    "    f = open('summary1.txt', 'r')\n",
    "    file_contents = f.read()\n",
    "    print (file_contents)\n",
    "    f.close()\n",
    "    if (file_contents.find('UNSAT') == -1):\n",
    "        not_done = True\n",
    "        break\n",
    "\n",
    "  if (not_done == False):\n",
    "     print(\"\\n RULE PROVED TO BE A PROPERTY!\")\n",
    "     return True\n",
    "  else:\n",
    "     print (\"PROPERTY COULD NOT BE PROVED:\")\n",
    "     return False\n",
    "  \n",
    "  #f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yK1Pr1agnsoi"
   },
   "source": [
    "### Examine clusters/invariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZbOQkQU0zBz6"
   },
   "outputs": [],
   "source": [
    "def get_decision_path(estimator, inp):\n",
    "  # Extract the decision path taken by an input as an ordered list of indices\n",
    "  # of the neurons that were evaluated.\n",
    "  # See: http://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html\n",
    "  n_nodes = estimator.tree_.node_count\n",
    "  feature = estimator.tree_.feature\n",
    "\n",
    "  # First let's retrieve the decision path of each sample. The decision_path\n",
    "  # method allows to retrieve the node indicator functions. A non zero element of\n",
    "  # indicator matrix at the position (i, j) indicates that the sample i goes\n",
    "  # through the node j.\n",
    "  X_test = [inp]\n",
    "  node_indicator = estimator.decision_path(X_test)\n",
    "  # Similarly, we can also have the leaves ids reached by each sample.\n",
    "  leaf_id = estimator.apply(X_test)\n",
    "  # Now, it's possible to get the tests that were used to predict a sample or\n",
    "  # a group of samples. First, let's make it for the sample.\n",
    "  node_index = node_indicator.indices[node_indicator.indptr[0]:\n",
    "                                      node_indicator.indptr[1]]\n",
    "  neuron_ids = []\n",
    "  for node_id in node_index:\n",
    "    if leaf_id[0] == node_id:\n",
    "        continue\n",
    "    neuron_ids.append(feature[node_id])\n",
    "  return neuron_ids\n",
    "\n",
    "def get_suffix_cluster(neuron_ids, neuron_sig,suffixes):\n",
    "  # Get the cluster of inputs that such that all inputs in the cluster\n",
    "  # have provided on/off signature for the provided neurons.\n",
    "  #\n",
    "  # The returned cluster is an array of indices (into mnist.train.images).\n",
    "  return np.where((suffixes[:, neuron_ids] == neuron_sig).all(axis=1))[0]\n",
    "\n",
    "def is_consistent_cluster(cluster, predictions):\n",
    "  # Check if all inputs within the cluster have the same prediction.\n",
    "  # 'cluster' is an array of input ids.\n",
    "  pred = predictions[cluster[0]]\n",
    "  for i in cluster:\n",
    "    if predictions[i] != pred:\n",
    "      return False\n",
    "  return True\n",
    "\n",
    "def is_misclassified(i):\n",
    "  return train_predictions[i] != mnist.train.labels[i]\n",
    "\n",
    "def visualize_conductances(img, label, neuron_ids, signature,only_on=False):\n",
    "  # Visualize the conductances for the provided image.\n",
    "  # Args:\n",
    "  # - img: the provided mnist image\n",
    "  # - label: prediction label w.r.t. conductance must be computed\n",
    "  # - neuron_ids: list of neurons indices from the suffix tensor for which\n",
    "  #    conductances must be computed.\n",
    "  # - only_on: If True then conductance is computed only for those neurons\n",
    "  #    that are on for the given image. \n",
    "  vis = [mnist_to_pil_img(img)]\n",
    "  #suffix = fingerprint_signature([img],curr_lay)\n",
    "  sumigc = 0.0\n",
    "  for i, id in enumerate(neuron_ids):\n",
    "    if only_on and signature[i] != 1:\n",
    "      continue  \n",
    "    igc = conductance(img, label, neuron_id=id)\n",
    "    for indx in range(0,len(igc)):\n",
    "      #print(indx,igc[indx]) ## a -ve gradient indicates the pixel value decreases the value of the neuron, making it go towards zero and negative\n",
    "      if (signature[i] != 1): ## in a property if we want the o/p of a neuron to be zero, pixels which increase the neurons output should be given negative weightage and vice versa\n",
    "         igc[indx] = -(igc[indx])\n",
    "    sumigc = sumigc + igc \n",
    "  \n",
    "  avgigc = sumigc / len(neuron_ids) ## gradient of each pixel w.r.t entire property - HIGHER VALUE INDICATES THE PIXEL HAS HIGHER CHANCE OF MAINTAINING THE PROPERTY\n",
    "  maxval = abs(max(avgigc, key=abs))\n",
    "  minval = abs(min(avgigc, key=abs))\n",
    "  threshold = (maxval - minval)/2.0\n",
    "  #print(\"MAX ATR:\", maxval, \"MIN ATR:\", minval, \"THRESH:\", threshold)\n",
    "  avgigc = 1.0 * avgigc * (abs(avgigc) >= threshold) ## pixels with less significance in either SAT or DIS-SAT the property get blacked out\n",
    "  \n",
    "  \n",
    "  vis.append(visualize_attrs2(255*mnist_to_rgb(img), mnist_to_rgb(avgigc)))\n",
    "  return combine(vis)\n",
    "\n",
    "def get_invariant_inp(estimator, ref_id, suffixes):\n",
    "  # Returns an invariant found w.r.t. the provided reference input\n",
    "  # Args\n",
    "  #  - inp: reference input, shape <784,>\n",
    "  # Returns:\n",
    "  #  - cluster: Indices of training inputs that satisfy the invariant\n",
    "  #  - neuron_id: A list of neurons such that all inputs that agree with\n",
    "  #    the reference input on the on/off status of these neurons have the\n",
    "  #    same prediction as the reference input.\n",
    "  ref_img = mnist_inp_images[ref_id]\n",
    "  ref_suffix = suffixes[ref_id]\n",
    "  print('PREFIX',ref_suffix)\n",
    "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
    "  print('NEURON IDS',neuron_ids)\n",
    "  neuron_sig = ref_suffix[neuron_ids]\n",
    "  print('NEURON SIGNATURE',neuron_sig)\n",
    "  cluster = get_suffix_cluster(neuron_ids, neuron_sig,suffixes)\n",
    "  imgs = []\n",
    "  cnt = 0\n",
    "  for indx1 in range(0,len(cluster)):\n",
    "    img = mnist.train.images(cluster[indx1])\n",
    "    fnd = 1\n",
    "    for i in range(0,len(img)):\n",
    "      if (ref_img[i] != img[i]):\n",
    "        fnd = 0\n",
    "        break\n",
    "    if (fnd == 1):\n",
    "        ref_id = cnt\n",
    "    cnt = cnt + 1\n",
    "    imgs.append(img)\n",
    "    \n",
    "  imgs_suffixes = fingerprint_signature(imgs,t_fc2)\n",
    "  ref_suffix = imgs_suffixes[ref_id]\n",
    "  print('PREFIX',ref_suffix)\n",
    "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
    "  print('NEURON IDS',neuron_ids)\n",
    "  neuron_sig = ref_suffix[neuron_ids]\n",
    "  print('NEURON SIGNATURE',neuron_sig)\n",
    "  cluster = get_suffix_cluster(neuron_ids, neuron_sig,imgs_suffixes)\n",
    "    \n",
    "  return cluster, neuron_ids, neuron_sig\n",
    "\n",
    "def get_invariant(estimator, ref_id):\n",
    "  # Returns an invariant found w.r.t. the provided reference input\n",
    "  # Args\n",
    "  #  - ref_id: Index (into mnist.train.images) of the reference input\n",
    "  # Returns:\n",
    "  #  - cluster: Indices of training inputs that satisfy the invariant\n",
    "  #  - neuron_id: A list of neurons such that all inputs that agree with\n",
    "  #    the reference input on the on/off status of these neurons have the\n",
    "  #    same prediction as the reference input.\n",
    "  ref_img = mnist.train.images[ref_id]\n",
    "  ref_suffix = train_suffixes[ref_id]\n",
    "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
    "  neuron_sig = ref_suffix[neuron_ids]\n",
    "  cluster = get_suffix_cluster(neuron_ids, neuron_sig, train_suffixes)\n",
    "  return cluster, neuron_ids, neuron_sig\n",
    "\n",
    "\n",
    "def get_all_invariants(estimator):\n",
    "  # Returns a dictionary mapping each decision tree prediction class\n",
    "  # to a list of invariants. Each invariant is specified as a triple:\n",
    "  # - neuron ids\n",
    "  # - neuron signature (for the neuron ids)\n",
    "  # - number of training samples that hit it\n",
    "  # The neuron ids and neuron signature can be supplied to get_suffix_cluster\n",
    "  # to obtain the cluster of training instances that hit the invariant.\n",
    "  def is_leaf(node):\n",
    "    return estimator.tree_.children_left[node] == estimator.tree_.children_right[node]\n",
    "\n",
    "  def left_child(node):\n",
    "    return estimator.tree_.children_left[node]\n",
    "\n",
    "  def right_child(node):\n",
    "    return estimator.tree_.children_right[node]\n",
    "  \n",
    "  def get_all_paths_rec(node):\n",
    "    # Returns a list of triples corresponding to paths\n",
    "    # in the decision tree. Each triple consists of\n",
    "    # - neurons encountered along the path\n",
    "    # - signature along the path\n",
    "    # - prediction class at the leaf\n",
    "    # - number of training samples that hit the path\n",
    "    # The prediction class and number of training samples\n",
    "    # are set to -1 when the leaf is \"impure\".\n",
    "    feature = estimator.tree_.feature\n",
    "    if is_leaf(node):\n",
    "      values = estimator.tree_.value[node][0]\n",
    "      if len(np.where(values != 0)[0]) == 1:\n",
    "        cl = estimator.classes_[np.where(values != 0)[0][0]]\n",
    "        nsamples = estimator.tree_.n_node_samples[node]\n",
    "      else:\n",
    "        # impure node\n",
    "        cl = -1\n",
    "        nsamples = -1\n",
    "      return [[[], [], cl, nsamples]]\n",
    "    # If it is not a leaf both left and right childs must exist\n",
    "    paths = [[[feature[node]] + p[0], [0] + p[1], p[2], p[3]] for p in get_all_paths_rec(left_child(node))]\n",
    "    paths += [[[feature[node]] + p[0], [1] + p[1], p[2], p[3]] for p in get_all_paths_rec(right_child(node))]\n",
    "    return paths\n",
    "  paths =  get_all_paths_rec(0)\n",
    "  #print(\"Obtained all paths\")\n",
    "  invariants = {}\n",
    "  for p in tqdm(paths):\n",
    "    neuron_ids, neuron_sig, cl, nsamples = p\n",
    "    if cl not in invariants:\n",
    "      invariants[cl] = []\n",
    "    # cluster = get_suffix_cluster(neuron_ids, neuron_sig)\n",
    "    invariants[cl].append([neuron_ids, neuron_sig, nsamples])\n",
    "  for cl in invariants.keys():\n",
    "    invariants[cl] = sorted(invariants[cl], key=operator.itemgetter(2), reverse=True)\n",
    "  return invariants\n",
    "\n",
    "\n",
    "def describe_cluster(cluster, neuron_ids, show_samples=False):\n",
    "  neuron_sig = train_suffixes[cluster[0]][neuron_ids]\n",
    "  print(\"Num neurons in invariant\", len(neuron_ids))\n",
    "  print(\"Neuron id and signature\")\n",
    "  \n",
    "  for i in range(0,len(neuron_ids)):\n",
    "    print(\"id:\", neuron_ids[i], \"sig:\", neuron_sig[i])\n",
    "  \n",
    "  print(\"Cluster size: \", len(cluster))\n",
    "  print(\"Num misclassified\", len([i for i in cluster if is_misclassified(i)]))\n",
    "  if show_samples:\n",
    "    for i in range(10):\n",
    "      images = []\n",
    "      for j in range(10):\n",
    "        if 10*i + j >= len(cluster):\n",
    "          break\n",
    "        images.append(mnist_to_pil_img(mnist.train.images[cluster[10*i+j]]))\n",
    "      if len(images) > 0:\n",
    "        show_img(combine(images))\n",
    " \n",
    "def common_nodes(cls,suffixes):\n",
    "    cnt = 0\n",
    "    common = np.zeros(10,dtype=int)\n",
    "    prev = np.zeros(10,dtype=int)\n",
    "    \n",
    "    for indx in range(0, len(cls)):\n",
    "        i = cls[indx]\n",
    "        cnt = cnt + 1\n",
    "        for j in range(0,len(suffixes[i])):\n",
    "          if (common[j] == -1):\n",
    "             continue\n",
    "          if ((indx != 0) and (suffixes[i][j] != prev[j])):\n",
    "             common[j] = -1\n",
    "          else:\n",
    "             common[j] = suffixes[i][j]\n",
    "          prev[j] = suffixes[i][j]\n",
    "\n",
    "\n",
    "    print('COMMON NODES IN CLUSTER for CLASS:',cl,cnt)\n",
    "    com = []\n",
    "    for k in range(0,len(common)):\n",
    "        if (common[k] != -1):\n",
    "           com.append((k,common[k]))\n",
    "    print(com)\n",
    "\n",
    "    return\n",
    "    \n",
    "def decision_prefs(cls,suffixes):\n",
    "    images = mnist.train.images\n",
    "    imgsCom = []\n",
    "    imgs = []\n",
    "    for indx in range(0, len(cls)):\n",
    "        print('IMG:')\n",
    "        print(list(zip(images[cls[indx]])))\n",
    "        imgs.append(images[cls[indx]])\n",
    "        imgsCom.append(images[cls[indx]])\n",
    "            \n",
    "    dec_prefixes= fingerprint_signature(imgs,layer)\n",
    "    prefixes = []\n",
    "    for indx in range(0,len(dec_prefixes)):\n",
    "       dec_pref = dec_prefixes[indx]\n",
    "    \n",
    "       match = 0\n",
    "       for indx1 in range(0, len(prefixes)):\n",
    "          match = 1\n",
    "          for i in range(0,len(prefixes[indx1])):\n",
    "             if (dec_pref[i] != prefixes[indx1][i]):\n",
    "                match = 0\n",
    "                break\n",
    "          if (match == 1):\n",
    "             break\n",
    "    \n",
    "       if (match == 0):\n",
    "          prefixes.append(dec_pref)\n",
    "    \n",
    "    print('DECISION PREFIXES IN CLUSTER for CLASS:',cl,cnt)\n",
    "    for k in range(0,len(prefixes)):\n",
    "      print(prefixes[k])\n",
    "\n",
    "    return\n",
    "    \n",
    "  \n",
    "  #print('LAYER INPS:')\n",
    "  #min = np.zeros(10)\n",
    "  #max = np.zeros(10)\n",
    "  #for dim in range(0,10):\n",
    "  #    min[dim] = 1000\n",
    "  #    max[dim] = -1000\n",
    "          \n",
    "  #prevlayer_vals = get_prediction(imgsCom,prevlayer)      \n",
    "  #print('MIN, MAX LAYER INPS:',len(prevlayer_vals))\n",
    "  #for i in range(0,len(prevlayer_vals)):\n",
    "  #    if (i == 0):\n",
    "  #      print(zip(prevlayer_vals[i]))\n",
    "  #    for dim in range(0,10):\n",
    "  #        if ( prevlayer_vals[i][dim] < min[dim]):\n",
    "  #            min[dim] = prevlayer_vals[i][dim]\n",
    "  #        if ( prevlayer_vals[i][dim] > max[dim]):\n",
    "  #            max[dim] = prevlayer_vals[i][dim]\n",
    "    \n",
    "  #print('MIN')\n",
    "  #print(zip(min))\n",
    "  #print('MAX')\n",
    "  #print(zip(max))    \n",
    "    \n",
    "  #df = pd.DataFrame(df, columns=['Prediction Class', 'Num Instances', 'Num Invariants', 'Num Invariants with cluster size >= 10', 'Size of largest invariant cluster'])\n",
    "  #df = pd.DataFrame(df,columns=['Pred Class','Total #Neurons','# Invariants'])\n",
    "  #return df\n",
    "\n",
    "\n",
    "def describe_all_invariants(all_invariants):\n",
    "  df = []\n",
    "  for cl, invs in all_invariants.iteritems(): \n",
    "    inv = invs[0]\n",
    "    clus = get_suffix_cluster(inv[0],inv[1],train_suffixes)\n",
    "    #print(len(clus))\n",
    "    misCl = 0\n",
    "    for i in range(0,len(clus)):\n",
    "      indx = clus[i]\n",
    "      if (is_misclassified(indx) == True):\n",
    "        misCl = misCl + 1\n",
    "    print('class:',cl,',masSup:',inv[2],',#misCl:',misCl)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MD5zSngzt1Gz"
   },
   "outputs": [],
   "source": [
    "def describe_invariants_all_labels(all_invariants,prevlayer,layer,suffixes,label):\n",
    "  \n",
    "  print(\"\\n PRINTING PURE RULES WITH SUPPORT MORE THAN 1000:\");\n",
    "  for cl, invs in all_invariants.items():\n",
    "    if ((label == -1) and (cl == -1)):\n",
    "        continue\n",
    "    \n",
    "    if ((label != -1) and (cl != label)):\n",
    "        continue\n",
    "    \n",
    "    for indx in range (0, len(invs)):\n",
    "      inv = invs[indx]\n",
    "      cls = get_suffix_cluster(inv[0],inv[1],suffixes)\n",
    "      \n",
    "      neurons = inv[0]\n",
    "      signature = inv[1]\n",
    "\n",
    "      if (len(cls) <= 1000):\n",
    "        continue\n",
    "      print(\"Class:\", cl, \", Rule:(neurons:\",inv[0],\",signature:\",inv[1],\"), Support:\",inv[2],\", Num misclassified\", len([i for i in cls if is_misclassified(i)]));\n",
    "\n",
    "\n",
    "\n",
    "      print(\"\\n CHECK IF RULE IS A PROPERTY: for all x: x /\\ Rule => Label\")\n",
    "      print(\"INVOKE MARABOU TO FIND COUNTER-EXAMPLES IN THE REGION THAT GET CLASSIFIED TO A DIFFERENT LABEL\")\n",
    "      \n",
    "      if (LAYER == 1):\n",
    "         prov = invoke_marabou_chk(LAYER,neurons,signature,cl)\n",
    "\n",
    "\n",
    "      print(\"Pixels impacting property for some of the inputs satisfying the property\")\n",
    "      interval = int(len(cls)/20)\n",
    "      #interval = 1\n",
    "    \n",
    "      i = 0\n",
    "      while (i < len(cls)):\n",
    "        ref_id = cls[i]\n",
    "        if (is_misclassified(ref_id)):\n",
    "          print(\"MISCLASSIFIED\")\n",
    "        else:\n",
    "          print(\"CORRECTLY CLASSIFIED\")\n",
    "       # describe_input(ref_id)\n",
    "        show_img(visualize_conductances(mnist.train.images[ref_id], train_predictions[ref_id], inv[0], inv[1],only_on=False))\n",
    "        i = i + interval\n",
    "\n",
    "    \n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "L2F_QleSkgvY",
    "outputId": "eb0fad70-251e-414e-8582-365b62e24fca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 550/550 [00:00<00:00, 911.47it/s]\n",
      "100%|██████████| 536/536 [00:00<00:00, 974067.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUFFIXES COMPUTED FOR ALL TRAINING DATA AT LAYER: 1\n",
      "DECISION-TREE CONSTRUCTED AT LAYER: 1\n",
      "\n",
      " PRINTING PURE RULES WITH SUPPORT MORE THAN 1000:\n",
      "Class: 6 , Rule:(neurons: [4, 8, 7, 1, 0, 2, 5, 3, 9, 6] ,signature: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ), Support: 3575 , Num misclassified 19\n",
      "\n",
      " CHECK IF RULE IS A PROPERTY: for all x: x /\\ Rule => Label\n",
      "INVOKE MARABOU TO FIND COUNTER-EXAMPLES IN THE REGION THAT GET CLASSIFIED TO A DIFFERENT LABEL\n",
      "there exists x: x /\\ Rule /\\ y_ 0  > y_ 6\n",
      "Network: ./mnist_10_layer.nnet\n",
      "Number of layers: 12. Input layer size: 784. Output layer size: 10. Number of ReLUs: 100\n",
      "Total number of variables: 994\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 1 0\n",
      "\n",
      "there exists x: x /\\ Rule /\\ y_ 1  > y_ 6\n",
      "Network: ./mnist_10_layer.nnet\n",
      "Number of layers: 12. Input layer size: 784. Output layer size: 10. Number of ReLUs: 100\n",
      "Total number of variables: 994\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 1 0\n",
      "\n",
      "there exists x: x /\\ Rule /\\ y_ 2  > y_ 6\n",
      "Network: ./mnist_10_layer.nnet\n",
      "Number of layers: 12. Input layer size: 784. Output layer size: 10. Number of ReLUs: 100\n",
      "Total number of variables: 994\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 1 0\n",
      "\n",
      "there exists x: x /\\ Rule /\\ y_ 3  > y_ 6\n",
      "Network: ./mnist_10_layer.nnet\n",
      "Number of layers: 12. Input layer size: 784. Output layer size: 10. Number of ReLUs: 100\n",
      "Total number of variables: 994\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 1 0\n",
      "\n",
      "there exists x: x /\\ Rule /\\ y_ 4  > y_ 6\n",
      "Network: ./mnist_10_layer.nnet\n",
      "Number of layers: 12. Input layer size: 784. Output layer size: 10. Number of ReLUs: 100\n",
      "Total number of variables: 994\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 1 0\n",
      "\n",
      "there exists x: x /\\ Rule /\\ y_ 5  > y_ 6\n",
      "Network: ./mnist_10_layer.nnet\n",
      "Number of layers: 12. Input layer size: 784. Output layer size: 10. Number of ReLUs: 100\n",
      "Total number of variables: 994\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 1 0\n",
      "\n",
      "there exists x: x /\\ Rule /\\ y_ 7  > y_ 6\n",
      "Network: ./mnist_10_layer.nnet\n",
      "Number of layers: 12. Input layer size: 784. Output layer size: 10. Number of ReLUs: 100\n",
      "Total number of variables: 994\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 1 0\n",
      "\n",
      "there exists x: x /\\ Rule /\\ y_ 8  > y_ 6\n",
      "Network: ./mnist_10_layer.nnet\n",
      "Number of layers: 12. Input layer size: 784. Output layer size: 10. Number of ReLUs: 100\n",
      "Total number of variables: 994\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 1 0\n",
      "\n",
      "there exists x: x /\\ Rule /\\ y_ 9  > y_ 6\n",
      "Network: ./mnist_10_layer.nnet\n",
      "Number of layers: 12. Input layer size: 784. Output layer size: 10. Number of ReLUs: 100\n",
      "Total number of variables: 994\n",
      "Property: ./property.txt\n",
      "\n",
      "UNSAT\n",
      "SUMMARY:\n",
      "UNSAT 0 1 0\n",
      "\n",
      "\n",
      " RULE PROVED TO BE A PROPERTY!\n",
      "Pixels impacting property for some of the inputs satisfying the property\n",
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-fc52fd7b9087>:56: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return np.clip(attrs/max(abs(h), abs(l)), -1.0, 1.0)\n",
      "<ipython-input-38-fc52fd7b9087>:56: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.clip(attrs/max(abs(h), abs(l)), -1.0, 1.0)\n",
      "<ipython-input-38-fc52fd7b9087>:124: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  pos_attrs = attrs * (attrs >= 0.0)\n",
      "<ipython-input-38-fc52fd7b9087>:126: RuntimeWarning: invalid value encountered in less\n",
      "  neg_attrs = -1.0 * attrs * (attrs < 0.0)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/roPB/hDUfGesiwsQI40HmXFzJ/q4I+7Mf6d65+vS/EF7ceE/hdoHh6yBgl1uA6jqEyfK0qMxEaeuNoGex/GgDjvFdnomn+Ibi08PX819p0QVVuJQAXbA3EYA+XdnHt69a9l/Zl/5mn/ALdP/a1eMat4U17QrC1vdV0m6s7e6JWJp027iOxB5B+uM17P+zL/AMzT/wBun/tagD0D42/8kh13/t3/APSiOvkCvr/42/8AJIdd/wC3f/0ojr5AoAKKKKAPr/4Jf8kh0L/t4/8ASiSvQK8/+CX/ACSHQv8At4/9KJK9AoA+AK970Dx74DsPDHhfWfElub7xBY2ZtIYbcea0KI7KpZSwVWI5Gee47V4JRQB6H8TvilcfECWC2itBaaZbOXjjYhpHYjG5j24zwPXvXefsy/8AM0/9un/tavAK9/8A2Zf+Zp/7dP8A2tQB6B8bf+SQ67/27/8ApRHXyBX1/wDG3/kkOu/9u/8A6UR18gUAW5I9OEUpjurppB/qla2VQ3zEfMd52/LtPAPJI6DcalFFJKwkrH1/8Ev+SQ6F/wBvH/pRJXoFef8AwS/5JDoX/bx/6USV6BTGf//Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/r0TwP4R0ceGtQ8Y+MIbhtFtiI7aCJirXcufu5HIHQZ46nnivPUXfIq+pAr2f4taddTeJ/C/w60dES0t7eNbdScbpHJUs5/4Dn8W9aAPHb2aC4vp5ra1W1geRmjgV2cRqTwu5uTgcZNe8fsy/wDM0/8Abp/7WrCn+GPgdLm48OQeLbybxTBG7MEt82+9F3MpAHHAI+/wRzzxW7+zL/zNP/bp/wC1qAPQPjb/AMkh13/t3/8ASiOvkCvr/wCNv/JIdd/7d/8A0ojr5CjYJIrMiuAQSjZw3scEH8jQA2iingR+SxLuJdw2qF+UjnJJzwenGDnJ5GOQD68+CX/JIdC/7eP/AEokr0CvP/gl/wAkh0L/ALeP/SiSvQKAPgEEqQR1HIr2r/hM/BfjrSdOvPFWqXWheKdN2qmo2sDMZcchvkU9+ccYPQ4NeKUUAer+KPiLokElzJ4c+36jrM8Jt31zUAiOkZ6iNFUDJBI3EA11H7Mv/M0/9un/ALWrwCvf/wBmX/maf+3T/wBrUAegfG3/AJJDrv8A27/+lEdfIFfX/wAbf+SQ67/27/8ApRHXyBQBYCWX2RmNxcC52jbGIBsJ3HILb8gbcHO05JIwMZMUpjMzmFHSIsdiu25gOwJAGT74H0plFJISVj6/+CX/ACSHQv8At4/9KJK9Arz/AOCX/JIdC/7eP/SiSvQKYz//2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDwKGGS4njhiUvJIwVVHUk9BXQeC/CN74w8TwaVAjpGG3XUuOIIwfmY/wAh71zlev3bt4A+F+n6LpcbSeIvFUAuLp4ss6W5zsVQB3Bx9d/tgA8+8Z/2EPFt+nhqNo9IjcRwbnLbtqgM2SScFgxHse3SvYf2Zf8Amaf+3T/2tXmOofC7xdpXhmTX7/TDb2cYBdXceYqkgAlOoHPfmvTv2Zf+Zp/7dP8A2tQB6B8bf+SQ67/27/8ApRHXyBX1/wDG3/kkOu/9u/8A6UR18gUAFFFFAH1/8Ev+SQ6F/wBvH/pRJXoFef8AwS/5JDoX/bx/6USV6BQB8AV9BeFvin4Kg8NafcanJLZ+I4LFdPM8Vs0rRRx8IU3ZUZBz9c54xXz7RQB6X46+J0Ws2Fxo2gQ3UVhdMr3l3evvubplOQCckKnfaOPQAcV2n7Mv/M0/9un/ALWrwCvf/wBmX/maf+3T/wBrUAegfG3/AJJDrv8A27/+lEdfIFfX/wAbf+SQ67/27/8ApRHXyBQBo3i6MRK1jLfqRny0njRt/wC8bGWDDbiPZ2OW3dBiqMpjMzmFHSIsdiu25gOwJAGT74H0plFJK3UmMbdT6/8Agl/ySHQv+3j/ANKJK9Arz/4Jf8kh0L/t4/8ASiSvQKZR/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ro/A/heTxd4ot9O3iK2UGa7nb7sUK8sx5HsPqRXOV6j4R0TVZfh1Ja6FaSvrHiS8e381cBUs4Qpkyx+6C7gH1xj2IBwPiJtLfxHqJ0SJotL+0OLVGYsRHnjk5P5mvbP2Zf+Zp/7dP8A2tXlfjfwJeeB5NOS6vbW7+2Qs++2bKo6sVZM98cc8c5HavVP2Zf+Zp/7dP8A2tQB6B8bf+SQ67/27/8ApRHXyBX1/wDG3/kkOu/9u/8A6UR18gUAFFFFAH1/8Ev+SQ6F/wBvH/pRJXoFef8AwS/5JDoX/bx/6USV6BQB8AV7L4C+I/hmLwE3g/xObyyjXeiXlmvJjZt5UlRuGTwcA5GK8aooA7T4ieItH1e+07TvDcckehaVbeTaiQHczMdzsc89Tjn0z3r0v9mX/maf+3T/ANrV4BXv/wCzL/zNP/bp/wC1qAPQPjb/AMkh13/t3/8ASiOvkCvr/wCNv/JIdd/7d/8A0ojr5AoAsBLL7IzG4nFyFG2MQDYTuOQW35A24OdpySRgYyWXUkMt3NJbweRC8jNHDvLeWpPC5PJwOM1FRSSElrc+v/gl/wAkh0L/ALeP/SiSvQK8/wDgl/ySHQv+3j/0okr0CmM//9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/q7pOk3uuarb6bp1u893cPsjjUdff2AHJPYCqVez6Tpt34V8B6fY+HtPln8aeJoDJ50P37azJ65P3MjAzwOSc/KKAOZ8Y6R4L8K6KdCtZZ9U8UK6/ab2NysFuw+/GB0b07/UY21337Mv/M0/9un/ALWryjxf4B1zwULNtYW3/wBL3bTDKH2suMq3ofmB/GvV/wBmX/maf+3T/wBrUAegfG3/AJJDrv8A27/+lEdfIFfX/wAbf+SQ67/27/8ApRHXyBQA5EMkiopUFiANzBR+JPAptSTDY3lFIw0eVZkbcGOTznJB9OOMAfUx0DatofX/AMEv+SQ6F/28f+lElegV5/8ABL/kkOhf9vH/AKUSV6BQI+AK96tfib4Z1rwt5d1rFx4b8QXEEUF9e29o0rSxxDG1Cv3N2T0xivBaKAOz8beIdEvdN0jQPDkFwNM0sSMbm5AElzK5G5yB0HyjH8hivTP2Zf8Amaf+3T/2tXgFe/8A7Mv/ADNP/bp/7WoA9A+Nv/JIdd/7d/8A0ojr5Ar6/wDjb/ySHXf+3f8A9KI6+QKAL06aV9nJgnvPOVeBJCu2Rt7c5D5QbNhx83zbhnGDVSUxmZzCjpEWOxXbcwHYEgDJ98D6UyiklYlRt1Pr/wCCX/JIdC/7eP8A0okr0CvP/gl/ySHQv+3j/wBKJK9AplH/2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/q3pmmXmsalBp+n273F3O2yOJOrGqlew6FpNz4G0PT49NtvtXjjxNDi0j4/0K2YH5wezkY5J4wfQ5AOR+Jel6DofiKHSdFiVZbS2SO/aOVnQ3OPnA3EkY+p544xXpn7Mv/M0/wDbp/7Wrz/xb4BsdE0O51ODxRHqd9aXEdtqECwN8k7hmIEmcNjaefUHoeK9A/Zl/wCZp/7dP/a1AHoHxt/5JDrv/bv/AOlEdfIFfX/xt/5JDrv/AG7/APpRHXyHDC9xOkMYy7sFA96ALmj2DX9+iFA0KfNKScBVHJye3Sqlx5RuZPIBEW47ATnit94GVJNGtXRYY2D3lyQM5GeM+nPTv+FZGoWUVoYTDcieOVN6kIVwMkc5+lIdj6z+CX/JIdC/7eP/AEokr0CvP/gl/wAkh0L/ALeP/SiSvQKYj4Ar3m1+JHg3VNKv9bvby50nxTNpf9nMEgacFRyWiwMBm6ZZhjA+p8GooA6HxB4li1LT7TR9MsjYaPaM0kcLSeZJJK33pJGwMtxgYAAHFevfsy/8zT/26f8AtavAK9//AGZf+Zp/7dP/AGtQB6B8bf8AkkOu/wDbv/6UR18kWN0bK9iuAu7Yc4z1HSvrf42/8kh13/t3/wDSiOvkCgDqdSvPDhsGWxlvTulMrW7xgFyWOAXz8oC7egOTnoOa5/UL19QvGuHjjiBAVY4lwqKBgAfh3PJ6kk1WoqVGxMY263Pr/wCCX/JIdC/7eP8A0okr0CvP/gl/ySHQv+3j/wBKJK9Aqij/2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/rR0HRL3xHrlppGnx77q6kCID0Hck+wGSfpWdXr/AMHtA1GDRde8X6bYNeanbRG002EgYMr43ODkfdU/kSKAOU8ZxeFNGabw9pGnTXF/ZS+XNrD3RxK4++BGBt2g5APXjqa9L/Zl/wCZp/7dP/a1eE6hZXmn381rqFvLBdxsRLHKpVgfcGvdv2Zf+Zp/7dP/AGtQB6B8bf8AkkOu/wDbv/6UR18gV9f/ABt/5JDrv/bv/wClEdfIFAF7TLAXsrtK/l28Kl5X9AB0HuahupbeWQG2tzCoGCC5bPvW79murPwp5EFqshvis00hjy6KpOFUnoD1OP8AEVzVJMNVo0fX/wAEv+SQ6F/28f8ApRJXoFef/BL/AJJDoX/bx/6USV6BTA+AK9k8U/Eew1jw14Y0/wAL6w3hkQBxeW6eciwkbdnzRoS4yGPGevPNeN0UAd78UfE2m+ItQ0lLC9fU3sbFYLjU3gMTXT9SdpAOB7jPJ69a9C/Zl/5mn/t0/wDa1eAV7/8Asy/8zT/26f8AtagD0D42/wDJIdd/7d//AEojr5J0+aCDUIJblC8KuC4AyceoB6kdcV9bfG3/AJJDrv8A27/+lEdfIFAHSXmrR3HiCS4i1No7MMCv7srkdxsAwPp0FZGr3Ftd6xeXFnEYrWSZmiRuqpnjPJ5xVKilYSVj6/8Agl/ySHQv+3j/ANKJK9Arz/4Jf8kh0L/t4/8ASiSvQKYz/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/rqPAfgu68ceIVsIpBBaRL513ct0ijHU/U9B/gDXL17taaVfeFfhhpXh3QkaTxN4vYSM6fI8MO0MwJ5OAvGePvMe1AHlXjX/AIR1fE9xD4XhkTTIAIld5C/nMvDSAnoGPP8Ah0Hr37Mv/M0/9un/ALWrgfE/w+0rS/DtxqGjeI4dTudLaOLVoVQhYnc7QY2xhhuyK779mX/maf8At0/9rUAegfG3/kkOu/8Abv8A+lEdfIFfX/xt/wCSQ67/ANu//pRHXyBQAUU5mDKgCKpUYJGfm5Jycn3xxjpQyhVQh1YsMkDPy8kYOR7Z4z1oHY+vfgl/ySHQv+3j/wBKJK9Arz/4Jf8AJIdC/wC3j/0okr0CgR8AV75oPxI8D6omm6t4knurHW7DTn04rFCWjkVhtLptU7TjPpjJHPFeB0UAeg+JvGfh5PCr+FfB2lT2unzSJJeXd4QZ7lkJKg4yAM4P9B3779mX/maf+3T/ANrV4BXv/wCzL/zNP/bp/wC1qAPQPjb/AMkh13/t3/8ASiOvkCvr/wCNv/JIdd/7d/8A0ojr5AoAvXP2CU3My3M5mZtyILRI0YlznO18INu0gAEZJHAAJqSmMzOYUdIix2K7bmA7AkAZPvgfSmUUkrEqNj6/+CX/ACSHQv8At4/9KJK9Arz/AOCX/JIdC/7eP/SiSvQKZR//2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/r0PwV4P0r/hF9S8Y+K0k/se2VorS3DMhvJiCAAQc4Bxz0znPANcr4U8PT+KvFGn6JbsUe6l2s4GdigZZsd8KCfwro/iZ4mt9Y1e20LQ/l0HR0FrZxoSRIw4aTpnJPHfpnvQBwde/wD7Mv8AzNP/AG6f+1qxPDHwd020tbO88ear/Zr37rFaafGwErs2AuTyQcnoBx3I6V0n7Otr9h1PxnaB94gmt4t2MbtpnGcfhQB2/wAbf+SQ67/27/8ApRHXyBX1/wDG3/kkOu/9u/8A6UR18p6PaLI8t7Op+y2uGdscbjnaufU4P5UAOuLKCx0dfPTN7OQyckGNRnPGcc8df8ayqtyvcatqJZVLSyN8q+g9PoK2G0HTrfT7lbnUGGoJD5qRxoGT6E5yOwzjv0GKTdhPRXPpz4Jf8kh0L/t4/wDSiSvQK8/+CX/JIdC/7eP/AEokr0CmM+K/h54hsPDXipbrVElawnt5bWdoT86K64LL7iu68MWnwk8O+KLbWW8ZXF4ls/mQ202nTDa4+6xYJzg89OuK8aooA9a174heE4/El3rum6fqWtau2RbXWryqYbdgfleOIL27A4x9a6j9mqR5pfFcsrs8jtaszMclifOyTXz7Xv8A+zL/AMzT/wBun/tagD0D42/8kh13/t3/APSiOvlfR5dPljew1K4ktYJZFYzohfZ9VHWvqj42/wDJIdd/7d//AEojr5AoewHWWEvh3S7e7lh1S6kuioWErblGHzevIHAB+pHYZONd39oI5orC3kRZWO6Wdw8hXOcZAH4+tZlFJKwkmup9f/BL/kkOhf8Abx/6USV6BXn/AMEv+SQ6F/28f+lElegUxn//2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/q3pmmXms6nbadYQNPd3DiOKNe5P8vrVSvS4mT4b+D43gbf4s8QWwKFR81hat0K8ZEj57dMdscgGL4p07w14b07+xLOQarrodTd36OwhtyBzFGAcPz1Yg+2D09O/Zl/5mn/t0/8Aa1eN3vhDxHp+kHV77Rr22sdwUzTxFBk9OvPPrXsn7Mv/ADNP/bp/7WoA9A+Nv/JIdd/7d/8A0ojr5Ar6/wDjb/ySHXf+3f8A9KI6+Q4YmnmSJBlnYKKALGn2DX9xsEiRRqNzyucKopt41qZFS0RgijBdicufXHatDUJPIiGi2IWQIwM0ka7jLIM9+uBkjjg4HXANZlxaT2pUTxNGWGRuHWkhtW0Prn4Jf8kh0L/t4/8ASiSvQK8/+CX/ACSHQv8At4/9KJK9ApiPgKNgkisRkAgkete56n4w8CazFfaxZeIJtE1298stLPpr3EtvGsYXyYGX5U5H3gQee3bwqigDtPEXi6zk0SXw/ocmpzWU8yz3V3qU2+W4ceiDIQZ56knAye1el/sy/wDM0/8Abp/7WrwCvf8A9mX/AJmn/t0/9rUAegfG3/kkOu/9u/8A6UR18n6NeR2Gqw3ErSLGMq7RjLBWBU4GRngnjPNfWHxt/wCSQ67/ANu//pRHXyBQ9RNXVjpLmTQ1tttrqd0FA5jS12vKcnJZ93HGDjnkkds1j6herdyqIkeOCMFYkd97AZ7tgZP4CqdFJKwJW6n1/wDBL/kkOhf9vH/pRJXoFef/AAS/5JDoX/bx/wClElegUxn/2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/qa0tZ768htLWJpbiZxHHGvVmJwBUNeueBtHTwV4ftvGV3bPc69qTNbaBp23lmYbfOIPbnj2I/vAgA534ieG9I8IQaLokGyTXI4Gl1WZZGbDsQUTGdo2jPTk5BNei/sy/wDM0/8Abp/7Wryjx14b8SeH9c8zxOub2/BuDL5gfeSeeR3B7V6v+zL/AMzT/wBun/tagD0D42/8kh13/t3/APSiOvkCvr/42/8AJIdd/wC3f/0ojr5BVS7BVBLE4AHegC3penTarfx2sCksx5I7DuaZqAt1vpVtRiFThcEnOO/PvXQpBNp1pJoliIJb67CNczYGYQM/IGPTryR145rmZoXt5nhlXDocEUk7jaa0a1Prv4Jf8kh0L/t4/wDSiSvQK8/+CX/JIdC/7eP/AEokr0CmI+AkKrIpddygglc4yPSvo0fEz4bGePxG9xenU4rJbS1sBA2bNQDnyzjYCcgFs5wB05r5wooA6Txv4yvvG2unULseXDGvlW1uGLCKMdBk9T3J7n8K9b/Zl/5mn/t0/wDa1eAV7/8Asy/8zT/26f8AtagD0D42/wDJIdd/7d//AEojr5N0m4gtdUt5rkN5Kt8xQZKj1AyM49M19ZfG3/kkOu/9u/8A6UR18gUAdlda3otpHNPp89zLfSOZCxhCKzl264I2gLtwozzkdK5K4uJru5luLiRpJpWLu7HJYnqTUVFSo2JjGysfX/wS/wCSQ6F/28f+lElegV5/8Ev+SQ6F/wBvH/pRJXoFUUf/2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/rs9G8N6bH8PNY8T62sx3OtlpSRvt3znlmPsoHfg8jriuMr0r4o288HiHSfA2lwvLb6TbRRW8Ua5aeaVQ7uQO5JH60Aea17/APsy/wDM0/8Abp/7Wrgpfhb9n87T5fEmnf8ACRxwNP8A2TEjucKhdlaUfKrYHQ/nXe/sy/8AM0/9un/tagD0D42/8kh13/t3/wDSiOvkCvr/AONv/JIdd/7d/wD0ojr5CjYJIrMiuAQSrZw3scYP5UANoopzKFVCHViwyQM/LyRg5HtnjPWgD69+CX/JIdC/7eP/AEokr0CvP/gl/wAkh0L/ALeP/SiSvQKAPgCvatF8eeCNW8UaX4r197/TPEFkqrO8UfmQXREZXdgAlT/nnt4rRQB6lrnjLwVpMOqDwfpl5PqmoiRZNUv2G6JZAQ/ljrkgkZOOveut/Zl/5mn/ALdP/a1eAV7/APsy/wDM0/8Abp/7WoA9A+Nv/JIdd/7d/wD0ojr5Ar6/+Nv/ACSHXf8At3/9KI6+QKALASy+yMxuLgXO0bYxANhO45BbfkDbg52nJJGBjJbcNbs4NtFLGnORJIHP3jjkKP4do9yCeM4ENFKwkj6/+CX/ACSHQv8At4/9KJK9Arz/AOCX/JIdC/7eP/SiSvQKYz//2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/rW8M+Hb3xX4htNFsNguLliAzk7VABJY47AAmsmvZfA9ufA3wl1jxxsifUr/ABaWG8HdENxUkHg5PLcHog96AOO+IHhfw74TnttN0vW5tS1SNnXUAY9scTDGAvHXO7PJ/CvS/wBmX/maf+3T/wBrV4CzM7s7sWZjkknJJr379mX/AJmn/t0/9rUAegfG3/kkOu/9u/8A6UR18gV9f/G3/kkOu/8Abv8A+lEdfIFAE1tbvdTiFCoYqxy3TgE8nt06ngdSQMmoasylo7SFPLjCyqJNwjO44Zx94j6j5TtOBnkcVqSKatofX/wS/wCSQ6F/28f+lElegV5/8Ev+SQ6F/wBvH/pRJXoFMk+AK+l/Avi3w9d+FPDH/FVWuhtpEDQ32nTyIqXYIwSQxGSSpYEZI3H15+aKKAOm+IN/oupeONTuvD9vHDpzSYj8sEK5A+ZwOwJycV6z+zL/AMzT/wBun/tavAK9/wD2Zf8Amaf+3T/2tQB6B8bf+SQ67/27/wDpRHXyBX1/8bf+SQ67/wBu/wD6UR18gUAXrn7BKbmZbm4MzNujUWiRoxLnOdr4QbdpwARkleAATRoopJWElbQ+v/gl/wAkh0L/ALeP/SiSvQK8/wDgl/ySHQv+3j/0okr0CmM//9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/r0HRPCemQfCjW/FWuW7M8zpbaQVdgRKCdzEA4I7c5+6a8+r2vx34d1G88GfDnwzoVpJcSzWj3LRQgBXcrGS7c8Y3tljx83WgDxSvf8A9mX/AJmn/t0/9rVwevfBfxd4e0GXV7qK0mhhUPLFbSl5I17kjbjA74Jx9K7z9mX/AJmn/t0/9rUAegfG3/kkOu/9u/8A6UR18gV9f/G3/kkOu/8Abv8A+lEdfJFjEJtQt42wVaRQQfTNAFvUbKGxsbRGUi7cF5DnjHYVmVvanYXWpa5OsCEqm1dzHCrwKz7/AEm604K0wUq3AZDkZ9KAPrH4Jf8AJIdC/wC3j/0okr0CvP8A4Jf8kh0L/t4/9KJK9AoA+AK+j/CXxg8Fy6JYprMs2l6taWH2H7Utuz/LhM7CgbqVBwRxt/P5wooA9bbxl4Q8I2+rJ4cvNb1y81Kze1aa/cJDEr5yQCAS2TnkY688muk/Zl/5mn/t0/8Aa1eAV7/+zL/zNP8A26f+1qAPQPjb/wAkh13/ALd//SiOvka0n+zXcM+M+W4bHrX1z8bf+SQ67/27/wDpRHXyBQB2l5qug31pc/6bcwSTPvKpbBNxzznBIAwB0HXjtk4mo6jYNp32Gxiutvm+Z5s8oYnluMBR22/keOeMaipUbEqNup9f/BL/AJJDoX/bx/6USV6BXn/wS/5JDoX/AG8f+lElegVRR//Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/q3pml32s38Vjp1rJc3UpwkcYyT/AID3qCCGS5njghQvLIwRFUckngCvfpLK7+HehW3hTwdp4vvGl7b+bqF3DHua3Q+jEDAzwM9MZIyRQB554p8B6X4L8NKusaq0nimcq0Wn2pVo4Ez8xlPOTjpgjn1HNegfsy/8zT/26f8AtavP9c+E3jex0mbX9QtkuE2tPcut0ssijqWbn5vXIJr0D9mX/maf+3T/ANrUAegfG3/kkOu/9u//AKUR18gV9f8Axt/5JDrv/bv/AOlEdfJOn2bX97HApwGOWPoO9ADrDTbrUpxFbR7j3YnCqPUmnajbWtpIkMEzTSKD5rfw59BW3eNc3CHStJgRLVGCSSrgb2GR989uexweKxL7SrvTwGnQbCcBlORmkhtWPrL4Jf8AJIdC/wC3j/0okr0CvP8A4Jf8kh0L/t4/9KJK9ApiPhTw1rB8PeJtN1cR+Z9juEmKf3gDyPyzXvl74n8H+ItD1r+x/Go0O/1Sf7TNNcRFZVjWNVaHPUjgkBTnJIGea+b6KAO41PxLpOjeG7rw94WutRuY71gLy9vAEDIvRIowTtUkAknkgAV6P+zL/wAzT/26f+1q8Ar3/wDZl/5mn/t0/wDa1AHoHxt/5JDrv/bv/wClEdfKugalHp1+WneSOGVDHI8QyyqeDgZGeMjGe9fVXxt/5JDrv/bv/wClEdfIFD1E1dWOr1WTR59OtY7bVZRFboEaIQKplO5juwDnONvXPOeeBnC1C9juCsNssiWkRPlrK25j7sfXtVGiklYUY2Pr/wCCX/JIdC/7eP8A0okr0CvP/gl/ySHQv+3j/wBKJK9AplH/2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDw/RNFvvEOtWuk6dF5t3cvsRc4A9ST2AGSfYV1viXw54H0DS5rKLxDe33iOAASC3jVrQvkZUNgHjnnJ+napfgrMIviVaIpjWea3njt3kPCSGM7T79MY965G30LVdR8SjRI7WRtUlnMJhYYYPnnPpjkmgDLr3/9mX/maf8At0/9rVymmfDjwheajc+HW8Zl/EgYxQxpastu0wGSu/ByAQQT8pz0Brr/ANmyGS2uPFsEqlZIntUdT2IMwIoA7z42/wDJIdd/7d//AEojr5LsLBr2RsuscMY3SSN0Uf419afG3/kkOu/9u/8A6UR18r2CmTw/qSxsvmBoyU53MvOSPYY/WgCrqCacrJ/Z8k7DGG83HXAyQQB1OeO1UqtWVk95IwDCOONd0kjdFFXW02wl0ue4tL5nngCs0TxkblJwcehHB9MZ5zgFbC2Pqj4Jf8kh0L/t4/8ASiSvQK8/+CX/ACSHQv8At4/9KJK9ApjPgW3uJrS5iubeV4p4XEkciHDIwOQQfUGvafBvxW8OXviTT9Q8VaJBb62gMP8AbVuSoIZSu6RB3wcZ56noK8RooA981uXwJ8ObJte8Iz6ZrGsyEpFJPqQnkgZs/OI1Bz15JI/nU37NMjyy+K5JGLO7WrMT3J86vn2vf/2Zf+Zp/wC3T/2tQB6B8bf+SQ67/wBu/wD6UR18j2l3LZXAmhIDDgg9CPQ19cfG3/kkOu/9u/8A6UR18gUAdVY3eh3lpcQy77OaZVLKAAjEMcjdu4GMHpzkjtk1dUurGxt57HTYIGjuCD5xlMkigHOMjA/T8q5+ilYnlPr/AOCX/JIdC/7eP/SiSvQK8/8Agl/ySHQv+3j/ANKJK9AplH//2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/r1H4YeC9GvNG1bxV4wtN/h+ziKxnzXQvKCM4CEE+nXqfrjhPDGkf2/4p0vSSSFu7lInIOCFJ+bB9cZr0P49aqR4qs/DdtuisNJtI0SIHClmGc4zjhdo6DvQB5VOY2uJDCpWIsSinqFzwK97/Zl/5mn/ALdP/a1cH4H+D/iDxiBdSqdN0wjcLm4Q5k/3F4JHv0+teofAfSBoPiLxxpIuUufsk1tF5yDAfHnc4oA6z42/8kh13/t3/wDSiOvkCvr/AONv/JIdd/7d/wD0ojr5Y8N2yz6oJHXcsI34Pc9qAJms7Gx8Nu15alr+c5hk8w/IMg/dHHTOc56jpjnBq1fzve6hLJ8zFnIVepx2FbGn+F/tFjdXF9eiyeOFpIkaPd5hAJ2k5G0nHHX/ABltRVyW1FNn078Ev+SQ6F/28f8ApRJXoFef/BL/AJJDoX/bx/6USV6BVFHwjoOry6Br9jq0MaySWkyzKjMQGwemRzXtlv43+E/irXk8Q+JbKe01VUUOlxE8sLEKB0QHdjsWHYfSvAqKAPU/iF8ZtW8R3Vxp+hzyWGiYMSiP5ZJ16EseoB/ujt1rrP2Zf+Zp/wC3T/2tXgFe/wD7Mv8AzNP/AG6f+1qAPQPjb/ySHXf+3f8A9KI6+UdG1FdNvRJIrGJ8LJt5YLnkgZAJ9j+lfV3xt/5JDrv/AG7/APpRHXyBQB2cN74Uslub2ylu/tIwYI5YcNkk5+YEgADuO56YFczf6rdagx818R5yI16D/GqVFTFW6kxTSte59f8AwS/5JDoX/bx/6USV6BXn/wAEv+SQ6F/28f8ApRJXoFUUf//Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/rc8I+GLzxf4ktdHsw4MrZllWPeIY8gF2GRwMjv3FYdfRmh+B9M8DfDm6XUdetdH8Q65AIftksvywhuRGvoCBy3qevAoA8d+IVt4dsPFUmn+Go2FpZxrbzSmRnE0653uNx4GeMdMgkcGvVf2Zf8Amaf+3T/2tXjfibQbbQtZnsrDVoNXhgVTJc20bBFJ42nPGc+hI59cgeyfsy/8zT/26f8AtagD0D42/wDJIdd/7d//AEojr5Ar6/8Ajb/ySHXf+3f/ANKI6+QKAHIoZiC6oME5bPYZxwO/T8e1Nqa4QRlI8xF1BDmNi3IY9T0PGOV4xjvmoaBtW0Pr/wCCX/JIdC/7eP8A0okr0CvP/gl/ySHQv+3j/wBKJK9AoEfBWm3g0/U7W9MEVx9nlWXyZQSj7TnBx24r2C98SfC/4hXyat4pl1bSNS27JFjZpYmVeFC4ViODnoOc/U+K0UAenajqvgjwt4e1zTvCmqX+q3GrRpDvmgMaRICS2dwG72+UY9a7H9mX/maf+3T/ANrV4BXv/wCzL/zNP/bp/wC1qAPQPjb/AMkh13/t3/8ASiOvkOOWSFi0UjIxVlJU4OCCCPoQSD7Gvrz42/8AJIdd/wC3f/0ojr5AoAtyR6cIpTHdXTSD/VK1sqhvmI+Y7zt+XaeAeSR0G4xXH2cSBbbzSi5G+TAL/McHaPu/Lt4y3IPPPENFJLzJSt1Pr/4Jf8kh0L/t4/8ASiSvQK8/+CX/ACSHQv8At4/9KJK9AplH/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/rttA8DRat8NvEfim4uJYG0540thwI5GyN4PGScMoGMckVxNfVUnw3jh+EuneGrnVBp1hGBd6vOMMXwN7KM8AbsHPog45oA+Va9//Zl/5mn/ALdP/a1cr4h8EeCb3whq2u+CtWv5/wCyGjFyt2h2SK52jaSqnPU9/wAOK6r9mX/maf8At0/9rUAegfG3/kkOu/8Abv8A+lEdfIFfX/xt/wCSQ67/ANu//pRHXyTYW32y/ht84Dtyfbqf0oAnvNOW106zuNzeZOCWU+nbH4Vn122sWNoZoZtTkMdpCnlokRwXPIznB9AOB2rnNUsLe2htrm0lZ4JwcBxhlIOOaSZUo2Pqz4Jf8kh0L/t4/wDSiSvQK8/+CX/JIdC/7eP/AEokr0CmSfA1ncfZL23uTGsghkWTY3RsHOD7Gvqz/hYXw68deF2Gs38MNumJZrG8nMTll5xtVh5gz0AzkgcZr5NooA9R8c/Fe31bQm8L+FtIi0rQSRvGxQ8oBBHA4UZAJ6k469RXXfsy/wDM0/8Abp/7WrwCvf8A9mX/AJmn/t0/9rUAegfG3/kkOu/9u/8A6UR18n6NeQ2OqRTThvK+65QZZQepAyMn2zX1h8bf+SQ67/27/wDpRHXyBQB3mqah4buIftzSvPOo+SLy1AYlj/CGwg27ex5yOmK5XWdXOq3ZdIBb2ysTFCG3bAe2e/YVm0VKjYmMbdT6/wDgl/ySHQv+3j/0okr0CvP/AIJf8kh0L/t4/wDSiSvQKoo//9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDwGNGllSNcbmIUZIAyfc8Cup8U/DnxL4OsYb7V7ONLWWTyllinRwHwTtODnPyn24rI8N6JN4j8Safo8DBHvJ1i3nnaD1b3wMn8K7n4kahe+J/G6eEPDsMkum6a4tLOztxw0gGHcgcE7t3zHsM8ZNAHmVe//sy/8zT/ANun/tauY0n4beHbPVINH1rUL7VvEMpG7S9FClYOn+tlbgAZ5x09+/pPwf0vSdE8a+PNN0O5a5063kskjkZw5ztk3jIAzhtw/CgDe+Nv/JIdd/7d/wD0ojr5GtbaS8nEMQBc5IycdK+ufjb/AMkh13/t3/8ASiOvlTQoI3vTcTqrQWymR1bo3tQBTu7Kexm8q4TaxGRznI9ar1fEd3rV68nU9WdjhUH19K2NL0bRLsXCT31xmKJn89UURZCk4yTnJIAGAc5pN2V2KUlFXZ9MfBL/AJJDoX/bx/6USV6BXn/wS/5JDoX/AG8f+lElegUxnxD4F1638MeNtK1m6hMtvbTZkUdQpBUke4zkfSvU9D1DwR4Ut/E2ojxmbi41Yj7PLZ27i8jQszOg3DCs2QNxxgjPBxXhdFAHe6n8R/stjcaR4O01NC02fImlDeZdXIP9+U5I+g6c8816H+zKcnxST/06f+1q+f69/wD2Zf8Amaf+3T/2tQB6B8bf+SQ67/27/wDpRHXynpFxbJ9otrqVoYrhQpmVdxTn0yM19WfG3/kkOu/9u/8A6UR18gUAdPJPodrokNt9pnnmUFpIokwkrlj1bIIAXb65Oe2KxbvUprqMQgLFbr92KMYA+vrVKiklYSVj6/8Agl/ySHQv+3j/ANKJK9Arz/4Jf8kh0L/t4/8ASiSvQKYz/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTLY CLASSIFIED\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ro/BXg++8aa6thaskNvGplu7qQ4SCIdWJ9ewHr6DJHOV7RovhrWYPhhb+HNBtY7jXPE+L26kQ+W1tYjaEDscfKxDEeoLgBqAPM/Fj+HjrbR+GIp106GNYRLOxLXDrwZcH7u7rjjHoOg9j/Zl/5mn/t0/wDa1eb+MfhV4l8EaXb6lqaWstrKwRntpS/kuRkK4IHoeRkcdeRn0j9mX/maf+3T/wBrUAegfG3/AJJDrv8A27/+lEdfIFfX/wAbf+SQ67/27/8ApRHXyBQAUUUUAfX/AMEv+SQ6F/28f+lElegV5/8ABL/kkOhf9vH/AKUSV6BQB8AV9EeGPi54ZvPCH2PVdVufD2sizjsmura2Mg2x52MmFYDIY5BAxk4I4NfO9FAHrnxH+JWn6t4QtvCmlahfawEnE1xqt6gjMmMkKq4B6kcnGAuOc5HR/sy/8zT/ANun/tavAK9//Zl/5mn/ALdP/a1AHoHxt/5JDrv/AG7/APpRHXyBX1/8bf8AkkOu/wDbv/6UR18gUAW5I9PEMpjurppRjyla2UBvmI5O87fl2ngHkkdBuNeUxmZzCjpEWOxXbcwHYEgDJ98D6UyiklYSVup9f/BL/kkOhf8Abx/6USV6BXn/AMEv+SQ6F/28f+lElegUxn//2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LAYER = 1\n",
    "#LABEL = 0\n",
    "print(\"LAYER:\", LAYER)\n",
    "\n",
    "\n",
    "cross_entropy, accuracy, x, keep_prob, y_fc, y_, W_fc1, W_fc2, W_fc3, W_fc4, W_fc5, W_fc6, W_fc7, W_fc8, W_fc9, W_fc10, W_fc11,b_fc1, b_fc2, b_fc3, b_fc4, b_fc5, b_fc6, b_fc7, b_fc8, b_fc9, b_fc10, b_fc11, h_fc1, h_fc1_relu_inp, h_fc2, h_fc2_relu_inp, h_fc3, h_fc3_relu_inp,h_fc4, h_fc4_relu_inp, h_fc5, h_fc5_relu_inp, h_fc6, h_fc6_relu_inp, h_fc7, h_fc7_relu_inp, h_fc8, h_fc8_relu_inp, h_fc9, h_fc9_relu_inp, h_fc10, h_fc10_relu_inp, y_fc = create_model()\n",
    "\n",
    "t_fc1 = h_fc1 #sess.graph.get_tensor_by_name('h_fc1:0')\n",
    "t_fc2 = h_fc2 #sess.graph.get_tensor_by_name('h_fc2:0')\n",
    "t_fc3 = h_fc3 #sess.graph.get_tensor_by_name('h_fc3:0')\n",
    "t_fc4 = h_fc4 #sess.graph.get_tensor_by_name('h_fc4:0')\n",
    "t_fc5 = h_fc5 #sess.graph.get_tensor_by_name('h_fc5:0')\n",
    "t_fc6 = h_fc6 #sess.graph.get_tensor_by_name('h_fc6:0')\n",
    "t_fc7 = h_fc7 #sess.graph.get_tensor_by_name('h_fc7:0')\n",
    "t_fc8 = h_fc8 #sess.graph.get_tensor_by_name('h_fc8:0')\n",
    "t_fc9 = h_fc9 #sess.graph.get_tensor_by_name('h_fc9:0')\n",
    "t_fc10 = h_fc10 #sess.graph.get_tensor_by_name('h_fc10:0')\n",
    "\n",
    "if (LAYER == 1):\n",
    "  curr_lay = t_fc1\n",
    "  prev_lay = t_fc1\n",
    "  curr_hlay = h_fc1\n",
    "  prev_hlay = h_fc1\n",
    "  inp_lay = h_fc1_relu_inp\n",
    "  \n",
    "if (LAYER == 2):\n",
    "  curr_lay = t_fc2\n",
    "  prev_lay = t_fc1\n",
    "  curr_hlay = h_fc2\n",
    "  prev_hlay = h_fc1\n",
    "  inp_lay = h_fc2_relu_inp\n",
    "  \n",
    "if (LAYER == 3):\n",
    "  curr_lay = t_fc3\n",
    "  prev_lay = t_fc2\n",
    "  curr_hlay = h_fc3\n",
    "  prev_hlay = h_fc2\n",
    "  inp_lay = h_fc3_relu_inp\n",
    "  \n",
    "if (LAYER == 4):\n",
    "  curr_lay = t_fc4\n",
    "  prev_lay = t_fc3\n",
    "  curr_hlay = h_fc4\n",
    "  prev_hlay = h_fc3\n",
    "  inp_lay = h_fc4_relu_inp\n",
    "\n",
    "if (LAYER == 5):\n",
    "  curr_lay = t_fc5\n",
    "  prev_lay = t_fc4\n",
    "  curr_hlay = h_fc5\n",
    "  prev_hlay = h_fc4\n",
    "  inp_lay = h_fc5_relu_inp\n",
    "  \n",
    "if (LAYER == 6):\n",
    "  curr_lay = t_fc6\n",
    "  prev_lay = t_fc5\n",
    "  curr_hlay = h_fc6\n",
    "  prev_hlay = h_fc5\n",
    "  inp_lay = h_fc6_relu_inp\n",
    "  \n",
    "if (LAYER == 7):\n",
    "  curr_lay = t_fc7\n",
    "  prev_lay = t_fc6\n",
    "  curr_hlay = h_fc7\n",
    "  prev_hlay = h_fc6\n",
    "  inp_lay = h_fc7_relu_inp\n",
    "  \n",
    "if (LAYER == 8):\n",
    "  curr_lay = t_fc8\n",
    "  prev_lay = t_fc7\n",
    "  curr_hlay = h_fc8\n",
    "  prev_hlay = h_fc7\n",
    "  inp_lay = h_fc8_relu_inp\n",
    "  \n",
    "if (LAYER == 9):\n",
    "  curr_lay = t_fc9\n",
    "  prev_lay = t_fc8\n",
    "  curr_hlay = h_fc9\n",
    "  prev_hlay = h_fc8\n",
    "  inp_lay = h_fc9_relu_inp\n",
    "  \n",
    "if (LAYER == 10):\n",
    "  curr_lay = t_fc10\n",
    "  prev_lay = t_fc9\n",
    "  curr_hlay = h_fc10\n",
    "  prev_hlay = h_fc9\n",
    "  inp_lay = h_fc10_relu_inp\n",
    "  \n",
    "t_label = tf.placeholder(tf.int32)\n",
    "t_neuron_id = tf.placeholder(tf.int32)\n",
    "t_grad = tf.gradients(y_fc[:, t_label], x)\n",
    "t_grad_neuron = tf.gradients(y_fc[:, t_label], curr_hlay)[0]\n",
    "#t_grad_conductance = tf.gradients(curr_lay[:,t_neuron_id], x, grad_ys=t_grad_neuron[:, t_neuron_id])\n",
    "t_grad_conductance = tf.gradients(curr_lay[:,t_neuron_id], x)# grad_ys=t_grad_neuron[:, t_neuron_id]) ## WE DO NOT NEED HOW THE NEURON IMPACTS THE O/P\n",
    "\n",
    "train_suffixes = fingerprint_signature(mnist.train.images, curr_lay)\n",
    "print(\"SUFFIXES COMPUTED FOR ALL TRAINING DATA AT LAYER:\", LAYER)\n",
    "#train_predictions = np.argmax(get_prediction(mnist_train_images), axis=1)\n",
    "#print(\"Predictions computed for all training data\")\n",
    "\n",
    "basic_estimator = tree.DecisionTreeClassifier()\n",
    "basic_estimator.fit(train_suffixes, train_predictions)\n",
    "print(\"DECISION-TREE CONSTRUCTED AT LAYER:\", LAYER)\n",
    "\n",
    "invariants = get_all_invariants(basic_estimator)\n",
    "describe_invariants_all_labels(invariants,prev_lay,curr_lay,train_suffixes,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Prophecy_MNIST",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
