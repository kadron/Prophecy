{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Main Tasks\n",
    "# Running NOW: Retrain only with ReLU and verify with Marabou\n",
    "\n",
    "\n",
    "# Use Marabou to verify global robustness or areas of local robustness if the global robustness doesn't work.\n",
    "# The network doesn't take time series as input, so time series input analysis seems like it's unrelated to this project\n",
    "# but we can come up with something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg') # If we don't want saved images printed on output\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "\n",
    "from Models.loss import smoothL1\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Input, InputLayer\n",
    "from tensorflow.keras.layers import Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn import tree\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "from NNet.python.nnet import NNet\n",
    "\n",
    "import math\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import copy\n",
    "import glob\n",
    "\n",
    "#from python.nnet import NNet\n",
    "\n",
    "\n",
    "#from vis.visualization import visualize_cam\n",
    "#import cv2\n",
    "#FIXIT Needs old Scipy version (1.1.0), need to check integration with Conda and Pip\n",
    "\n",
    "#import tensorflow as tf\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 GPUs\n"
     ]
    }
   ],
   "source": [
    "from tf_keras_vis.utils import num_of_gpus\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils import normalize\n",
    "\n",
    "from matplotlib import cm\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.gradcam import GradcamPlusPlus\n",
    "\n",
    "_, gpus = num_of_gpus()\n",
    "print('{} GPUs'.format(gpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DATA_BOEING = False\n",
    "PLOT_DATA_KJ = True\n",
    "\n",
    "BOEING_TRAIN = False \n",
    "BOEING_TEST = False\n",
    "\n",
    "KJ_TRAIN = False\n",
    "KJ_TEST  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (7386, 200, 360, 3)\n"
     ]
    }
   ],
   "source": [
    "## Loading the data\n",
    "eval_folder = '../20200630_TaxiNet_data/'\n",
    "eval_folder_kjtrain = '/home/ikadron/Work/KJ-TaxinetArtifacts/data_train/'\n",
    "eval_folder_kjtest = '/home/ikadron/Work/KJ-TaxinetArtifacts/data_val/'\n",
    "\n",
    "#Loading the data\n",
    "if BOEING_TRAIN and not BOEING_TEST and not KJ_TRAIN and not KJ_TEST:\n",
    "    x=np.load(eval_folder+'X_train.npy')\n",
    "    y=np.load(eval_folder+'Y_train.npy')\n",
    "elif BOEING_TEST and not BOEING_TRAIN and not KJ_TRAIN and not KJ_TEST:\n",
    "    x=np.load(eval_folder+'X_test.npy')\n",
    "    y=np.load(eval_folder+'Y_test.npy')\n",
    "elif KJ_TRAIN and not BOEING_TEST and not BOEING_TRAIN and not KJ_TEST:\n",
    "    eval_folder = '/home/ikadron/Work/KJ-TaxinetArtifacts/data_train/'\n",
    "elif KJ_TEST and not BOEING_TEST and not BOEING_TRAIN and not KJ_TRAIN:\n",
    "    eval_folder = '/home/ikadron/Work/KJ-TaxinetArtifacts/data_val/'\n",
    "else:\n",
    "    print(\"Only one of BOEING_TRAIN, BOEING_TEST, KJ_TRAIN, KJ_TEST has to be True.\")\n",
    "    \n",
    "if KJ_TRAIN or KJ_TEST:\n",
    "    table = pd.read_csv(eval_folder + \"errors.csv\")\n",
    "    \n",
    "    # Use each example image in folder\n",
    "    exampleImages = glob.glob(eval_folder + \"*png\")\n",
    "    imgNums = sorted([int( f.split(\"/\")[-1].split(\".\")[0] ) for f in exampleImages])\n",
    "    \n",
    "    x = list()\n",
    "    y = list()\n",
    "    for imgNum in imgNums:\n",
    "        img = PIL.Image.open(\"{}{}.png\".format(eval_folder,imgNum))\n",
    "        img_copy = np.array(img)\n",
    "        truth = np.array([table.CTE[imgNum],table.HE[imgNum]])\n",
    "        img.close()\n",
    "        \n",
    "        #print(img_copy.shape)\n",
    "        x.append(img_copy)\n",
    "        y.append(truth)\n",
    "        \n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "print(\"Shape of X:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ##Loading the model\n",
    "# #if MODEL == 'SimpleModel':\n",
    "#     model_path = './Training_Runs/TaxiNet-Simple/SimpleModel.h5'\n",
    "# elif MODEL == 'MobileNetModel':\n",
    "#     model_path = './Training_Runs/TaxiNet-MobileNet/MobileNetV2.h5'\n",
    "# else:\n",
    "#     model_path = './Training_Runs/TaxiNet-FullyConnected/FullyConnectedModel.h5'\n",
    "\n",
    "# print('Loading the model and printing the summary:')\n",
    "# model=load_model(model_path,custom_objects={'smoothL1':smoothL1}) \n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Inputs with Boeing-TaxiNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plots and graphs of distribution of outputs\n",
    "if PLOT_DATA_BOEING:\n",
    "    outputs_test   = []\n",
    "    inference_time = []\n",
    "\n",
    "\n",
    "    for img in x:\n",
    "        t=time.time()\n",
    "        outputs_test.append(model.predict(np.expand_dims(img/255.0,axis=0)))\n",
    "        inference_time.append((1/(time.time()-t)))\n",
    "\n",
    "    outputs_test=np.squeeze(np.asarray(outputs_test))\n",
    "    inference_time=np.squeeze(np.asarray(inference_time))\n",
    "\n",
    "\n",
    "    #Scale the predictions\n",
    "    outputs_cte=outputs_test[:,0]*8.0\n",
    "    outputs_heading=outputs_test[:,1]*35.0\n",
    "\n",
    "    #Plot the predictions vs truth\n",
    "    plt.figure()\n",
    "    truth,=plt.plot(y[:,0],label='Truth')\n",
    "    predictions,=plt.plot(outputs_cte,label='Predictions')\n",
    "    plt.legend(handles=[truth,predictions])\n",
    "    plt.title('Cross Track Error')\n",
    "    plt.xlabel('sample number')\n",
    "    plt.ylabel('distance in meters')\n",
    "    plt.show()\n",
    "\n",
    "    #Plot the model error histogram\n",
    "    error_test=np.squeeze(y[:,0])-outputs_cte\n",
    "    plt.figure()\n",
    "    plt.hist(error_test,bins=50)\n",
    "    plt.title('CT Error Histogram')\n",
    "    plt.xlabel('Error in meters')\n",
    "    plt.ylabel('number of instances')\n",
    "    plt.show()\n",
    "\n",
    "    #Plot the inference time histogram\n",
    "    plt.figure()\n",
    "    plt.hist(inference_time[1:],bins=50)\n",
    "    plt.title('Inference Time Histogram')\n",
    "    plt.xlabel('Inference Time in Hz')\n",
    "    plt.ylabel('number of instances')\n",
    "    plt.show()\n",
    "\n",
    "    #Print error metrics\n",
    "    print(\" \")\n",
    "    print(\"Cross Track Error\")\n",
    "    abs_error_test=np.abs(error_test)\n",
    "    print('MeanAbsoluteError: '+str(np.mean(abs_error_test)))\n",
    "    print('MedianAbsoluteError: '+str(np.median(abs_error_test)))\n",
    "    print('StandardDeviation: '+str(np.std(abs_error_test)))\n",
    "    print('MeanInferenceTime: '+str(np.mean(inference_time)))\n",
    "    print('MaxAbsoluteError: '+str(np.max(abs_error_test)))\n",
    "\n",
    "    #Plot the predictions vs truth\n",
    "    plt.figure()\n",
    "    truth,=plt.plot(y[:,1],label='Truth')\n",
    "    predictions,=plt.plot(outputs_heading,label='Predictions')\n",
    "    plt.legend(handles=[truth,predictions])\n",
    "    plt.title('Heading Error')\n",
    "    plt.xlabel('sample number')\n",
    "    plt.ylabel('degrees')\n",
    "    plt.show()\n",
    "\n",
    "    #Plot the model error histogram\n",
    "    error_test=np.squeeze(y[:,1])-outputs_heading\n",
    "    plt.figure()\n",
    "    plt.hist(error_test,bins=50)\n",
    "    plt.title('Heading Error Histogram')\n",
    "    plt.xlabel('Error in degrees')\n",
    "    plt.ylabel('number of instances')\n",
    "    plt.show()\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Heading Error\")\n",
    "    #Print error metrics\n",
    "    abs_error_test=np.abs(error_test)\n",
    "    print('MeanAbsoluteError: '+str(np.mean(abs_error_test)))\n",
    "    print('MedianAbsoluteError: '+str(np.median(abs_error_test)))\n",
    "    print('StandardDeviation: '+str(np.std(abs_error_test)))\n",
    "    print('MaxAbsoluteError: '+str(np.max(abs_error_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Inputs with KJ-TaxiNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Cross Track Error\n",
      "MeanAbsoluteError: 1.2301886719867832\n",
      "MedianAbsoluteError: 1.1476284667313994\n",
      "StandardDeviation: 0.328541700345444\n",
      "MaxAbsoluteError: 1.7994767347303364\n",
      " \n",
      "Heading Error\n",
      "MeanAbsoluteError: 2.696643050193012\n",
      "MedianAbsoluteError: 2.7565213364950876\n",
      "StandardDeviation: 1.0198928500674072\n",
      "MaxAbsoluteError: 4.221397363510208\n"
     ]
    }
   ],
   "source": [
    "def downsampleImage(img): \n",
    "    \"\"\"\n",
    "    Function for downsampling images of taxiway from 200x360x3 into 8x16x1\n",
    "    \"\"\"\n",
    "    \n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Remove yellow/orange lines\n",
    "    mask = ((img[:,:,0].astype('float')-img[:,:,2].astype('float'))>60) & ((img[:,:,1].astype('float')-img[:,:,2].astype('float'))>30) \n",
    "    img[mask] = 0\n",
    "    \n",
    "    # Convert to grayscale, crop out nose, sky, bottom of image, resize to 256x128, scale so \n",
    "    # values range between 0 and 1\n",
    "    img = np.array(PIL.Image.fromarray(img).convert('L').crop((55,5,360,140)).resize((256,128)))/255.0\n",
    "\n",
    "    # Downsample image\n",
    "    # Split image into stride x stride boxes, average numPix brightest pixels in that box\n",
    "    # As a result, img2 has one value for every box\n",
    "    img2 = np.zeros((height,width))\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            img2[i,j] = np.mean(np.sort(img[stride*i:stride*(i+1),stride*j:stride*(j+1)].reshape(-1))[-numPix:])\n",
    "\n",
    "    # Ensure that the mean of the image is 0.5 and that values range between 0 and 1\n",
    "    # The training data only contains images from sunny, 9am conditions.\n",
    "    # Biasing the image helps the network generalize to different lighting conditions (cloudy, noon, etc)\n",
    "    img2 -= img2.mean()\n",
    "    img2 += 0.5\n",
    "    img2[img2>1] = 1\n",
    "    img2[img2<0] = 0\n",
    "    return img2\n",
    "\n",
    "if PLOT_DATA_KJ:\n",
    "    \n",
    "    ### IMPORTANT PARAMETERS FOR IMAGE PROCESSING ###\n",
    "    stride = 16             # Size of square of pixels downsampled to one grayscale value\n",
    "    numPix = 16             # During downsampling, average the numPix brightest pixels in each square\n",
    "    width  = 256//stride    # Width of downsampled grayscale image\n",
    "    height = 128//stride    # Height of downsampled grayscale image\n",
    "    #################################################\n",
    "    \n",
    "    \n",
    "    # Load network and ground truth errors table\n",
    "    nnet = NNet(\"KJ_TaxiNet.nnet\")\n",
    "    table = pd.read_csv(\"errors.csv\")\n",
    "\n",
    "    # Use each example image in folder\n",
    "    #exampleImages = glob.glob(\"*png\")\n",
    "    #imgNums = sorted([int(file.split(\".\")[0]) for file in exampleImages])\n",
    "    #for imgNum in imgNums:\n",
    "\n",
    "    error_test_ct = []\n",
    "    error_test_he = []\n",
    "\n",
    "    for imgNum, img in enumerate(x[:20]):\n",
    "\n",
    "        # Load image\n",
    "        #img = Image.open(\"%d.png\" % imgNum)\n",
    "\n",
    "        #print(\"Image shape:\", img.shape)\n",
    "        \n",
    "        # Compute downsampled image to use as network input\n",
    "        dsImg = downsampleImage(img)\n",
    "        flatImg = dsImg.reshape(-1)\n",
    "        \n",
    "        #print(\"Downsampled Image shape:\", dsImg.shape)\n",
    "        #print(\"Flat Image shape:\", flatImg.shape)\n",
    "\n",
    "        # save dsImg\n",
    "        #np.save(\"%d.npy\" % imgNum, dsImg)\n",
    "\n",
    "        # Compute prediction and ground truth of CTE / HE\n",
    "        predictions = nnet.evaluate_network(dsImg.reshape(-1))\n",
    "        #truth = np.array([table.CTE[imgNum], table.HE[imgNum]])\n",
    "        truth = y[imgNum]\n",
    "\n",
    "        error_test_ct.append(predictions[0]-truth[0])\n",
    "        error_test_he.append( predictions[1]-truth[1])\n",
    "\n",
    "        # Print result\n",
    "        if False:\n",
    "            print(\"\\nImg Number: %d\" % imgNum)\n",
    "            print(\"Prediction: %.3f CTE, %.3f HE\" % (predictions[0],predictions[1]))\n",
    "            print(\"Truth: %.3f CTE, %.3f HE\" % (truth[0],truth[1]))\n",
    "\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Cross Track Error\")\n",
    "    abs_error_test=np.abs(error_test_ct)\n",
    "    print('MeanAbsoluteError: '+str(np.mean(abs_error_test)))\n",
    "    print('MedianAbsoluteError: '+str(np.median(abs_error_test)))\n",
    "    print('StandardDeviation: '+str(np.std(abs_error_test)))\n",
    "    print('MaxAbsoluteError: '+str(np.max(abs_error_test)))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Heading Error\")\n",
    "    abs_error_test=np.abs(error_test_he)\n",
    "    print('MeanAbsoluteError: '+str(np.mean(abs_error_test)))\n",
    "    print('MedianAbsoluteError: '+str(np.median(abs_error_test)))\n",
    "    print('StandardDeviation: '+str(np.std(abs_error_test)))\n",
    "    print('MaxAbsoluteError: '+str(np.max(abs_error_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "8\n",
      "8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 2,290\n",
      "Trainable params: 2,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "KJ_TAXINET_TRANSFER = True\n",
    "\n",
    "if KJ_TAXINET_TRANSFER:\n",
    "    #Using Keras to Load KJ-TaxiNet\n",
    "    model = Sequential()\n",
    "    for ind, layer_size in enumerate(nnet.layerSizes[1:-1]):\n",
    "        print(layer_size)\n",
    "        if ind == 0:\n",
    "            model.add(Dense(layer_size, activation='relu', kernel_initializer='he_normal', input_shape=(128,), name='dense_{}'.format(ind+1)))\n",
    "        else:\n",
    "            model.add(Dense(layer_size, activation='relu', kernel_initializer='he_normal', name='dense_{}'.format(ind+1)))\n",
    "    model.add(Dense(2,kernel_initializer='he_normal', name='dense_4'))\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[128, 16, 8, 8, 2]\n",
      "MeanAbsoluteDifference CTE: 2.6061404519667714e-06\n",
      "MeanAbsoluteDifference HE: 2.6061404519667714e-06\n",
      " \n",
      "Cross Track Error\n",
      "MeanAbsoluteError: 1.435996198475685\n",
      "MedianAbsoluteError: 1.2262143001819321\n",
      "StandardDeviation: 1.0665681338567263\n",
      "MaxAbsoluteError: 9.604651518062415\n",
      " \n",
      "Heading Error\n",
      "MeanAbsoluteError: 2.751920598503374\n",
      "MedianAbsoluteError: 2.30513006969154\n",
      "StandardDeviation: 2.360128109920573\n",
      "MaxAbsoluteError: 24.663136410407308\n"
     ]
    }
   ],
   "source": [
    "#Transferred KJ-TaxiNet to Keras!\n",
    "if KJ_TAXINET_TRANSFER:\n",
    "    layer_name_list = ['dense_1', 'dense_2', 'dense_3', 'dense_4']\n",
    "\n",
    "    print(nnet.numLayers)\n",
    "    print(nnet.layerSizes)\n",
    "    #print(nnet.ranges)\n",
    "    #print(nnet.means)\n",
    "\n",
    "    for ind, layer_name in enumerate(layer_name_list):\n",
    "        temp = model.get_layer(layer_name).get_weights()\n",
    "\n",
    "        l_w = np.transpose(np.array(nnet.weights[ind]))\n",
    "        l_b = np.array(nnet.biases[ind])\n",
    "\n",
    "        #print(type(temp))\n",
    "        #print(temp[0].shape)\n",
    "        #print(temp[1].shape)\n",
    "        #print(l_w.shape)\n",
    "        #print(l_b.shape)\n",
    "\n",
    "        model.get_layer(layer_name).set_weights([l_w, l_b])\n",
    "\n",
    "    ### IMPORTANT PARAMETERS FOR IMAGE PROCESSING ###\n",
    "    stride = 16             # Size of square of pixels downsampled to one grayscale value\n",
    "    numPix = 16             # During downsampling, average the numPix brightest pixels in each square\n",
    "    width  = 256//stride    # Width of downsampled grayscale image\n",
    "    height = 128//stride    # Height of downsampled grayscale image\n",
    "    #################################################\n",
    "\n",
    "\n",
    "    # Load network and ground truth errors table\n",
    "    #nnet = NNet(\"KJ_TaxiNet.nnet\")\n",
    "    #table = pd.read_csv(\"errors.csv\")\n",
    "\n",
    "    # Use each example image in folder\n",
    "    #exampleImages = glob.glob(\"*png\")\n",
    "    #imgNums = sorted([int(file.split(\".\")[0]) for file in exampleImages])\n",
    "    #for imgNum in imgNums:\n",
    "\n",
    "    error_test_ct = []\n",
    "    error_test_he = []\n",
    "    \n",
    "    error_diff_ct = []\n",
    "    error_diff_he = []\n",
    "\n",
    "    for imgNum, img in enumerate(x):\n",
    "\n",
    "        # Load image\n",
    "        #img = Image.open(\"%d.png\" % imgNum)\n",
    "\n",
    "        # Compute downsampled image to use as network input\n",
    "        dsImg = downsampleImage(img)\n",
    "\n",
    "        # save dsImg\n",
    "        #np.save(\"%d.npy\" % imgNum, dsImg)\n",
    "\n",
    "        # Compute prediction and ground truth of CTE / HE\n",
    "        flat_img = dsImg.reshape(-1)\n",
    "        flat_img_keras = np.expand_dims(flat_img, axis=0)\n",
    "        #print(\"Flat Img Shape:\", flat_img.shape)\n",
    "        #print(\"Flat Img Keras Shape:\", flat_img_keras.shape)\n",
    "        #print(\"Img Shape:\", x[0].shape)\n",
    "        predictions1 = nnet.evaluate_network(flat_img)\n",
    "        predictions2 = model.predict(flat_img_keras)\n",
    "\n",
    "        #outputs_test=np.squeeze(np.asarray(outputs_test))\n",
    "        #inference_time=np.squeeze(np.asarray(inference_time))\n",
    "\n",
    "        #truth = np.array([table.CTE[imgNum], table.HE[imgNum]])\n",
    "        truth = y[imgNum]\n",
    "\n",
    "        error_test_ct.append(predictions1[0]-truth[0])\n",
    "        error_test_he.append(predictions1[1]-truth[1])\n",
    "        \n",
    "        error_diff_ct.append(predictions1[0]-predictions2[0][0])\n",
    "        error_diff_he.append(predictions1[0]-predictions2[0][0])\n",
    "\n",
    "        # Print result\n",
    "        if (predictions1[0] - predictions2[0][0] > 0.1):\n",
    "            print(\"\\nImg Number: %d\" % imgNum)\n",
    "            print(\"Prediction NNet: %.3f CTE, %.3f HE\" % (predictions1[0],predictions1[1]))\n",
    "            print(\"Prediction Keras: %.3f CTE, %.3f HE\" % (predictions2[0][0],predictions2[0][1]))\n",
    "            print(\"Truth: %.3f CTE, %.3f HE\" % (truth[0],truth[1]))\n",
    "\n",
    "\n",
    "            \n",
    "    abs_error_diff_ct = np.abs(error_diff_ct)\n",
    "    print('MeanAbsoluteDifference CTE: '+str(np.mean(abs_error_diff_ct)))\n",
    "    abs_error_diff_he = np.abs(error_diff_he)\n",
    "    print('MeanAbsoluteDifference HE: '+str(np.mean(abs_error_diff_he)))\n",
    "    \n",
    "    print(\" \")\n",
    "    print(\"Cross Track Error\")\n",
    "    abs_error_test=np.abs(error_test_ct)\n",
    "    print('MeanAbsoluteError: '+str(np.mean(abs_error_test)))\n",
    "    print('MedianAbsoluteError: '+str(np.median(abs_error_test)))\n",
    "    print('StandardDeviation: '+str(np.std(abs_error_test)))\n",
    "    print('MaxAbsoluteError: '+str(np.max(abs_error_test)))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Heading Error\")\n",
    "    abs_error_test=np.abs(error_test_he)\n",
    "    print('MeanAbsoluteError: '+str(np.mean(abs_error_test)))\n",
    "    print('MedianAbsoluteError: '+str(np.median(abs_error_test)))\n",
    "    print('StandardDeviation: '+str(np.std(abs_error_test)))\n",
    "    print('MaxAbsoluteError: '+str(np.max(abs_error_test)))\n",
    "\n",
    "\n",
    "    #print(len(nnet.weights))\n",
    "    #print(len(nnet.weights[0]))\n",
    "    #print(len(nnet.weights[0][0]))\n",
    "    #print(len(nnet.weights[1]))\n",
    "    #print(len(nnet.biases[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting activations for each layer\n",
    "\n",
    "#for layer_name in ['dense_1']: #['dense_1', 'dense_2', 'dense_3']:\n",
    "#    print('Extracting values for layer {}'.format(layer_name))\n",
    "#    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "#    #intermediate_output = intermediate_layer_model.predict(data)\n",
    "#    \n",
    "#    layers_test  = []\n",
    "#    outputs_test = []\n",
    "#    \n",
    "#    for img in x:\n",
    "#        t=time.time()\n",
    "#        layer_result = (intermediate_layer_model.predict(np.expand_dims(img/255.0,axis=0))>0).astype('int')\n",
    "#        #print(layer_result[0])\n",
    "#        layers_test.append(layer_result[0])\n",
    "#        outputs_test.append(model.predict(np.expand_dims(img/255.0,axis=0)))\n",
    "#        \n",
    "#    layers_test = np.asarray(layers_test)\n",
    "#    \n",
    "#    #Scale the predictions\n",
    "#    outputs_test = np.squeeze(np.asarray(outputs_test))\n",
    "#    outputs_cte = outputs_test[:,0]*8.0\n",
    "#    outputs_heading = outputs_test[:,1]*35.0\n",
    "#    outputs_cte_divided = (outputs_cte>0).astype('int')\n",
    "#    outputs_heading_divided = (outputs_heading>0).astype('int')\n",
    "#    print(\"Cross Track Error: {}\".format(outputs_cte))\n",
    "#    print(\"Heading Error: {}\".format(outputs_heading))\n",
    "#    \n",
    "#    print(\"Layer patterns: {}\".format(layers_test))\n",
    "#    print(\"Cross Track Error Divided: {}\".format(outputs_cte_divided))\n",
    "#    print(\"Heading Error Divided: {}\".format(outputs_heading_divided))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS TRACK ERROR PREDICTION DIVISIONS:\n",
    "# Change it so that instead of Positive or Negative prediction the classes should be following:\n",
    "# Absolute error is between 0 to 2.0 (|Prediction - Ground Truth|)\n",
    "# Absolute error is greater than 2.0\n",
    "#----------------------------------------------------------------------------------------------\n",
    "# Combine both positive/negative prediction and error bound is within 1.5/greater than 1.5\n",
    "# OR Ground truth is positive/negative and error bound is within 1.5/greater than 1.5\n",
    "\n",
    "# HEADING ERROR PREDICTION DIVISIONS:\n",
    "# \n",
    "def get_prediction(inputs, tensor = None):\n",
    "    if tensor == \"ALL\":\n",
    "        full_list = []\n",
    "        for tensor in ['dense_1', 'dense_2', 'dense_3']:\n",
    "            layer_name = tensor\n",
    "            layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "            layer_outputs_test = []\n",
    "            for img in inputs:\n",
    "                dsImg = downsampleImage(img)\n",
    "                flat_img = dsImg.reshape(-1)\n",
    "                flat_img_keras = np.expand_dims(flat_img, axis=0)\n",
    "\n",
    "                layer_result = (layer_model.predict(flat_img_keras)>0).astype('int')\n",
    "                #layer_output = layer_model.predict(np.expand_dims(img/255.0,axis=0))[0]\n",
    "                layer_outputs_test.append(layer_result[0])\n",
    "            full_list.append(layer_outputs_test)\n",
    "        \n",
    "        new_list = [list(full_list[0][i])+list(full_list[1][i])+list(full_list[2][i]) for i in range(len(inputs))]\n",
    "            \n",
    "        layer_outputs_test = np.asarray(new_list)\n",
    "        return layer_outputs_test\n",
    "    if tensor is None or tensor == 'dense_4':\n",
    "        outputs_test = []\n",
    "        \n",
    "        for img in inputs:\n",
    "            dsImg = downsampleImage(img)\n",
    "            flat_img = dsImg.reshape(-1)\n",
    "            flat_img_keras = np.expand_dims(flat_img, axis=0)\n",
    "            \n",
    "            outputs_test.append(model.predict(flat_img_keras))\n",
    "\n",
    "        outputs_test    = np.squeeze(np.asarray(outputs_test))\n",
    "\n",
    "        #Scale the predictions\n",
    "        outputs_cte     = outputs_test[:,0]\n",
    "        outputs_heading = outputs_test[:,1]\n",
    "        \n",
    "        #Absolute value of the predictions\n",
    "        abs_outputs_cte = np.abs(outputs_cte)\n",
    "        abs_outputs_heading = np.abs(outputs_heading)\n",
    "        \n",
    "        #Absolute Error between Ground Truth and Prediction for Cross Track Error\n",
    "        error_cte=np.squeeze(y[:inputs.shape[0],0])-outputs_cte\n",
    "        abs_error_cte=np.abs(error_cte)\n",
    "\n",
    "        #Absolute Error between Ground Truth and Prediction for Heading Error\n",
    "        error_heading     = np.squeeze(y[:inputs.shape[0],1])-outputs_heading\n",
    "        abs_error_heading = np.abs(error_heading)\n",
    "        \n",
    "        #return (abs_error_heading<=10.0).astype('int')\n",
    "        return abs_outputs_heading, (abs_outputs_cte<=10.0).astype('int')\n",
    "        #return ((outputs_cte>0).__and__(outputs_cte<=1.0)).astype('int')\n",
    "    else:\n",
    "        layer_name = tensor\n",
    "        layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "        layer_outputs_test = []\n",
    "        for img in inputs:\n",
    "            dsImg = downsampleImage(img)\n",
    "            flat_img = dsImg.reshape(-1)\n",
    "            flat_img_keras = np.expand_dims(flat_img, axis=0)\n",
    "            \n",
    "            layer_result = (layer_model.predict(flat_img_keras)>0).astype('int')\n",
    "            #layer_output = layer_model.predict(np.expand_dims(img/255.0,axis=0))[0]\n",
    "            layer_outputs_test.append(layer_result[0])\n",
    "\n",
    "        layer_outputs_test = np.asarray(layer_outputs_test)\n",
    "\n",
    "        #Scale the predictions        \n",
    "        return layer_outputs_test\n",
    "\n",
    "def fingerprint_suffix(inps,ten):\n",
    "    return (get_prediction(inps, tensor=ten)>0.0).astype('int')\n",
    "\n",
    "def fingerprint_signature(inps, layer_name = 'dense_1'):\n",
    "    return None\n",
    "#    layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "#    layer_result = (layer_model.predict(np.expand_dims(img/255.0,axis=0))>0).astype('int')[0]\n",
    "#    return layer_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `output` variable refer to the output of the model,\n",
    "# so, in this case, `output` shape is `(1, 2)` i.e., (samples, classes).\n",
    "\n",
    "#Loss and Model Modifier for middle layers\n",
    "def loss_gen_sum(node_list):\n",
    "    def loss(output):\n",
    "        loss_val = sum([output[0][i] for i in node_list])/len(node_list)\n",
    "        return loss_val\n",
    "    return loss\n",
    "\n",
    "def loss_gen_separate(node_list):\n",
    "    def loss(output):\n",
    "        loss_val = tuple([output[ind][i] for ind,i in enumerate(node_list)])\n",
    "        return loss_val\n",
    "    return loss\n",
    "\n",
    "def model_modifier(current_model):\n",
    "    target_layer = current_model.get_layer(name=layer)\n",
    "    new_model = tf.keras.Model(inputs=current_model.inputs,\n",
    "                               outputs=target_layer.output)\n",
    "    new_model.layers[-1].activation = tf.keras.activations.linear\n",
    "    return new_model\n",
    "    \n",
    "def loss_crosstrack(output):\n",
    "    return (output[0][0])\n",
    "\n",
    "def loss_heading(output):\n",
    "    return (output[0][1])\n",
    "\n",
    "def no_loss(output):\n",
    "    return (output[0][0] * 0)\n",
    "\n",
    "def model_modifier_lastlayer(m):\n",
    "    m.layers[-1].activation = tf.keras.activations.linear\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_decision_path(estimator, inp):\n",
    "  # Extract the decision path taken by an input as an ordered list of indices\n",
    "  # of the neurons that were evaluated.\n",
    "  # See: http://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html\n",
    "  n_nodes = estimator.tree_.node_count\n",
    "  feature = estimator.tree_.feature\n",
    "\n",
    "  # First let's retrieve the decision path of each sample. The decision_path\n",
    "  # method allows to retrieve the node indicator functions. A non zero element of\n",
    "  # indicator matrix at the position (i, j) indicates that the sample i goes\n",
    "  # through the node j.\n",
    "  X_test = [inp]\n",
    "  node_indicator = estimator.decision_path(X_test)\n",
    "  # Similarly, we can also have the leaves ids reached by each sample.\n",
    "  leaf_id = estimator.apply(X_test)\n",
    "  # Now, it's possible to get the tests that were used to predict a sample or\n",
    "  # a group of samples. First, let's make it for the sample.\n",
    "  node_index = node_indicator.indices[node_indicator.indptr[0]:\n",
    "                                      node_indicator.indptr[1]]\n",
    "  neuron_ids = []\n",
    "  for node_id in node_index:\n",
    "    if leaf_id[0] == node_id:\n",
    "        continue\n",
    "    neuron_ids.append(feature[node_id])\n",
    "  return neuron_ids\n",
    "\n",
    "def get_suffix_cluster(neuron_ids, neuron_sig,suffixes):\n",
    "  # Get the cluster of inputs that such that all inputs in the cluster\n",
    "  # have provided on/off signature for the provided neurons.\n",
    "  #\n",
    "  # The returned cluster is an array of indices (into mnist.train.images).\n",
    "  return np.where((suffixes[:, neuron_ids] == neuron_sig).all(axis=1))[0]\n",
    "\n",
    "def is_consistent_cluster(cluster, predictions):\n",
    "  # Check if all inputs within the cluster have the same prediction.\n",
    "  # 'cluster' is an array of input ids.\n",
    "  pred = predictions[cluster[0]]\n",
    "  for i in cluster:\n",
    "    if predictions[i] != pred:\n",
    "      return False\n",
    "  return True\n",
    "\n",
    "def is_misclassified(i):\n",
    "  #print(train_predictions[i])\n",
    "  #print(y[i][0])\n",
    "  return False\n",
    "  #return (1 if train_predictions[i]>0.0 else 0) != (1 if y[i][0]>0.0 else 0)\n",
    "\n",
    "def visualize_conductances(img, label, layer, neuron_ids, only_on=False):\n",
    "  # Visualize the conductances for the provided image.\n",
    "  # Args:\n",
    "  # - img: the provided mnist image\n",
    "  # - label: prediction label w.r.t. conductance must be computed\n",
    "  # - neuron_ids: list of neurons indices from the suffix tensor for which\n",
    "  #    conductances must be computed.\n",
    "  # - only_on: If True then conductance is computed only for those neurons\n",
    "  #    that are on for the given image. \n",
    "  vis = [mnist_to_pil_img(img)]\n",
    "  suffix = fingerprint_suffix([img], layer)\n",
    "  sumigc = 0.0\n",
    "  for i, id in enumerate(neuron_ids):\n",
    "    if only_on and suffix[i] != 1:\n",
    "      continue  \n",
    "    igc = conductance(img, label, neuron_id=id)\n",
    "    # igc = conductances[id]\n",
    "    sumigc = sumigc + igc\n",
    "  \n",
    "  \n",
    "  avgigc = sumigc / len(neuron_ids)\n",
    "  maxval = abs(max(avgigc, key=abs))\n",
    "  minval = abs(min(avgigc, key=abs))\n",
    "  threshold = (maxval - minval)/2.0\n",
    "  print(\"MAX ATR:\", maxval, \"MIN ATR:\", minval, \"THRESH:\", threshold)\n",
    "  avgigc = 1.0 * avgigc * (abs(avgigc) >= threshold)\n",
    "  \n",
    "  \n",
    "  vis.append(visualize_attrs2(255*mnist_to_rgb(img), mnist_to_rgb(avgigc)))\n",
    "  return combine(vis)\n",
    "\n",
    "def get_invariant_inp(estimator, ref_id, suffixes):\n",
    "  # Returns an invariant found w.r.t. the provided reference input\n",
    "  # Args\n",
    "  #  - inp: reference input, shape <784,>\n",
    "  # Returns:\n",
    "  #  - cluster: Indices of training inputs that satisfy the invariant\n",
    "  #  - neuron_id: A list of neurons such that all inputs that agree with\n",
    "  #    the reference input on the on/off status of these neurons have the\n",
    "  #    same prediction as the reference input.\n",
    "  ref_img = mnist_inp_images[ref_id]\n",
    "  ref_suffix = suffixes[ref_id]\n",
    "  print('PREFIX',ref_suffix)\n",
    "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
    "  print('NEURON IDS',neuron_ids)\n",
    "  neuron_sig = ref_suffix[neuron_ids]\n",
    "  print('NEURON SIGNATURE',neuron_sig)\n",
    "  cluster = get_suffix_cluster(neuron_ids, neuron_sig,suffixes)\n",
    "  imgs = []\n",
    "  cnt = 0\n",
    "  for indx1 in range(0,len(cluster)):\n",
    "    img = mnist.train.images(cluster[indx1])\n",
    "    fnd = 1\n",
    "    for i in range(0,len(img)):\n",
    "      if (ref_img[i] != img[i]):\n",
    "        fnd = 0\n",
    "        break\n",
    "    if (fnd == 1):\n",
    "        ref_id = cnt\n",
    "    cnt = cnt + 1\n",
    "    imgs.append(img)\n",
    "    \n",
    "  imgs_suffixes = fingerprint_signature(imgs,'dense_1')\n",
    "  ref_suffix = imgs_suffixes[ref_id]\n",
    "  print('PREFIX',ref_suffix)\n",
    "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
    "  print('NEURON IDS',neuron_ids)\n",
    "  neuron_sig = ref_suffix[neuron_ids]\n",
    "  print('NEURON SIGNATURE',neuron_sig)\n",
    "  cluster = get_suffix_cluster(neuron_ids, neuron_sig, imgs_suffixes)\n",
    "    \n",
    "  return cluster, neuron_ids, neuron_sig\n",
    "\n",
    "def get_invariant(estimator, ref_id, suffixes):\n",
    "  # Returns an invariant found w.r.t. the provided reference input\n",
    "  # Args\n",
    "  #  - ref_id: Index (into mnist.train.images) of the reference input\n",
    "  # Returns:\n",
    "  #  - cluster: Indices of training inputs that satisfy the invariant\n",
    "  #  - neuron_id: A list of neurons such that all inputs that agree with\n",
    "  #    the reference input on the on/off status of these neurons have the\n",
    "  #    same prediction as the reference input.\n",
    "  ref_img = mnist.train.images[ref_id]\n",
    "  ref_suffix = suffixes[ref_id]\n",
    "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
    "  neuron_sig = ref_suffix[neuron_ids]\n",
    "  cluster = get_suffix_cluster(neuron_ids, neuron_sig)\n",
    "  return cluster, neuron_ids, neuron_sig\n",
    "\n",
    "\n",
    "def get_all_invariants(estimator):\n",
    "  # Returns a dictionary mapping each decision tree prediction class\n",
    "  # to a list of invariants. Each invariant is specified as a triple:\n",
    "  # - neuron ids\n",
    "  # - neuron signature (for the neuron ids)\n",
    "  # - number of training samples that hit it\n",
    "  # The neuron ids and neuron signature can be supplied to get_suffix_cluster\n",
    "  # to obtain the cluster of training instances that hit the invariant.\n",
    "  def is_leaf(node):\n",
    "    return estimator.tree_.children_left[node] == estimator.tree_.children_right[node]\n",
    "\n",
    "  def left_child(node):\n",
    "    return estimator.tree_.children_left[node]\n",
    "\n",
    "  def right_child(node):\n",
    "    return estimator.tree_.children_right[node]\n",
    "  \n",
    "  def get_all_paths_rec(node):\n",
    "    # Returns a list of triples corresponding to paths\n",
    "    # in the decision tree. Each triple consists of\n",
    "    # - neurons encountered along the path\n",
    "    # - signature along the path\n",
    "    # - prediction class at the leaf\n",
    "    # - number of training samples that hit the path\n",
    "    # The prediction class and number of training samples\n",
    "    # are set to -1 when the leaf is \"impure\".\n",
    "    feature = estimator.tree_.feature\n",
    "    if is_leaf(node):\n",
    "      values = estimator.tree_.value[node][0]\n",
    "      if len(np.where(values != 0)[0]) == 1:\n",
    "        cl = estimator.classes_[np.where(values != 0)[0][0]]\n",
    "        nsamples = estimator.tree_.n_node_samples[node]\n",
    "      else:\n",
    "        # impure node\n",
    "        cl = -1\n",
    "        nsamples = -1\n",
    "      return [[[], [], cl, nsamples]]\n",
    "    # If it is not a leaf both left and right childs must exist\n",
    "    paths = [[[feature[node]] + p[0], [0] + p[1], p[2], p[3]] for p in get_all_paths_rec(left_child(node))]\n",
    "    paths += [[[feature[node]] + p[0], [1] + p[1], p[2], p[3]] for p in get_all_paths_rec(right_child(node))]\n",
    "    return paths\n",
    "  paths =  get_all_paths_rec(0)\n",
    "  print(\"Obtained all paths\")\n",
    "  invariants = {}\n",
    "  for p in tqdm(paths):\n",
    "    neuron_ids, neuron_sig, cl, nsamples = p\n",
    "    if cl not in invariants:\n",
    "      invariants[cl] = []\n",
    "    # cluster = get_suffix_cluster(neuron_ids, neuron_sig)\n",
    "    invariants[cl].append([neuron_ids, neuron_sig, nsamples])\n",
    "  for cl in invariants.keys():\n",
    "    invariants[cl] = sorted(invariants[cl], key=operator.itemgetter(2), reverse=True)\n",
    "  return invariants\n",
    "\n",
    "\n",
    "def describe_cluster(cluster, neuron_ids, suffixes, show_samples=False):\n",
    "  neuron_sig = suffixes[cluster[0]][neuron_ids]\n",
    "  print(\"Num neurons in invariant\", len(neuron_ids))\n",
    "  print(\"Neuron id and signature\")\n",
    "  \n",
    "  for i in range(0,len(neuron_ids)):\n",
    "    print(\"id:\", neuron_ids[i], \"sig:\", neuron_sig[i])\n",
    "  \n",
    "  print(\"Cluster size: \", len(cluster))\n",
    "  print(\"Num misclassified\", len([i for i in cluster if is_misclassified(i)]))\n",
    "  if show_samples:\n",
    "    for i in range(10):\n",
    "      images = []\n",
    "      for j in range(10):\n",
    "        if 10*i + j >= len(cluster):\n",
    "          break\n",
    "        images.append(mnist_to_pil_img(mnist.train.images[cluster[10*i+j]]))\n",
    "      if len(images) > 0:\n",
    "        show_img(combine(images))\n",
    "  \n",
    "\n",
    "def describe_invariants_all_labels(all_invariants,prevlayer,layer,suffixes, COMMON=False, DEC_PREFX= False):\n",
    "  print(\"PRINTING PURE RULES WITH SUPPORT MORE THAN 1000 FOR EVERY LABEL:\");\n",
    "  for cl, invs in all_invariants.items():\n",
    "    if (cl == -1):\n",
    "      continue\n",
    "    \n",
    "    for indx in range (0, 5):\n",
    "    #len(invs)):\n",
    "      inv = invs[indx]\n",
    "      cls = get_suffix_cluster(inv[0],inv[1],suffixes)\n",
    "      \n",
    "      neurons = inv[0]\n",
    "      signature = inv[1]\n",
    "\n",
    "      if (len(cls) <= 1000):\n",
    "        continue\n",
    "      print(\"Class:\", cl, \", Rule:(neurons:\",inv[0],\",signature:\",inv[1],\"), Support:\",inv[2],\", Num misclassified\", len([i for i in cls if is_misclassified(i)]));\n",
    "\n",
    "      ##invoke_marabou_chk(LAYER,neurons,signature,cl)\n",
    "\n",
    "      if (COMMON == True):\n",
    "          common_nodes(cls,suffixes)\n",
    "\n",
    "      if (DEC_PREFX == True):\n",
    "          decision_prefs(cls,suffixes)\n",
    "\n",
    "  return\n",
    "  \n",
    "def common_nodes(cls,suffixes):\n",
    "    cnt = 0\n",
    "    common = np.zeros(10,dtype=int)\n",
    "    prev = np.zeros(10,dtype=int)\n",
    "    \n",
    "    for indx in range(0, len(cls)):\n",
    "        i = cls[indx]\n",
    "        cnt = cnt + 1\n",
    "        for j in range(0,len(suffixes[i])):\n",
    "          if (common[j] == -1):\n",
    "             continue\n",
    "          if ((indx != 0) and (suffixes[i][j] != prev[j])):\n",
    "             common[j] = -1\n",
    "          else:\n",
    "             common[j] = suffixes[i][j]\n",
    "          prev[j] = suffixes[i][j]\n",
    "\n",
    "\n",
    "    print('COMMON NODES IN CLUSTER for CLASS:',cl,cnt)\n",
    "    com = []\n",
    "    for k in range(0,len(common)):\n",
    "        if (common[k] != -1):\n",
    "           com.append((k,common[k]))\n",
    "    print(com)\n",
    "\n",
    "    return\n",
    "    \n",
    "def decision_prefs(cls,suffixes):\n",
    "    images = mnist.train.images\n",
    "    imgsCom = []\n",
    "    imgs = []\n",
    "    for indx in range(0, len(cls)):\n",
    "        print('IMG:')\n",
    "        print(list(zip(images[cls[indx]])))\n",
    "        imgs.append(images[cls[indx]])\n",
    "        imgsCom.append(images[cls[indx]])\n",
    "            \n",
    "    dec_prefixes= fingerprint_signature(imgs,layer)\n",
    "    prefixes = []\n",
    "    for indx in range(0,len(dec_prefixes)):\n",
    "       dec_pref = dec_prefixes[indx]\n",
    "    \n",
    "       match = 0\n",
    "       for indx1 in range(0, len(prefixes)):\n",
    "          match = 1\n",
    "          for i in range(0,len(prefixes[indx1])):\n",
    "             if (dec_pref[i] != prefixes[indx1][i]):\n",
    "                match = 0\n",
    "                break\n",
    "          if (match == 1):\n",
    "             break\n",
    "    \n",
    "       if (match == 0):\n",
    "          prefixes.append(dec_pref)\n",
    "    \n",
    "    print('DECISION PREFIXES IN CLUSTER for CLASS:',cl,cnt)\n",
    "    for k in range(0,len(prefixes)):\n",
    "      print(prefixes[k])\n",
    "\n",
    "    return\n",
    "    \n",
    "  \n",
    "  #print('LAYER INPS:')\n",
    "  #min = np.zeros(10)\n",
    "  #max = np.zeros(10)\n",
    "  #for dim in range(0,10):\n",
    "  #    min[dim] = 1000\n",
    "  #    max[dim] = -1000\n",
    "          \n",
    "  #prevlayer_vals = get_prediction(imgsCom,prevlayer)      \n",
    "  #print('MIN, MAX LAYER INPS:',len(prevlayer_vals))\n",
    "  #for i in range(0,len(prevlayer_vals)):\n",
    "  #    if (i == 0):\n",
    "  #      print(zip(prevlayer_vals[i]))\n",
    "  #    for dim in range(0,10):\n",
    "  #        if ( prevlayer_vals[i][dim] < min[dim]):\n",
    "  #            min[dim] = prevlayer_vals[i][dim]\n",
    "  #        if ( prevlayer_vals[i][dim] > max[dim]):\n",
    "  #            max[dim] = prevlayer_vals[i][dim]\n",
    "    \n",
    "  #print('MIN')\n",
    "  #print(zip(min))\n",
    "  #print('MAX')\n",
    "  #print(zip(max))    \n",
    "    \n",
    "  #df = pd.DataFrame(df, columns=['Prediction Class', 'Num Instances', 'Num Invariants', 'Num Invariants with cluster size >= 10', 'Size of largest invariant cluster'])\n",
    "  #df = pd.DataFrame(df,columns=['Pred Class','Total #Neurons','# Invariants'])\n",
    "  #return df\n",
    "\n",
    "\n",
    "def describe_all_invariants(all_invariants):\n",
    "  df = []\n",
    "  for cl, invs in all_invariants.iteritems(): \n",
    "    inv = invs[0]\n",
    "    clus = get_suffix_cluster(inv[0],inv[1])\n",
    "    #print(len(clus))\n",
    "    misCl = 0\n",
    "    for i in range(0,len(clus)):\n",
    "      indx = clus[i]\n",
    "      if (is_misclassified(indx) == True):\n",
    "        misCl = misCl + 1\n",
    "    print('class:',cl,',masSup:',inv[2],',#misCl:',misCl)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.shape)\n",
    "# print(len(train_suffixes))\n",
    "# print(len(train_predictions))\n",
    "# print(train_suffixes[0])\n",
    "# print(train_predictions[0])\n",
    "# print(sum(train_predictions))\n",
    "# basic_estimator.max_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions computed for all training data\n"
     ]
    }
   ],
   "source": [
    "actual_predictions, train_predictions = get_prediction(x[:100])#x[:int(len(x)/2)])\n",
    "print(\"Predictions computed for all training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sum((actual_predictions<=20.0).astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER = 4\n",
    "if LAYER == 1:\n",
    "    layer = 'dense_1' #16\n",
    "elif LAYER == 2:\n",
    "    layer = 'dense_2' #8\n",
    "elif LAYER == 3:\n",
    "    layer = 'dense_3' #8\n",
    "else:\n",
    "    layer = 'ALL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffixes computed for all training data\n"
     ]
    }
   ],
   "source": [
    "train_suffixes = fingerprint_suffix(x[:100], layer) #[:int(len(x)/2)], layer)\n",
    "print(\"Suffixes computed for all training data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic decision tree\n",
    "basic_estimator = tree.DecisionTreeClassifier()\n",
    "basic_estimator.fit(train_suffixes, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def invoke_marabou_chk(layer, neurons, signature, label, cl, x_min, x_max, y_min, y_max):\n",
    "    subplot_args = {'subplot_kw': {'xticks': [], 'yticks': []} }# 'nrows': 1, 'ncols': 1, 'figsize': (6, 12),\n",
    "    \n",
    "    #layer = 1\n",
    "    #neurons = [4, 8, 7, 1, 0, 2, 5, 3, 9, 6] \n",
    "    #signature = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    #label = 6\n",
    "\n",
    "    #for lab_indx in range(0,10):\n",
    "    #if (lab_indx == label):\n",
    "    #  continue\n",
    "    limit = 10.0\n",
    "    not_done = False\n",
    "    ROBUSTNESS = False\n",
    "\n",
    "    print(\"there exists x: x >= x_min /\\ x <= x_max /\\ Rule /\\ (y < y_min \\/ y > y_max)\")\n",
    "    print(\"Needs to be UNSAT to prove Rule /\\ x_bounding_box => (y_min <= y <= y_max)\")\n",
    "    \n",
    "    strInternal = \"\"\n",
    "    #Input constraints\n",
    "    for i in range(len(x_min)):\n",
    "        strInternal = strInternal + \"x\"+ str(i) + \" >= \" + str(x_min[i]) + \"\\n\"\n",
    "        strInternal = strInternal + \"x\"+ str(i) + \" <= \" + str(x_max[i]) + \"\\n\"\n",
    "    \n",
    "    #Hidden layer constraints\n",
    "    if layer == 'ALL':\n",
    "        for i in range(0,len(neurons)):\n",
    "            if neurons[i] < 16:\n",
    "                strInternal = strInternal + \"ws_1\" + \"_\" + str(neurons[i])\n",
    "            elif neurons[i] < 24:\n",
    "                strInternal = strInternal + \"ws_2\" + \"_\" + str(neurons[i]-16)\n",
    "            else:\n",
    "                strInternal = strInternal + \"ws_3\" + \"_\" + str(neurons[i]-24)\n",
    "                \n",
    "            if (signature[i] == 0):\n",
    "                strInternal = strInternal + \" <= 0.0\" + \"\\n\"\n",
    "            else:\n",
    "                strInternal = strInternal + \" >= 0.0\"  + \"\\n\"\n",
    "    else:\n",
    "        for i in range(0,len(neurons)):\n",
    "            strInternal = strInternal + \"ws_\"+ str(layer[-1]) + \"_\" + str(neurons[i])\n",
    "            if (signature[i] == 0):\n",
    "                strInternal = strInternal + \" <= 0.0\" + \"\\n\"\n",
    "            else:\n",
    "                strInternal = strInternal + \" >= 0.0\"  + \"\\n\"\n",
    "\n",
    "    strOP = \"\"\n",
    "    #Output layer constraints\n",
    "    if cl == 0:\n",
    "        strOP = \"y0 <= {}\\ny0 >= {}\\n\".format(limit, -limit)\n",
    "        ROBUSTNESS = False\n",
    "    if cl == 1:\n",
    "        y_max = limit\n",
    "        y_min = -limit\n",
    "    ROBUSTNESS = True    \n",
    "        \n",
    "    if ROBUSTNESS:\n",
    "        print(\"Testing NOT(y_min <= y <= y_max)\")\n",
    "        print(\"Testing NOT({} <= y <= {})\".format(y_min, y_max))\n",
    "        for (op, val) in [('>=', y_max+0.1), ('<=', y_min-0.1)]:\n",
    "            strOP = \"y0 {} {}\\n\".format(op, val)\n",
    "\n",
    "            #Write to a property file\n",
    "            file1 = open('TaxiNetProperty.txt',\"w\")\n",
    "            #file1.writelines(strInp) \n",
    "            file1.writelines(strInternal) \n",
    "            file1.writelines(strOP) \n",
    "            file1.close() \n",
    "\n",
    "            #    file1 = open('property.txt',\"r\")  \n",
    "            #    print(\"PROPERTY FILE IS \")\n",
    "            #    print(file1.read())\n",
    "            #    file1.close()\n",
    "\n",
    "            !MarabouExample/Marabou-nosbt ./KJ_TaxiNet.nnet ./TaxiNetProperty.txt --summary-file=TaxiNetSummary.txt --verbosity=0 > TaxiNetSummary2.txt #2>&1\n",
    "            time.sleep(0.5)\n",
    "            print(\"SUMMARY:\")\n",
    "            f = open('TaxiNetSummary.txt', 'r')\n",
    "            file_contents = f.read()\n",
    "            print(file_contents)\n",
    "            f.close()\n",
    "            if(file_contents.find('UNSAT') == -1):\n",
    "                not_done = True\n",
    "                image_vals = []\n",
    "                f2 = open('TaxiNetSummary2.txt', 'r')\n",
    "                file_contents = f2.readlines()\n",
    "                #print(file_contents)\n",
    "                for line in file_contents:\n",
    "                    if \"=\" in line and \"x\" in line:\n",
    "                        value = line.split(\"=\")[-1]\n",
    "                        #print(\"x\", value)\n",
    "                        #print(\"x\", float(value))\n",
    "                        image_vals.append(float(value))\n",
    "                #print (file_contents)\n",
    "                f2.close()\n",
    "                img = np.array(image_vals)\n",
    "                img = np.reshape(img, (8,16))\n",
    "                img = np.rint(img*255.0)\n",
    "\n",
    "                f, ax = plt.subplots(**subplot_args)\n",
    "\n",
    "                #Visualize base image\n",
    "                ax.imshow(img)\n",
    "                ax.set_title(\"Counterexample Image\", fontsize=14)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                plt.close(f)\n",
    "\n",
    "    else:\n",
    "        #Write to a property file\n",
    "        file1 = open('TaxiNetProperty.txt',\"w\")\n",
    "        #file1.writelines(strInp) \n",
    "        file1.writelines(strInternal) \n",
    "        file1.writelines(strOP) \n",
    "        file1.close() \n",
    "\n",
    "        #    file1 = open('property.txt',\"r\")  \n",
    "        #    print(\"PROPERTY FILE IS \")\n",
    "        #    print(file1.read())\n",
    "        #    file1.close()\n",
    "\n",
    "        !MarabouExample/Marabou-nosbt ./KJ_TaxiNet.nnet ./TaxiNetProperty.txt --summary-file=TaxiNetSummary.txt --verbosity=0 | tee TaxiNetSummary2.txt #2>&1\n",
    "        time.sleep(0.5)\n",
    "        print(\"SUMMARY:\")\n",
    "        f = open('TaxiNetSummary.txt', 'r')\n",
    "        file_contents = f.read()\n",
    "        print (file_contents)\n",
    "        f.close()\n",
    "        if (file_contents.find('UNSAT') == -1):\n",
    "            not_done = True\n",
    "        else:\n",
    "            image_vals = []\n",
    "            f2 = open('TaxiNetSummary2.txt', 'r')\n",
    "            file_contents = f2.readlines()\n",
    "            for line in file_contents:\n",
    "                if \"=\" in line and \"x\" in line:\n",
    "                    value = line.split(\"=\")[-1]\n",
    "                    print(\"x\", value)\n",
    "                    print(\"x\", float(value))\n",
    "                    image_vals.append(float(value))\n",
    "            print (file_contents)\n",
    "            f2.close()\n",
    "            print(\"If the values are correct, visualize!\")\n",
    "\n",
    "    if (not_done == False):\n",
    "        print(\"RULE PROVED TO BE A PROPERTY!\")\n",
    "        return True\n",
    "    else:\n",
    "        print (\"PROPERTY COULD NOT BE PROVED:\")\n",
    "        return False\n",
    "  \n",
    "  #f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_invariants_all_labels(all_invariants,prevlayer,layer,suffixes,label):\n",
    "    #base_image_folder = './Images/BaseImages/'\n",
    "    #if not os.path.exists(base_image_folder):\n",
    "    #    os.makedirs(base_image_folder)\n",
    "    #image_folder = './Images/KJ_TaxiNet_CrossTrackBound_1'\n",
    "    #if not os.path.exists(image_folder):\n",
    "    #    os.makedirs(image_folder)\n",
    "    plt.style.use('grayscale')\n",
    "    \n",
    "    VISUALIZE = False\n",
    "    SAVE = False\n",
    "    SHOW = True\n",
    "    min_support = 1\n",
    "\n",
    "    print(\"\\n PRINTING PURE RULES WITH SUPPORT MORE THAN {}:\".format(min_support));\n",
    "    for cl, invs in all_invariants.items():\n",
    "        #if ((cl == -1)): \n",
    "        #    continue\n",
    "    \n",
    "    \n",
    "        for indx in range (0, len(invs)):\n",
    "            inv = invs[indx]\n",
    "            cls = get_suffix_cluster(inv[0],inv[1],suffixes)\n",
    "      \n",
    "            neurons = inv[0]\n",
    "            signature = inv[1]\n",
    "            print(len(cls))\n",
    "\n",
    "            \n",
    "            print(\"Class:\", cl, \", Rule:(neurons:\",inv[0],\",signature:\",inv[1],\"), Support:\",inv[2],\", Num misclassified\", len([i for i in cls if is_misclassified(i)]));\n",
    "            \n",
    "            \n",
    "            if (len(cls) <= min_support):   \n",
    "                continue\n",
    "            if ((cl == -1)): \n",
    "                continue\n",
    "                \n",
    "            interval = int(len(cls)/10)\n",
    "            \n",
    "            #Finding Longest Sequences\n",
    "            i = 0\n",
    "            sequence = [cls[k] for k in range(len(cls))]\n",
    "            #print(\"Image Sequence for Class:\", sequence)\n",
    "            sequence = sorted(sequence)\n",
    "            #print(\"Sorted Image Sequence for Class:\", sequence)\n",
    "            cons_subsequence = []\n",
    "            subseq_start = False\n",
    "            new_subseq = []\n",
    "            for el in sequence:\n",
    "                if subseq_start is False or el == new_subseq[-1] + 1:\n",
    "                    subseq_start = True\n",
    "                else:\n",
    "                    cons_subsequence.append(new_subseq)\n",
    "                    new_subseq = []\n",
    "                new_subseq.append(el)\n",
    "            cons_subsequence.append(new_subseq)\n",
    "            \n",
    "            cons_subsequence = sorted(cons_subsequence, key=len)\n",
    "            cons_subsequence.reverse()\n",
    "            \n",
    "            print(\"Consecutive Subsequence Lengths by decreasing length:\", [len(el) for el in cons_subsequence])\n",
    "            \n",
    "            for sequence_ind, sequence in enumerate(cons_subsequence[0:10]):\n",
    "                len_lower_limit = 1\n",
    "                if len(sequence) <= len_lower_limit:\n",
    "                    print(\"Skipping sequence {} because its length {} is less than or equal to {}\".format(sequence_ind, len(sequence), len_lower_limit))\n",
    "                    continue\n",
    "                print(\"Generating images for sequence {} of length {}\".format(sequence_ind, len(sequence)))\n",
    "\n",
    "                heatmap_sequence = list()\n",
    "                 \n",
    "                test_img = x[sequence[0]]\n",
    "                dsImg = downsampleImage(test_img)\n",
    "                flat_img = dsImg.reshape(-1)\n",
    "                #flat_img_keras = np.expand_dims(flat_img, axis=0)\n",
    "                \n",
    "                min_img = flat_img[:] #x[sequence[0]]\n",
    "                max_img = flat_img[:] #x[sequence[0]]\n",
    "\n",
    "                for ind, ref_id in enumerate(sequence):\n",
    "                    if ind > 0:\n",
    "                        img = x[ref_id]\n",
    "                        dsImg = downsampleImage(img)\n",
    "                        new_img = dsImg.reshape(-1)\n",
    "                        min_img = np.minimum(min_img, new_img)\n",
    "                        max_img = np.maximum(max_img, new_img)\n",
    "                    \n",
    "                    #Visualize base image\n",
    "                    if ind%3 == 0 or ind == len(sequence)-1:\n",
    "                        f, ax = plt.subplots(**{'subplot_kw': {'xticks': [], 'yticks': []}})\n",
    "                        ax.imshow(dsImg)\n",
    "                        ax.set_title(\"Downsampled Image #{}\".format(ref_id), fontsize=14)\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                        plt.close(f)\n",
    "                        \n",
    "                print(\"Generating proofs for sequence {} of length {}\".format(sequence_ind, len(sequence)))\n",
    "                    \n",
    "                y_subset = y[sequence[0]:sequence[-1]+1,0]\n",
    "                y_min = min(y_subset)\n",
    "                y_max = max(y_subset)\n",
    "                print(\"y_min,max\", y_min, y_max)\n",
    "                prov = invoke_marabou_chk(layer, neurons, signature, label, cl, min_img, max_img, y_min, y_max)\n",
    "            \n",
    "            #print(\"Visualizing Images and Activations for Longest Subsequence:\", cons_subsequence[0])\n",
    "            \n",
    "            if VISUALIZE:\n",
    "                subplot_args = { 'nrows': 1, 'ncols': 3, 'figsize': (6, 12),\n",
    "                                 'subplot_kw': {'xticks': [], 'yticks': []} }\n",
    "                subplot_args2 = { 'nrows': 1, 'ncols': 2, 'figsize': (6, 12),\n",
    "                                 'subplot_kw': {'xticks': [], 'yticks': []} }\n",
    "                for sequence_ind, sequence in enumerate(cons_subsequence[0:10]):\n",
    "                    if len(sequence) < 5:\n",
    "                        print(\"Skipping sequence {} because its length {} is less than 5\".format(sequence_ind, len(sequence)))\n",
    "                        continue\n",
    "                    print(\"Generating Images and Activation Visualizations for sequence {} of length {}\".format(sequence_ind, len(sequence)))\n",
    "                    \n",
    "                    heatmap_sequence = list()\n",
    "                    \n",
    "                    min_img = x[sequence[0]]\n",
    "                    max_img = x[sequence[0]]\n",
    "                    \n",
    "                    for ref_id in sequence[1:]:\n",
    "                        img = x[ref_id]\n",
    "                        min_img = np.minimum(min_img, img)\n",
    "                        max_img = np.maximum(max_img, img)\n",
    "\n",
    "                    if SHOW:\n",
    "                        f,ax = plt.subplots(**subplot_args2)\n",
    "\n",
    "                        #Visualize base image\n",
    "                        ax[0].imshow(min_img)\n",
    "                        ax[0].set_title(\"Min Image\", fontsize=14)\n",
    "\n",
    "                        #Visualize base image\n",
    "                        ax[1].imshow(max_img)\n",
    "                        ax[1].set_title(\"Max Image\", fontsize=14)\n",
    "\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                    \n",
    "                    if SAVE:\n",
    "                        f, ax = plt.subplots(**{'subplot_kw': {'xticks': [], 'yticks': []}})\n",
    "                        ax.imshow(min_img)\n",
    "                        f.savefig(\"{}Sequence#{}, Len_{}, Minimum of Images#{}-{}.png\".format(\n",
    "                            inv_image_folder, sequence_ind, len(sequence), sequence[0], sequence[-1]))\n",
    "                        plt.close(f)\n",
    "                        \n",
    "                        f, ax = plt.subplots(**{'subplot_kw': {'xticks': [], 'yticks': []}})\n",
    "                        ax.imshow(max_img)\n",
    "                        f.savefig(\"{}Sequence#{}, Len_{}, Maximum of Images#{}-{}.png\".format(\n",
    "                            inv_image_folder, sequence_ind, len(sequence), sequence[0], sequence[-1]))\n",
    "                        plt.close(f)\n",
    "                    \n",
    "                    for ind, ref_id in enumerate(sequence):\n",
    "                        #if (is_misclassified(ref_id)):\n",
    "                        #  print(\"MISCLASSIFIED\")\n",
    "                        #else:\n",
    "                        #  print(\"CORRECTLY CLASSIFIED\")\n",
    "                        #print(\"Input #{}\".format(ref_id))\n",
    "                        \n",
    "                        #Loss function with the neuron IDs in the pattern\n",
    "                        loss_fn = loss_gen_sum(inv[0])\n",
    "                        loss_fn2 = loss_gen_separate(inv[0])\n",
    "\n",
    "                        img = x[ref_id]\n",
    "                        img_mod = np.expand_dims(img/255.0,axis=0)\n",
    "                        \n",
    "                        if SHOW:\n",
    "                            f, ax = plt.subplots(**subplot_args)\n",
    "                        \n",
    "                            #Visualize base image\n",
    "                            ax[0].imshow(img)\n",
    "                            ax[0].set_title(\"Image #{}\".format(ref_id), fontsize=14)\n",
    "                        if SAVE:\n",
    "                            f, ax = plt.subplots(**{'subplot_kw': {'xticks': [], 'yticks': []}})\n",
    "                            ax.imshow(img)\n",
    "                            f.savefig(\"{}Image #{}.png\".format(base_image_folder, ref_id))\n",
    "                            plt.close(f)\n",
    "                        \n",
    "                        if False: #SALIENCY:\n",
    "                            \n",
    "                            saliency_map = saliency(loss_fn, img_mod, \n",
    "                                                    smooth_samples=20, # The number of calculating gradients iterations.\n",
    "                                                    smooth_noise=0.20) # noise spread level.\n",
    "                            saliency_map = normalize(saliency_map)\n",
    "                            \n",
    "                            # Render\n",
    "                            ax[1].set_title('Saliency', fontsize=14)\n",
    "                            ax[1].imshow(img)\n",
    "                            ax[1].imshow(saliency_map[0], cmap='jet', alpha=0.5)\n",
    "                            \n",
    "                        if SAVE or SHOW: #GRADCAM++:\n",
    "                            # Generate heatmap with GradCAM++\n",
    "                            cam = gradcam(loss_fn,\n",
    "                                          img_mod,\n",
    "                                          penultimate_layer=-1, # model.layers number\n",
    "                                         )\n",
    "                            cam = normalize(cam)\n",
    "                            heatmap_sequence.append(cam)\n",
    "                            \n",
    "                            heatmap = np.uint8(cm.jet(cam[0])[..., :3] * 255)\n",
    "                            #heatmap_sequence.append(heatmap)\n",
    "                            \n",
    "                            if SHOW:\n",
    "                                ax[1].set_title('GradCAM++', fontsize=14)\n",
    "                                ax[1].imshow(img)\n",
    "                                ax[1].imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "                            if SAVE:\n",
    "                                f, ax = plt.subplots(**{'subplot_kw': {'xticks': [], 'yticks': []}})\n",
    "                                ax.imshow(img)\n",
    "                                ax.imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "                                f.savefig(\"{}Sequence#{}, Len_{}, GradCAM++ on Image#{}.png\".format(\n",
    "                                    inv_image_folder, sequence_ind, len(sequence), ref_id))\n",
    "                                plt.close(f)\n",
    "                                \n",
    "                        for K in [5, 10, 15, len(sequence)]:\n",
    "                            if len(heatmap_sequence) >= K:\n",
    "                                new_heatmap = heatmap_sequence[ind]\n",
    "                                for k in range(1,K):\n",
    "                                    new_heatmap = np.add(new_heatmap, heatmap_sequence[ind-k])\n",
    "\n",
    "                                new_heatmap = np.divide(new_heatmap, K)\n",
    "                                new_heatmap = np.uint8(cm.jet(new_heatmap)[..., :3] * 255)\n",
    "                                new_heatmap = np.squeeze(new_heatmap)\n",
    "                                \n",
    "                                new_img = x[ref_id]\n",
    "                                for k in range(1,K):\n",
    "                                    new_img = np.add(new_img, x[ref_id-k])\n",
    "                                new_img = np.divide(new_img, K)\n",
    "                                new_img = np.expand_dims(new_img/255.0,axis=0)\n",
    "                                new_img = np.squeeze(new_img)\n",
    "\n",
    "                                if SHOW:\n",
    "                                    ax[2].set_title('GradCAM++ {} between Images#{}-{}'.format(K, ref_id-K+1, ref_id), fontsize=14)\n",
    "                                    ax[2].imshow(new_img)\n",
    "                                    ax[2].imshow(new_heatmap, cmap='jet', alpha=0.5)\n",
    "                                if SAVE:\n",
    "                                    f, ax = plt.subplots(**{'subplot_kw': {'xticks': [], 'yticks': []}})\n",
    "                                    ax.imshow(new_img)\n",
    "                                    ax.imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "                                    f.savefig(\"{}Sequence#{}, Len_{}, GradCAM++ on Subsequence of Length {}, Images#{}-{}.png\".format(\n",
    "                                        inv_image_folder, sequence_ind, len(sequence), K, ref_id-K+1, ref_id))\n",
    "                                    plt.close(f)\n",
    "                            elif SHOW:\n",
    "                                ax[2].set_title('Empty Image', fontsize=14)\n",
    "                                ax[2].imshow(np.zeros(img.shape))\n",
    "\n",
    "                            if SHOW:\n",
    "                                plt.tight_layout()\n",
    "                                plt.show()\n",
    "    return\n",
    "\n",
    "#             if False:\n",
    "#                 while (i < len(cls)):\n",
    "#                     ref_id = cls[i]\n",
    "#                     #if (is_misclassified(ref_id)):\n",
    "#                     #  print(\"MISCLASSIFIED\")\n",
    "#                     #else:\n",
    "#                     #  print(\"CORRECTLY CLASSIFIED\")\n",
    "#                     print(\"Input #{}\".format(i))\n",
    "\n",
    "#                     #show_img(visualize_conductances(x[ref_id], train_predictions[ref_id], layer, inv[0]))\n",
    "\n",
    "#                     #Loss function with the neuron IDs in the pattern\n",
    "#                     loss = loss_gen(inv[0])\n",
    "\n",
    "#                     img = x[ref_id]\n",
    "#                     img_mod = np.expand_dims(img/255.0,axis=0)\n",
    "\n",
    "#                     f,ax = plt.subplots(**subplot_args)\n",
    "\n",
    "#                     #Visualize base image\n",
    "#                     ax[0][0].imshow(img)\n",
    "#                     ax[0][0].set_title('Image', fontsize=14)\n",
    "#                     #plt.tight_layout()\n",
    "#                     #plt.show()\n",
    "\n",
    "#                     if True: #SALIENCY:\n",
    "\n",
    "#                         saliency_map = saliency(loss, img_mod, \n",
    "#                                                 smooth_samples=20, # The number of calculating gradients iterations.\n",
    "#                                                 smooth_noise=0.20) # noise spread level.\n",
    "#                         saliency_map = normalize(saliency_map)\n",
    "\n",
    "#                         # Render\n",
    "#                         ax[0][1].set_title('Saliency', fontsize=14)\n",
    "#                         ax[0][1].imshow(img)\n",
    "#                         ax[0][1].imshow(saliency_map[0], cmap='jet', alpha=0.5)\n",
    "\n",
    "#                         ###########                    \n",
    "#                         saliency_map_ll = saliency_lastlayer(loss_lastlayer, img_mod, \n",
    "#                                                 smooth_samples=20, # The number of calculating gradients iterations.\n",
    "#                                                 smooth_noise=0.20) # noise spread level.\n",
    "#                         saliency_map_ll = normalize(saliency_map_ll)\n",
    "\n",
    "#                         # Render\n",
    "#                         ax[1][1].set_title('Saliency Lastlayer', fontsize=14)\n",
    "#                         ax[1][1].imshow(img)\n",
    "#                         ax[1][1].imshow(saliency_map_ll[0], cmap='jet', alpha=0.5)\n",
    "\n",
    "#                         #plt.tight_layout()\n",
    "#                         #plt.show()\n",
    "#                     if True: #GRADCAM:\n",
    "#                         # Generate heatmap with GradCAM++\n",
    "#                         cam = gradcam(loss,\n",
    "#                                       img_mod,\n",
    "#                                       penultimate_layer=-1, # model.layers number\n",
    "#                                      )\n",
    "#                         cam = normalize(cam)\n",
    "\n",
    "#                         heatmap = np.uint8(cm.jet(cam[0])[..., :3] * 255)\n",
    "#                         ax[0][2].set_title('GradCAM++', fontsize=14)\n",
    "#                         ax[0][2].imshow(img)\n",
    "#                         ax[0][2].imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "\n",
    "#                         ##########\n",
    "#                         cam_ll = gradcam_lastlayer(loss_lastlayer,\n",
    "#                                       img_mod,\n",
    "#                                       penultimate_layer=-1, # model.layers number\n",
    "#                                      )\n",
    "#                         cam_ll = normalize(cam_ll)\n",
    "\n",
    "#                         heatmap_ll = np.uint8(cm.jet(cam_ll[0])[..., :3] * 255)\n",
    "#                         ax[1][2].set_title('GradCAM++ LastLayer', fontsize=14)\n",
    "#                         ax[1][2].imshow(img)\n",
    "#                         ax[1][2].imshow(heatmap_ll, cmap='jet', alpha=0.5)\n",
    "\n",
    "#                     plt.tight_layout()\n",
    "#                     plt.show()\n",
    "                    \n",
    "#                     i = i + interval\n",
    "                    \n",
    "#                     #f, ax = plt.subplots(**subplot_args)\n",
    "#                     #for i, title in enumerate(image_titles):\n",
    "#                     #    heatmap = np.uint8(cm.jet(cam[i])[..., :3] * 255)\n",
    "#                     #    ax[i].set_title(title, fontsize=14)\n",
    "#                     #    ax[i].imshow(images[i])\n",
    "#                     #    ax[i].imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "#                     #plt.tight_layout()\n",
    "#                     #plt.savefig('images/gradcam_plus_plus.png')\n",
    "#                     #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6/6 [00:00<00:00, 19225.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "Obtained all paths\n",
      "\n",
      " PRINTING PURE RULES WITH SUPPORT MORE THAN 1:\n",
      "58\n",
      "Class: 1 , Rule:(neurons: [30] ,signature: [0] ), Support: 58 , Num misclassified 0\n",
      "Consecutive Subsequence Lengths by decreasing length: [58]\n",
      "Generating images for sequence 0 of length 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(sum(train_predictions))\n",
    "\n",
    "invariants = get_all_invariants(basic_estimator)\n",
    "describe_invariants_all_labels(invariants, None, layer, suffixes = train_suffixes, label = train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nasa-env]",
   "language": "python",
   "name": "conda-env-nasa-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
